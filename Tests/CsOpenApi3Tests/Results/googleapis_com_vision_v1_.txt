//------------------------------------------------------------------------------
// <auto-generated>
//     This code was generated by a tool.
//
//     Changes to this file may cause incorrect behavior and will be lost if
//     the code is regenerated.
// </auto-generated>
//------------------------------------------------------------------------------

namespace MyNS
{
	using System;
	using System.Linq;
	using System.Collections.Generic;
	using System.Threading.Tasks;
	using Newtonsoft.Json;
	using Fonlow.Net.Http;
	
	
	/// <summary>
	/// Request message for the `AddProductToProductSet` method.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class AddProductToProductSetRequest
	{
		
		/// <summary>
		/// Required. The resource name for the Product to be added to this ProductSet. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID`
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="product")]
		public string Product { get; set; }
	}
	
	/// <summary>
	/// A request to annotate one single file, e.g. a PDF, TIFF or GIF file.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class AnnotateFileRequest
	{
		
		/// <summary>
		/// Required. Requested features.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="features")]
		public Feature[] Features { get; set; }
		
		/// <summary>
		/// Image context and/or feature-specific parameters.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="imageContext")]
		public ImageContext ImageContext { get; set; }
		
		/// <summary>
		/// The desired input location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="inputConfig")]
		public InputConfig InputConfig { get; set; }
		
		/// <summary>
		/// Pages of the file to perform image annotation. Pages starts from 1, we assume the first page of the file is page 1. At most 5 pages are supported per request. Pages can be negative. Page 1 means the first page. Page 2 means the second page. Page -1 means the last page. Page -2 means the second to the last page. If the file is GIF instead of PDF or TIFF, page refers to GIF frames. If this field is empty, by default the service performs image annotation for the first 5 pages of the file.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pages")]
		public int[] Pages { get; set; }
	}
	
	/// <summary>
	/// The type of Google Cloud Vision API detection to perform, and the maximum number of results to return for that type. Multiple `Feature` objects can be specified in the `features` list.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Feature
	{
		
		/// <summary>
		/// Maximum number of results of this type. Does not apply to `TEXT_DETECTION`, `DOCUMENT_TEXT_DETECTION`, or `CROP_HINTS`.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="maxResults")]
		public System.Nullable<System.Int32> MaxResults { get; set; }
		
		/// <summary>
		/// Model to use for the feature. Supported values: "builtin/stable" (the default if unset) and "builtin/latest". `DOCUMENT_TEXT_DETECTION` and `TEXT_DETECTION` also support "builtin/weekly" for the bleeding edge release updated weekly.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="model")]
		public string Model { get; set; }
		
		/// <summary>
		/// The feature type.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="type")]
		public System.Nullable<FeatureType> Type { get; set; }
	}
	
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public enum FeatureType
	{
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		TYPE_UNSPECIFIED = 0,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		FACE_DETECTION = 1,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LANDMARK_DETECTION = 2,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LOGO_DETECTION = 3,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LABEL_DETECTION = 4,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		TEXT_DETECTION = 5,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		DOCUMENT_TEXT_DETECTION = 6,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		SAFE_SEARCH_DETECTION = 7,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		IMAGE_PROPERTIES = 8,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		CROP_HINTS = 9,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		WEB_DETECTION = 10,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		PRODUCT_SEARCH = 11,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		OBJECT_LOCALIZATION = 12,
	}
	
	/// <summary>
	/// Image context and/or feature-specific parameters.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ImageContext
	{
		
		/// <summary>
		/// Parameters for crop hints annotation request.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="cropHintsParams")]
		public CropHintsParams CropHintsParams { get; set; }
		
		/// <summary>
		/// List of languages to use for TEXT_DETECTION. In most cases, an empty value yields the best results since it enables automatic language detection. For languages based on the Latin alphabet, setting `language_hints` is not needed. In rare cases, when the language of the text in the image is known, setting a hint will help get better results (although it will be a significant hindrance if the hint is wrong). Text detection returns an error if one or more of the specified languages is not one of the [supported languages](https://cloud.google.com/vision/docs/languages).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageHints")]
		public string[] LanguageHints { get; set; }
		
		/// <summary>
		/// Rectangle determined by min and max `LatLng` pairs.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="latLongRect")]
		public LatLongRect LatLongRect { get; set; }
		
		/// <summary>
		/// Parameters for a product search request.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productSearchParams")]
		public ProductSearchParams ProductSearchParams { get; set; }
		
		/// <summary>
		/// Parameters for text detections. This is used to control TEXT_DETECTION and DOCUMENT_TEXT_DETECTION features.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="textDetectionParams")]
		public TextDetectionParams TextDetectionParams { get; set; }
		
		/// <summary>
		/// Parameters for web detection request.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="webDetectionParams")]
		public WebDetectionParams WebDetectionParams { get; set; }
	}
	
	/// <summary>
	/// Parameters for crop hints annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class CropHintsParams
	{
		
		/// <summary>
		/// Aspect ratios in floats, representing the ratio of the width to the height of the image. For example, if the desired aspect ratio is 4/3, the corresponding float value should be 1.33333. If not specified, the best possible crop is returned. The number of provided aspect ratios is limited to a maximum of 16; any aspect ratios provided after the 16th are ignored.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="aspectRatios")]
		public double[] AspectRatios { get; set; }
	}
	
	/// <summary>
	/// Rectangle determined by min and max `LatLng` pairs.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class LatLongRect
	{
		
		/// <summary>
		/// An object that represents a latitude/longitude pair. This is expressed as a pair of doubles to represent degrees latitude and degrees longitude. Unless specified otherwise, this object must conform to the WGS84 standard. Values must be within normalized ranges.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="maxLatLng")]
		public LatLng MaxLatLng { get; set; }
		
		/// <summary>
		/// An object that represents a latitude/longitude pair. This is expressed as a pair of doubles to represent degrees latitude and degrees longitude. Unless specified otherwise, this object must conform to the WGS84 standard. Values must be within normalized ranges.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="minLatLng")]
		public LatLng MinLatLng { get; set; }
	}
	
	/// <summary>
	/// An object that represents a latitude/longitude pair. This is expressed as a pair of doubles to represent degrees latitude and degrees longitude. Unless specified otherwise, this object must conform to the WGS84 standard. Values must be within normalized ranges.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class LatLng
	{
		
		/// <summary>
		/// The latitude in degrees. It must be in the range [-90.0, +90.0].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="latitude")]
		public System.Nullable<System.Double> Latitude { get; set; }
		
		/// <summary>
		/// The longitude in degrees. It must be in the range [-180.0, +180.0].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="longitude")]
		public System.Nullable<System.Double> Longitude { get; set; }
	}
	
	/// <summary>
	/// Parameters for a product search request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ProductSearchParams
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// The filtering expression. This can be used to restrict search results based on Product labels. We currently support an AND of OR of key-value expressions, where each expression within an OR must have the same key. An '=' should be used to connect the key and value. For example, "(color = red OR color = blue) AND brand = Google" is acceptable, but "(color = red OR brand = Google)" is not acceptable. "color: red" is not acceptable because it uses a ':' instead of an '='.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="filter")]
		public string Filter { get; set; }
		
		/// <summary>
		/// The list of product categories to search in. Currently, we only consider the first category, and either "homegoods-v2", "apparel-v2", "toys-v2", "packagedgoods-v1", or "general-v1" should be specified. The legacy categories "homegoods", "apparel", and "toys" are still supported but will be deprecated. For new products, please use "homegoods-v2", "apparel-v2", or "toys-v2" for better product search accuracy. It is recommended to migrate existing products to these categories as well.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productCategories")]
		public string[] ProductCategories { get; set; }
		
		/// <summary>
		/// The resource name of a ProductSet to be searched for similar images. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productSet")]
		public string ProductSet { get; set; }
	}
	
	/// <summary>
	/// A bounding polygon for the detected image annotation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class BoundingPoly
	{
		
		/// <summary>
		/// The bounding polygon normalized vertices.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="normalizedVertices")]
		public NormalizedVertex[] NormalizedVertices { get; set; }
		
		/// <summary>
		/// The bounding polygon vertices.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="vertices")]
		public Vertex[] Vertices { get; set; }
	}
	
	/// <summary>
	/// A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class NormalizedVertex
	{
		
		/// <summary>
		/// X coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="x")]
		public System.Nullable<System.Single> X { get; set; }
		
		/// <summary>
		/// Y coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="y")]
		public System.Nullable<System.Single> Y { get; set; }
	}
	
	/// <summary>
	/// A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Vertex
	{
		
		/// <summary>
		/// X coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="x")]
		public System.Nullable<System.Int32> X { get; set; }
		
		/// <summary>
		/// Y coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="y")]
		public System.Nullable<System.Int32> Y { get; set; }
	}
	
	/// <summary>
	/// Parameters for text detections. This is used to control TEXT_DETECTION and DOCUMENT_TEXT_DETECTION features.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class TextDetectionParams
	{
		
		/// <summary>
		/// A list of advanced OCR options to further fine-tune OCR behavior. Current valid values are: - `legacy_layout`: a heuristics layout detection algorithm, which serves as an alternative to the current ML-based layout detection algorithm. Customers can choose the best suitable layout algorithm based on their situation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="advancedOcrOptions")]
		public string[] AdvancedOcrOptions { get; set; }
		
		/// <summary>
		/// By default, Cloud Vision API only includes confidence score for DOCUMENT_TEXT_DETECTION result. Set the flag to true to include confidence score for TEXT_DETECTION as well.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="enableTextDetectionConfidenceScore")]
		public System.Nullable<System.Boolean> EnableTextDetectionConfidenceScore { get; set; }
	}
	
	/// <summary>
	/// Parameters for web detection request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class WebDetectionParams
	{
		
		/// <summary>
		/// This field has no effect on results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="includeGeoResults")]
		public System.Nullable<System.Boolean> IncludeGeoResults { get; set; }
	}
	
	/// <summary>
	/// The desired input location and metadata.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class InputConfig
	{
		
		/// <summary>
		/// File content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use a pure binary representation, whereas JSON representations use base64. Currently, this field only works for BatchAnnotateFiles requests. It does not work for AsyncBatchAnnotateFiles requests.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="content")]
		public string Content { get; set; }
		
		/// <summary>
		/// The Google Cloud Storage location where the input will be read from.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="gcsSource")]
		public GcsSource GcsSource { get; set; }
		
		/// <summary>
		/// The type of the file. Currently only "application/pdf", "image/tiff" and "image/gif" are supported. Wildcards are not supported.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mimeType")]
		public string MimeType { get; set; }
	}
	
	/// <summary>
	/// The Google Cloud Storage location where the input will be read from.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GcsSource
	{
		
		/// <summary>
		/// Google Cloud Storage URI for the input file. This must only be a Google Cloud Storage object. Wildcards are not currently supported.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Response to a single file annotation request. A file may contain one or more images, which individually have their own responses.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class AnnotateFileResponse
	{
		
		/// <summary>
		/// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="error")]
		public Status Error { get; set; }
		
		/// <summary>
		/// The desired input location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="inputConfig")]
		public InputConfig InputConfig { get; set; }
		
		/// <summary>
		/// Individual responses to images found within the file. This field will be empty if the `error` field is set.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="responses")]
		public AnnotateImageResponse[] Responses { get; set; }
		
		/// <summary>
		/// This field gives the total number of pages in the file.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="totalPages")]
		public System.Nullable<System.Int32> TotalPages { get; set; }
	}
	
	/// <summary>
	/// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Status
	{
		
		/// <summary>
		/// The status code, which should be an enum value of google.rpc.Code.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="code")]
		public System.Nullable<System.Int32> Code { get; set; }
		
		/// <summary>
		/// A list of messages that carry the error details. There is a common set of message types for APIs to use.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="details")]
		public string[] Details { get; set; }
		
		/// <summary>
		/// A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="message")]
		public string Message { get; set; }
	}
	
	/// <summary>
	/// Response to an image annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class AnnotateImageResponse
	{
		
		/// <summary>
		/// If an image was produced from a file (e.g. a PDF), this message gives information about the source of that image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="context")]
		public ImageAnnotationContext Context { get; set; }
		
		/// <summary>
		/// Set of crop hints that are used to generate new crops when serving images.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="cropHintsAnnotation")]
		public CropHintsAnnotation CropHintsAnnotation { get; set; }
		
		/// <summary>
		/// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="error")]
		public Status Error { get; set; }
		
		/// <summary>
		/// If present, face detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="faceAnnotations")]
		public FaceAnnotation[] FaceAnnotations { get; set; }
		
		/// <summary>
		/// TextAnnotation contains a structured representation of OCR extracted text. The hierarchy of an OCR extracted text structure is like this: TextAnnotation -> Page -> Block -> Paragraph -> Word -> Symbol Each structural component, starting from Page, may further have their own properties. Properties describe detected languages, breaks etc.. Please refer to the TextAnnotation.TextProperty message definition below for more detail.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fullTextAnnotation")]
		public TextAnnotation FullTextAnnotation { get; set; }
		
		/// <summary>
		/// Stores image properties, such as dominant colors.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="imagePropertiesAnnotation")]
		public ImageProperties ImagePropertiesAnnotation { get; set; }
		
		/// <summary>
		/// If present, label detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="labelAnnotations")]
		public EntityAnnotation[] LabelAnnotations { get; set; }
		
		/// <summary>
		/// If present, landmark detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="landmarkAnnotations")]
		public EntityAnnotation[] LandmarkAnnotations { get; set; }
		
		/// <summary>
		/// If present, localized object detection has completed successfully. This will be sorted descending by confidence score.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="localizedObjectAnnotations")]
		public LocalizedObjectAnnotation[] LocalizedObjectAnnotations { get; set; }
		
		/// <summary>
		/// If present, logo detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="logoAnnotations")]
		public EntityAnnotation[] LogoAnnotations { get; set; }
		
		/// <summary>
		/// Results for a product search request.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productSearchResults")]
		public ProductSearchResults ProductSearchResults { get; set; }
		
		/// <summary>
		/// Set of features pertaining to the image, computed by computer vision methods over safe-search verticals (for example, adult, spoof, medical, violence).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="safeSearchAnnotation")]
		public SafeSearchAnnotation SafeSearchAnnotation { get; set; }
		
		/// <summary>
		/// If present, text (OCR) detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="textAnnotations")]
		public EntityAnnotation[] TextAnnotations { get; set; }
		
		/// <summary>
		/// Relevant information for the image from the Internet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="webDetection")]
		public WebDetection WebDetection { get; set; }
	}
	
	/// <summary>
	/// If an image was produced from a file (e.g. a PDF), this message gives information about the source of that image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ImageAnnotationContext
	{
		
		/// <summary>
		/// If the file was a PDF or TIFF, this field gives the page number within the file used to produce the image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pageNumber")]
		public System.Nullable<System.Int32> PageNumber { get; set; }
		
		/// <summary>
		/// The URI of the file used to produce the image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Set of crop hints that are used to generate new crops when serving images.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class CropHintsAnnotation
	{
		
		/// <summary>
		/// Crop hint results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="cropHints")]
		public CropHint[] CropHints { get; set; }
	}
	
	/// <summary>
	/// Single crop hint that is used to generate a new crop when serving an image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class CropHint
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// Confidence of this being a salient region. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Fraction of importance of this salient region with respect to the original image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="importanceFraction")]
		public System.Nullable<System.Single> ImportanceFraction { get; set; }
	}
	
	/// <summary>
	/// A face annotation object contains the results of face detection.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class FaceAnnotation
	{
		
		/// <summary>
		/// Anger likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="angerLikelihood")]
		public System.Nullable<FaceAnnotationAngerLikelihood> AngerLikelihood { get; set; }
		
		/// <summary>
		/// Blurred likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blurredLikelihood")]
		public FaceAnnotationAngerLikelihood BlurredLikelihood { get; set; }
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// Detection confidence. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="detectionConfidence")]
		public System.Nullable<System.Single> DetectionConfidence { get; set; }
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fdBoundingPoly")]
		public BoundingPoly FdBoundingPoly { get; set; }
		
		/// <summary>
		/// Headwear likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="headwearLikelihood")]
		public FaceAnnotationAngerLikelihood HeadwearLikelihood { get; set; }
		
		/// <summary>
		/// Joy likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="joyLikelihood")]
		public FaceAnnotationAngerLikelihood JoyLikelihood { get; set; }
		
		/// <summary>
		/// Face landmarking confidence. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="landmarkingConfidence")]
		public System.Nullable<System.Single> LandmarkingConfidence { get; set; }
		
		/// <summary>
		/// Detected face landmarks.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="landmarks")]
		public Landmark[] Landmarks { get; set; }
		
		/// <summary>
		/// Yaw angle, which indicates the leftward/rightward angle that the face is pointing relative to the vertical plane perpendicular to the image. Range [-180,180].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="panAngle")]
		public System.Nullable<System.Single> PanAngle { get; set; }
		
		/// <summary>
		/// Roll angle, which indicates the amount of clockwise/anti-clockwise rotation of the face relative to the image vertical about the axis perpendicular to the face. Range [-180,180].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="rollAngle")]
		public System.Nullable<System.Single> RollAngle { get; set; }
		
		/// <summary>
		/// Sorrow likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="sorrowLikelihood")]
		public FaceAnnotationAngerLikelihood SorrowLikelihood { get; set; }
		
		/// <summary>
		/// Surprise likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="surpriseLikelihood")]
		public FaceAnnotationAngerLikelihood SurpriseLikelihood { get; set; }
		
		/// <summary>
		/// Pitch angle, which indicates the upwards/downwards angle that the face is pointing relative to the image's horizontal plane. Range [-180,180].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="tiltAngle")]
		public System.Nullable<System.Single> TiltAngle { get; set; }
		
		/// <summary>
		/// Under-exposed likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="underExposedLikelihood")]
		public FaceAnnotationAngerLikelihood UnderExposedLikelihood { get; set; }
	}
	
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public enum FaceAnnotationAngerLikelihood
	{
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		UNKNOWN = 0,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		VERY_UNLIKELY = 1,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		UNLIKELY = 2,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		POSSIBLE = 3,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LIKELY = 4,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		VERY_LIKELY = 5,
	}
	
	/// <summary>
	/// A face-specific landmark (for example, a face feature).
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Landmark
	{
		
		/// <summary>
		/// A 3D position in the image, used primarily for Face detection landmarks. A valid Position must have both x and y coordinates. The position coordinates are in the same scale as the original image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="position")]
		public Position Position { get; set; }
		
		/// <summary>
		/// Face landmark type.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="type")]
		public System.Nullable<LandmarkType> Type { get; set; }
	}
	
	/// <summary>
	/// A 3D position in the image, used primarily for Face detection landmarks. A valid Position must have both x and y coordinates. The position coordinates are in the same scale as the original image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Position
	{
		
		/// <summary>
		/// X coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="x")]
		public System.Nullable<System.Single> X { get; set; }
		
		/// <summary>
		/// Y coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="y")]
		public System.Nullable<System.Single> Y { get; set; }
		
		/// <summary>
		/// Z coordinate (or depth).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="z")]
		public System.Nullable<System.Single> Z { get; set; }
	}
	
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public enum LandmarkType
	{
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		UNKNOWN_LANDMARK = 0,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LEFT_EYE = 1,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		RIGHT_EYE = 2,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LEFT_OF_LEFT_EYEBROW = 3,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		RIGHT_OF_LEFT_EYEBROW = 4,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LEFT_OF_RIGHT_EYEBROW = 5,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		RIGHT_OF_RIGHT_EYEBROW = 6,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		MIDPOINT_BETWEEN_EYES = 7,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		NOSE_TIP = 8,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		UPPER_LIP = 9,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LOWER_LIP = 10,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		MOUTH_LEFT = 11,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		MOUTH_RIGHT = 12,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		MOUTH_CENTER = 13,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		NOSE_BOTTOM_RIGHT = 14,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		NOSE_BOTTOM_LEFT = 15,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		NOSE_BOTTOM_CENTER = 16,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LEFT_EYE_TOP_BOUNDARY = 17,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LEFT_EYE_RIGHT_CORNER = 18,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LEFT_EYE_BOTTOM_BOUNDARY = 19,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LEFT_EYE_LEFT_CORNER = 20,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		RIGHT_EYE_TOP_BOUNDARY = 21,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		RIGHT_EYE_RIGHT_CORNER = 22,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		RIGHT_EYE_BOTTOM_BOUNDARY = 23,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		RIGHT_EYE_LEFT_CORNER = 24,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LEFT_EYEBROW_UPPER_MIDPOINT = 25,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		RIGHT_EYEBROW_UPPER_MIDPOINT = 26,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LEFT_EAR_TRAGION = 27,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		RIGHT_EAR_TRAGION = 28,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LEFT_EYE_PUPIL = 29,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		RIGHT_EYE_PUPIL = 30,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		FOREHEAD_GLABELLA = 31,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		CHIN_GNATHION = 32,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		CHIN_LEFT_GONION = 33,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		CHIN_RIGHT_GONION = 34,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LEFT_CHEEK_CENTER = 35,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		RIGHT_CHEEK_CENTER = 36,
	}
	
	/// <summary>
	/// TextAnnotation contains a structured representation of OCR extracted text. The hierarchy of an OCR extracted text structure is like this: TextAnnotation -> Page -> Block -> Paragraph -> Word -> Symbol Each structural component, starting from Page, may further have their own properties. Properties describe detected languages, breaks etc.. Please refer to the TextAnnotation.TextProperty message definition below for more detail.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class TextAnnotation
	{
		
		/// <summary>
		/// List of pages detected by OCR.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pages")]
		public Page[] Pages { get; set; }
		
		/// <summary>
		/// UTF-8 text detected on the pages.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="text")]
		public string Text { get; set; }
	}
	
	/// <summary>
	/// Detected page from OCR.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Page
	{
		
		/// <summary>
		/// List of blocks of text, images etc on this page.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blocks")]
		public Block[] Blocks { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results on the page. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Page height. For PDFs the unit is points. For images (including TIFFs) the unit is pixels.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="height")]
		public System.Nullable<System.Int32> Height { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public TextProperty Property { get; set; }
		
		/// <summary>
		/// Page width. For PDFs the unit is points. For images (including TIFFs) the unit is pixels.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="width")]
		public System.Nullable<System.Int32> Width { get; set; }
	}
	
	/// <summary>
	/// Logical element on the page.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Block
	{
		
		/// <summary>
		/// Detected block type (text, image etc) for this block.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blockType")]
		public System.Nullable<BlockBlockType> BlockType { get; set; }
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results on the block. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// List of paragraphs in this block (if this blocks is of type text).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="paragraphs")]
		public Paragraph[] Paragraphs { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public TextProperty Property { get; set; }
	}
	
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public enum BlockBlockType
	{
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		UNKNOWN = 0,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		TEXT = 1,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		TABLE = 2,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		PICTURE = 3,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		RULER = 4,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		BARCODE = 5,
	}
	
	/// <summary>
	/// Structural unit of text representing a number of words in certain order.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Paragraph
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results for the paragraph. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public TextProperty Property { get; set; }
		
		/// <summary>
		/// List of all words in this paragraph.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="words")]
		public Word[] Words { get; set; }
	}
	
	/// <summary>
	/// Additional information detected on the structural component.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class TextProperty
	{
		
		/// <summary>
		/// Detected start or end of a structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="detectedBreak")]
		public DetectedBreak DetectedBreak { get; set; }
		
		/// <summary>
		/// A list of detected languages together with confidence.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="detectedLanguages")]
		public DetectedLanguage[] DetectedLanguages { get; set; }
	}
	
	/// <summary>
	/// Detected start or end of a structural component.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class DetectedBreak
	{
		
		/// <summary>
		/// True if break prepends the element.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="isPrefix")]
		public System.Nullable<System.Boolean> IsPrefix { get; set; }
		
		/// <summary>
		/// Detected break type.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="type")]
		public System.Nullable<DetectedBreakType> Type { get; set; }
	}
	
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public enum DetectedBreakType
	{
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		UNKNOWN = 0,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		SPACE = 1,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		SURE_SPACE = 2,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		EOL_SURE_SPACE = 3,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		HYPHEN = 4,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		LINE_BREAK = 5,
	}
	
	/// <summary>
	/// Detected language for a structural component.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class DetectedLanguage
	{
		
		/// <summary>
		/// Confidence of detected language. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
	}
	
	/// <summary>
	/// A word representation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Word
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results for the word. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public TextProperty Property { get; set; }
		
		/// <summary>
		/// List of symbols in the word. The order of the symbols follows the natural reading order.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="symbols")]
		public Symbol[] Symbols { get; set; }
	}
	
	/// <summary>
	/// A single symbol representation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Symbol
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results for the symbol. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public TextProperty Property { get; set; }
		
		/// <summary>
		/// The actual UTF-8 representation of the symbol.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="text")]
		public string Text { get; set; }
	}
	
	/// <summary>
	/// Stores image properties, such as dominant colors.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ImageProperties
	{
		
		/// <summary>
		/// Set of dominant colors and their corresponding scores.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="dominantColors")]
		public DominantColorsAnnotation DominantColors { get; set; }
	}
	
	/// <summary>
	/// Set of dominant colors and their corresponding scores.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class DominantColorsAnnotation
	{
		
		/// <summary>
		/// RGB color values with their score and pixel fraction.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="colors")]
		public ColorInfo[] Colors { get; set; }
	}
	
	/// <summary>
	/// Color information consists of RGB channels, score, and the fraction of the image that the color occupies in the image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ColorInfo
	{
		
		/// <summary>
		/// Represents a color in the RGBA color space. This representation is designed for simplicity of conversion to and from color representations in various languages over compactness. For example, the fields of this representation can be trivially provided to the constructor of `java.awt.Color` in Java; it can also be trivially provided to UIColor's `+colorWithRed:green:blue:alpha` method in iOS; and, with just a little work, it can be easily formatted into a CSS `rgba()` string in JavaScript. This reference page doesn't have information about the absolute color space that should be used to interpret the RGB valueâ€”for example, sRGB, Adobe RGB, DCI-P3, and BT.2020. By default, applications should assume the sRGB color space. When color equality needs to be decided, implementations, unless documented otherwise, treat two colors as equal if all their red, green, blue, and alpha values each differ by at most `1e-5`. Example (Java): import com.google.type.Color; // ... public static java.awt.Color fromProto(Color protocolor) { float alpha = protocolor.hasAlpha() ? protocolor.getAlpha().getValue() : 1.0; return new java.awt.Color( protocolor.getRed(), protocolor.getGreen(), protocolor.getBlue(), alpha); } public static Color toProto(java.awt.Color color) { float red = (float) color.getRed(); float green = (float) color.getGreen(); float blue = (float) color.getBlue(); float denominator = 255.0; Color.Builder resultBuilder = Color .newBuilder() .setRed(red / denominator) .setGreen(green / denominator) .setBlue(blue / denominator); int alpha = color.getAlpha(); if (alpha != 255) { result.setAlpha( FloatValue .newBuilder() .setValue(((float) alpha) / denominator) .build()); } return resultBuilder.build(); } // ... Example (iOS / Obj-C): // ... static UIColor* fromProto(Color* protocolor) { float red = [protocolor red]; float green = [protocolor green]; float blue = [protocolor blue]; FloatValue* alpha_wrapper = [protocolor alpha]; float alpha = 1.0; if (alpha_wrapper != nil) { alpha = [alpha_wrapper value]; } return [UIColor colorWithRed:red green:green blue:blue alpha:alpha]; } static Color* toProto(UIColor* color) { CGFloat red, green, blue, alpha; if (![color getRed:&red green:&green blue:&blue alpha:&alpha]) { return nil; } Color* result = [[Color alloc] init]; [result setRed:red]; [result setGreen:green]; [result setBlue:blue]; if (alpha <= 0.9999) { [result setAlpha:floatWrapperWithValue(alpha)]; } [result autorelease]; return result; } // ... Example (JavaScript): // ... var protoToCssColor = function(rgb_color) { var redFrac = rgb_color.red || 0.0; var greenFrac = rgb_color.green || 0.0; var blueFrac = rgb_color.blue || 0.0; var red = Math.floor(redFrac * 255); var green = Math.floor(greenFrac * 255); var blue = Math.floor(blueFrac * 255); if (!('alpha' in rgb_color)) { return rgbToCssColor(red, green, blue); } var alphaFrac = rgb_color.alpha.value || 0.0; var rgbParams = [red, green, blue].join(','); return ['rgba(', rgbParams, ',', alphaFrac, ')'].join(''); }; var rgbToCssColor = function(red, green, blue) { var rgbNumber = new Number((red << 16) | (green << 8) | blue); var hexString = rgbNumber.toString(16); var missingZeros = 6 - hexString.length; var resultBuilder = ['#']; for (var i = 0; i < missingZeros; i++) { resultBuilder.push('0'); } resultBuilder.push(hexString); return resultBuilder.join(''); }; // ...
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="color")]
		public Color Color { get; set; }
		
		/// <summary>
		/// The fraction of pixels the color occupies in the image. Value in range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pixelFraction")]
		public System.Nullable<System.Single> PixelFraction { get; set; }
		
		/// <summary>
		/// Image-specific score for this color. Value in range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Represents a color in the RGBA color space. This representation is designed for simplicity of conversion to and from color representations in various languages over compactness. For example, the fields of this representation can be trivially provided to the constructor of `java.awt.Color` in Java; it can also be trivially provided to UIColor's `+colorWithRed:green:blue:alpha` method in iOS; and, with just a little work, it can be easily formatted into a CSS `rgba()` string in JavaScript. This reference page doesn't have information about the absolute color space that should be used to interpret the RGB valueâ€”for example, sRGB, Adobe RGB, DCI-P3, and BT.2020. By default, applications should assume the sRGB color space. When color equality needs to be decided, implementations, unless documented otherwise, treat two colors as equal if all their red, green, blue, and alpha values each differ by at most `1e-5`. Example (Java): import com.google.type.Color; // ... public static java.awt.Color fromProto(Color protocolor) { float alpha = protocolor.hasAlpha() ? protocolor.getAlpha().getValue() : 1.0; return new java.awt.Color( protocolor.getRed(), protocolor.getGreen(), protocolor.getBlue(), alpha); } public static Color toProto(java.awt.Color color) { float red = (float) color.getRed(); float green = (float) color.getGreen(); float blue = (float) color.getBlue(); float denominator = 255.0; Color.Builder resultBuilder = Color .newBuilder() .setRed(red / denominator) .setGreen(green / denominator) .setBlue(blue / denominator); int alpha = color.getAlpha(); if (alpha != 255) { result.setAlpha( FloatValue .newBuilder() .setValue(((float) alpha) / denominator) .build()); } return resultBuilder.build(); } // ... Example (iOS / Obj-C): // ... static UIColor* fromProto(Color* protocolor) { float red = [protocolor red]; float green = [protocolor green]; float blue = [protocolor blue]; FloatValue* alpha_wrapper = [protocolor alpha]; float alpha = 1.0; if (alpha_wrapper != nil) { alpha = [alpha_wrapper value]; } return [UIColor colorWithRed:red green:green blue:blue alpha:alpha]; } static Color* toProto(UIColor* color) { CGFloat red, green, blue, alpha; if (![color getRed:&red green:&green blue:&blue alpha:&alpha]) { return nil; } Color* result = [[Color alloc] init]; [result setRed:red]; [result setGreen:green]; [result setBlue:blue]; if (alpha <= 0.9999) { [result setAlpha:floatWrapperWithValue(alpha)]; } [result autorelease]; return result; } // ... Example (JavaScript): // ... var protoToCssColor = function(rgb_color) { var redFrac = rgb_color.red || 0.0; var greenFrac = rgb_color.green || 0.0; var blueFrac = rgb_color.blue || 0.0; var red = Math.floor(redFrac * 255); var green = Math.floor(greenFrac * 255); var blue = Math.floor(blueFrac * 255); if (!('alpha' in rgb_color)) { return rgbToCssColor(red, green, blue); } var alphaFrac = rgb_color.alpha.value || 0.0; var rgbParams = [red, green, blue].join(','); return ['rgba(', rgbParams, ',', alphaFrac, ')'].join(''); }; var rgbToCssColor = function(red, green, blue) { var rgbNumber = new Number((red << 16) | (green << 8) | blue); var hexString = rgbNumber.toString(16); var missingZeros = 6 - hexString.length; var resultBuilder = ['#']; for (var i = 0; i < missingZeros; i++) { resultBuilder.push('0'); } resultBuilder.push(hexString); return resultBuilder.join(''); }; // ...
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Color
	{
		
		/// <summary>
		/// The fraction of this color that should be applied to the pixel. That is, the final pixel color is defined by the equation: `pixel color = alpha * (this color) + (1.0 - alpha) * (background color)` This means that a value of 1.0 corresponds to a solid color, whereas a value of 0.0 corresponds to a completely transparent color. This uses a wrapper message rather than a simple float scalar so that it is possible to distinguish between a default value and the value being unset. If omitted, this color object is rendered as a solid color (as if the alpha value had been explicitly given a value of 1.0).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="alpha")]
		public System.Nullable<System.Single> Alpha { get; set; }
		
		/// <summary>
		/// The amount of blue in the color as a value in the interval [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blue")]
		public System.Nullable<System.Single> Blue { get; set; }
		
		/// <summary>
		/// The amount of green in the color as a value in the interval [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="green")]
		public System.Nullable<System.Single> Green { get; set; }
		
		/// <summary>
		/// The amount of red in the color as a value in the interval [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="red")]
		public System.Nullable<System.Single> Red { get; set; }
	}
	
	/// <summary>
	/// Set of detected entity features.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class EntityAnnotation
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// **Deprecated. Use `score` instead.** The accuracy of the entity detection in an image. For example, for an image in which the "Eiffel Tower" entity is detected, this field represents the confidence that there is a tower in the query image. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Entity textual description, expressed in its `locale` language.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// The language code for the locale in which the entity textual `description` is expressed.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="locale")]
		public string Locale { get; set; }
		
		/// <summary>
		/// The location information for the detected entity. Multiple `LocationInfo` elements can be present because one location may indicate the location of the scene in the image, and another location may indicate the location of the place where the image was taken. Location information is usually present for landmarks.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="locations")]
		public LocationInfo[] Locations { get; set; }
		
		/// <summary>
		/// Opaque entity ID. Some IDs may be available in [Google Knowledge Graph Search API](https://developers.google.com/knowledge-graph/).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mid")]
		public string Mid { get; set; }
		
		/// <summary>
		/// Some entities may have optional user-supplied `Property` (name/value) fields, such a score or string that qualifies the entity.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="properties")]
		public Property[] Properties { get; set; }
		
		/// <summary>
		/// Overall score of the result. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
		
		/// <summary>
		/// The relevancy of the ICA (Image Content Annotation) label to the image. For example, the relevancy of "tower" is likely higher to an image containing the detected "Eiffel Tower" than to an image containing a detected distant towering building, even though the confidence that there is a tower in each image may be the same. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="topicality")]
		public System.Nullable<System.Single> Topicality { get; set; }
	}
	
	/// <summary>
	/// Detected entity location information.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class LocationInfo
	{
		
		/// <summary>
		/// An object that represents a latitude/longitude pair. This is expressed as a pair of doubles to represent degrees latitude and degrees longitude. Unless specified otherwise, this object must conform to the WGS84 standard. Values must be within normalized ranges.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="latLng")]
		public LatLng LatLng { get; set; }
	}
	
	/// <summary>
	/// A `Property` consists of a user-supplied name/value pair.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Property
	{
		
		/// <summary>
		/// Name of the property.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Value of numeric properties.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uint64Value")]
		public string Uint64Value { get; set; }
		
		/// <summary>
		/// Value of the property.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="value")]
		public string Value { get; set; }
	}
	
	/// <summary>
	/// Set of detected objects with bounding boxes.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class LocalizedObjectAnnotation
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
		
		/// <summary>
		/// Object ID that should align with EntityAnnotation mid.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mid")]
		public string Mid { get; set; }
		
		/// <summary>
		/// Object name, expressed in its `language_code` language.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Score of the result. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Results for a product search request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ProductSearchResults
	{
		
		/// <summary>
		/// Timestamp of the index which provided these results. Products added to the product set and products removed from the product set after this time are not reflected in the current results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="indexTime")]
		public string IndexTime { get; set; }
		
		/// <summary>
		/// List of results grouped by products detected in the query image. Each entry corresponds to one bounding polygon in the query image, and contains the matching products specific to that region. There may be duplicate product matches in the union of all the per-product results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productGroupedResults")]
		public GroupedResult[] ProductGroupedResults { get; set; }
		
		/// <summary>
		/// List of results, one for each product match.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="results")]
		public Result[] Results { get; set; }
	}
	
	/// <summary>
	/// Information about the products similar to a single product in a query image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GroupedResult
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// List of generic predictions for the object in the bounding box.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="objectAnnotations")]
		public ObjectAnnotation[] ObjectAnnotations { get; set; }
		
		/// <summary>
		/// List of results, one for each product match.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="results")]
		public Result[] Results { get; set; }
	}
	
	/// <summary>
	/// Prediction for what the object in the bounding box is.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ObjectAnnotation
	{
		
		/// <summary>
		/// The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
		
		/// <summary>
		/// Object ID that should align with EntityAnnotation mid.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mid")]
		public string Mid { get; set; }
		
		/// <summary>
		/// Object name, expressed in its `language_code` language.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Score of the result. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Information about a product.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Result
	{
		
		/// <summary>
		/// The resource name of the image from the product that is the closest match to the query.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="image")]
		public string Image { get; set; }
		
		/// <summary>
		/// A Product contains ReferenceImages.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="product")]
		public Product Product { get; set; }
		
		/// <summary>
		/// A confidence level on the match, ranging from 0 (no confidence) to 1 (full confidence).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// A Product contains ReferenceImages.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Product
	{
		
		/// <summary>
		/// User-provided metadata to be stored with this product. Must be at most 4096 characters long.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// The user-provided name for this Product. Must not be empty. Must be at most 4096 characters long.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="displayName")]
		public string DisplayName { get; set; }
		
		/// <summary>
		/// The resource name of the product. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID`. This field is ignored when creating a product.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Immutable. The category for the product identified by the reference image. This should be one of "homegoods-v2", "apparel-v2", "toys-v2", "packagedgoods-v1" or "general-v1". The legacy categories "homegoods", "apparel", and "toys" are still supported, but these should not be used for new products.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productCategory")]
		public string ProductCategory { get; set; }
		
		/// <summary>
		/// Key-value pairs that can be attached to a product. At query time, constraints can be specified based on the product_labels. Note that integer values can be provided as strings, e.g. "1199". Only strings with integer values can match a range-based restriction which is to be supported soon. Multiple values can be assigned to the same key. One product may have up to 500 product_labels. Notice that the total number of distinct product_labels over all products in one ProductSet cannot exceed 1M, otherwise the product search pipeline will refuse to work for that ProductSet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productLabels")]
		public KeyValue[] ProductLabels { get; set; }
	}
	
	/// <summary>
	/// A product label represented as a key-value pair.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class KeyValue
	{
		
		/// <summary>
		/// The key of the label attached to the product. Cannot be empty and cannot exceed 128 bytes.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="key")]
		public string Key { get; set; }
		
		/// <summary>
		/// The value of the label attached to the product. Cannot be empty and cannot exceed 128 bytes.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="value")]
		public string Value { get; set; }
	}
	
	/// <summary>
	/// Set of features pertaining to the image, computed by computer vision methods over safe-search verticals (for example, adult, spoof, medical, violence).
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class SafeSearchAnnotation
	{
		
		/// <summary>
		/// Represents the adult content likelihood for the image. Adult content may contain elements such as nudity, pornographic images or cartoons, or sexual activities.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="adult")]
		public FaceAnnotationAngerLikelihood Adult { get; set; }
		
		/// <summary>
		/// Likelihood that this is a medical image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="medical")]
		public FaceAnnotationAngerLikelihood Medical { get; set; }
		
		/// <summary>
		/// Likelihood that the request image contains racy content. Racy content may include (but is not limited to) skimpy or sheer clothing, strategically covered nudity, lewd or provocative poses, or close-ups of sensitive body areas.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="racy")]
		public FaceAnnotationAngerLikelihood Racy { get; set; }
		
		/// <summary>
		/// Spoof likelihood. The likelihood that an modification was made to the image's canonical version to make it appear funny or offensive.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="spoof")]
		public FaceAnnotationAngerLikelihood Spoof { get; set; }
		
		/// <summary>
		/// Likelihood that this image contains violent content. Violent content may include death, serious harm, or injury to individuals or groups of individuals.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="violence")]
		public FaceAnnotationAngerLikelihood Violence { get; set; }
	}
	
	/// <summary>
	/// Relevant information for the image from the Internet.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class WebDetection
	{
		
		/// <summary>
		/// The service's best guess as to the topic of the request image. Inferred from similar images on the open web.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="bestGuessLabels")]
		public WebLabel[] BestGuessLabels { get; set; }
		
		/// <summary>
		/// Fully matching images from the Internet. Can include resized copies of the query image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fullMatchingImages")]
		public WebImage[] FullMatchingImages { get; set; }
		
		/// <summary>
		/// Web pages containing the matching images from the Internet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pagesWithMatchingImages")]
		public WebPage[] PagesWithMatchingImages { get; set; }
		
		/// <summary>
		/// Partial matching images from the Internet. Those images are similar enough to share some key-point features. For example an original image will likely have partial matching for its crops.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="partialMatchingImages")]
		public WebImage[] PartialMatchingImages { get; set; }
		
		/// <summary>
		/// The visually similar image results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="visuallySimilarImages")]
		public WebImage[] VisuallySimilarImages { get; set; }
		
		/// <summary>
		/// Deduced entities from similar images on the Internet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="webEntities")]
		public WebEntity[] WebEntities { get; set; }
	}
	
	/// <summary>
	/// Label to provide extra metadata for the web detection.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class WebLabel
	{
		
		/// <summary>
		/// Label for extra metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="label")]
		public string Label { get; set; }
		
		/// <summary>
		/// The BCP-47 language code for `label`, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
	}
	
	/// <summary>
	/// Metadata for online images.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class WebImage
	{
		
		/// <summary>
		/// (Deprecated) Overall relevancy score for the image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
		
		/// <summary>
		/// The result image URL.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="url")]
		public string Url { get; set; }
	}
	
	/// <summary>
	/// Metadata for web pages.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class WebPage
	{
		
		/// <summary>
		/// Fully matching images on the page. Can include resized copies of the query image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fullMatchingImages")]
		public WebImage[] FullMatchingImages { get; set; }
		
		/// <summary>
		/// Title for the web page, may contain HTML markups.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pageTitle")]
		public string PageTitle { get; set; }
		
		/// <summary>
		/// Partial matching images on the page. Those images are similar enough to share some key-point features. For example an original image will likely have partial matching for its crops.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="partialMatchingImages")]
		public WebImage[] PartialMatchingImages { get; set; }
		
		/// <summary>
		/// (Deprecated) Overall relevancy score for the web page.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
		
		/// <summary>
		/// The result web page URL.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="url")]
		public string Url { get; set; }
	}
	
	/// <summary>
	/// Entity deduced from similar images on the Internet.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class WebEntity
	{
		
		/// <summary>
		/// Canonical description of the entity, in English.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// Opaque entity ID.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="entityId")]
		public string EntityId { get; set; }
		
		/// <summary>
		/// Overall relevancy score for the entity. Not normalized and not comparable across different image queries.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Request for performing Google Cloud Vision API tasks over a user-provided image, with user-requested features, and with context information.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class AnnotateImageRequest
	{
		
		/// <summary>
		/// Requested features.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="features")]
		public Feature[] Features { get; set; }
		
		/// <summary>
		/// Client image to perform Google Cloud Vision API tasks over.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="image")]
		public Image Image { get; set; }
		
		/// <summary>
		/// Image context and/or feature-specific parameters.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="imageContext")]
		public ImageContext ImageContext { get; set; }
	}
	
	/// <summary>
	/// Client image to perform Google Cloud Vision API tasks over.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Image
	{
		
		/// <summary>
		/// Image content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use a pure binary representation, whereas JSON representations use base64. Currently, this field only works for BatchAnnotateImages requests. It does not work for AsyncBatchAnnotateImages requests.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="content")]
		public string Content { get; set; }
		
		/// <summary>
		/// External image source (Google Cloud Storage or web URL image location).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="source")]
		public ImageSource Source { get; set; }
	}
	
	/// <summary>
	/// External image source (Google Cloud Storage or web URL image location).
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ImageSource
	{
		
		/// <summary>
		/// **Use `image_uri` instead.** The Google Cloud Storage URI of the form `gs://bucket_name/object_name`. Object versioning is not supported. See [Google Cloud Storage Request URIs](https://cloud.google.com/storage/docs/reference-uris) for more info.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="gcsImageUri")]
		public string GcsImageUri { get; set; }
		
		/// <summary>
		/// The URI of the source image. Can be either: 1. A Google Cloud Storage URI of the form `gs://bucket_name/object_name`. Object versioning is not supported. See [Google Cloud Storage Request URIs](https://cloud.google.com/storage/docs/reference-uris) for more info. 2. A publicly-accessible image HTTP/HTTPS URL. When fetching images from HTTP/HTTPS URLs, Google cannot guarantee that the request will be completed. Your request may fail if the specified host denies the request (e.g. due to request throttling or DOS prevention), or if Google throttles requests to the site for abuse prevention. You should not depend on externally-hosted images for production applications. When both `gcs_image_uri` and `image_uri` are specified, `image_uri` takes precedence.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="imageUri")]
		public string ImageUri { get; set; }
	}
	
	/// <summary>
	/// An offline file annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class AsyncAnnotateFileRequest
	{
		
		/// <summary>
		/// Required. Requested features.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="features")]
		public Feature[] Features { get; set; }
		
		/// <summary>
		/// Image context and/or feature-specific parameters.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="imageContext")]
		public ImageContext ImageContext { get; set; }
		
		/// <summary>
		/// The desired input location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="inputConfig")]
		public InputConfig InputConfig { get; set; }
		
		/// <summary>
		/// The desired output location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="outputConfig")]
		public OutputConfig OutputConfig { get; set; }
	}
	
	/// <summary>
	/// The desired output location and metadata.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class OutputConfig
	{
		
		/// <summary>
		/// The max number of response protos to put into each output JSON file on Google Cloud Storage. The valid range is [1, 100]. If not specified, the default value is 20. For example, for one pdf file with 100 pages, 100 response protos will be generated. If `batch_size` = 20, then 5 json files each containing 20 response protos will be written under the prefix `gcs_destination`.`uri`. Currently, batch_size only applies to GcsDestination, with potential future support for other output configurations.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="batchSize")]
		public System.Nullable<System.Int32> BatchSize { get; set; }
		
		/// <summary>
		/// The Google Cloud Storage location where the output will be written to.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="gcsDestination")]
		public GcsDestination GcsDestination { get; set; }
	}
	
	/// <summary>
	/// The Google Cloud Storage location where the output will be written to.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GcsDestination
	{
		
		/// <summary>
		/// Google Cloud Storage URI prefix where the results will be stored. Results will be in JSON format and preceded by its corresponding input URI prefix. This field can either represent a gcs file prefix or gcs directory. In either case, the uri should be unique because in order to get all of the output files, you will need to do a wildcard gcs search on the uri prefix you provide. Examples: * File Prefix: gs://bucket-name/here/filenameprefix The output files will be created in gs://bucket-name/here/ and the names of the output files will begin with "filenameprefix". * Directory Prefix: gs://bucket-name/some/location/ The output files will be created in gs://bucket-name/some/location/ and the names of the output files could be anything because there was no filename prefix specified. If multiple outputs, each response is still AnnotateFileResponse, each of which contains some subset of the full list of AnnotateImageResponse. Multiple outputs can happen if, for example, the output JSON is too large and overflows into multiple sharded files.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// The response for a single offline file annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class AsyncAnnotateFileResponse
	{
		
		/// <summary>
		/// The desired output location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="outputConfig")]
		public OutputConfig OutputConfig { get; set; }
	}
	
	/// <summary>
	/// Multiple async file annotation requests are batched into a single service call.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class AsyncBatchAnnotateFilesRequest
	{
		
		/// <summary>
		/// Optional. The labels with user-defined metadata for the request. Label keys and values can be no longer than 63 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. Label values are optional. Label keys must start with a letter.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="labels")]
		public System.Collections.Generic.Dictionary<string, string> Labels { get; set; }
		
		/// <summary>
		/// Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="parent")]
		public string Parent { get; set; }
		
		/// <summary>
		/// Required. Individual async file annotation requests for this batch.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="requests")]
		public AsyncAnnotateFileRequest[] Requests { get; set; }
	}
	
	/// <summary>
	/// Response to an async batch file annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class AsyncBatchAnnotateFilesResponse
	{
		
		/// <summary>
		/// The list of file annotation responses, one for each request in AsyncBatchAnnotateFilesRequest.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="responses")]
		public AsyncAnnotateFileResponse[] Responses { get; set; }
	}
	
	/// <summary>
	/// Request for async image annotation for a list of images.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class AsyncBatchAnnotateImagesRequest
	{
		
		/// <summary>
		/// Optional. The labels with user-defined metadata for the request. Label keys and values can be no longer than 63 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. Label values are optional. Label keys must start with a letter.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="labels")]
		public System.Collections.Generic.Dictionary<string, string> Labels { get; set; }
		
		/// <summary>
		/// The desired output location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="outputConfig")]
		public OutputConfig OutputConfig { get; set; }
		
		/// <summary>
		/// Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="parent")]
		public string Parent { get; set; }
		
		/// <summary>
		/// Required. Individual image annotation requests for this batch.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="requests")]
		public AnnotateImageRequest[] Requests { get; set; }
	}
	
	/// <summary>
	/// Response to an async batch image annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class AsyncBatchAnnotateImagesResponse
	{
		
		/// <summary>
		/// The desired output location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="outputConfig")]
		public OutputConfig OutputConfig { get; set; }
	}
	
	/// <summary>
	/// A list of requests to annotate files using the BatchAnnotateFiles API.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class BatchAnnotateFilesRequest
	{
		
		/// <summary>
		/// Optional. The labels with user-defined metadata for the request. Label keys and values can be no longer than 63 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. Label values are optional. Label keys must start with a letter.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="labels")]
		public System.Collections.Generic.Dictionary<string, string> Labels { get; set; }
		
		/// <summary>
		/// Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="parent")]
		public string Parent { get; set; }
		
		/// <summary>
		/// Required. The list of file annotation requests. Right now we support only one AnnotateFileRequest in BatchAnnotateFilesRequest.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="requests")]
		public AnnotateFileRequest[] Requests { get; set; }
	}
	
	/// <summary>
	/// A list of file annotation responses.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class BatchAnnotateFilesResponse
	{
		
		/// <summary>
		/// The list of file annotation responses, each response corresponding to each AnnotateFileRequest in BatchAnnotateFilesRequest.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="responses")]
		public AnnotateFileResponse[] Responses { get; set; }
	}
	
	/// <summary>
	/// Multiple image annotation requests are batched into a single service call.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class BatchAnnotateImagesRequest
	{
		
		/// <summary>
		/// Optional. The labels with user-defined metadata for the request. Label keys and values can be no longer than 63 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. Label values are optional. Label keys must start with a letter.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="labels")]
		public System.Collections.Generic.Dictionary<string, string> Labels { get; set; }
		
		/// <summary>
		/// Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="parent")]
		public string Parent { get; set; }
		
		/// <summary>
		/// Required. Individual image annotation requests for this batch.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="requests")]
		public AnnotateImageRequest[] Requests { get; set; }
	}
	
	/// <summary>
	/// Response to a batch image annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class BatchAnnotateImagesResponse
	{
		
		/// <summary>
		/// Individual responses to image annotation requests within the batch.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="responses")]
		public AnnotateImageResponse[] Responses { get; set; }
	}
	
	/// <summary>
	/// Metadata for the batch operations such as the current state. This is included in the `metadata` field of the `Operation` returned by the `GetOperation` call of the `google::longrunning::Operations` service.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class BatchOperationMetadata
	{
		
		/// <summary>
		/// The time when the batch request is finished and google.longrunning.Operation.done is set to true.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="endTime")]
		public string EndTime { get; set; }
		
		/// <summary>
		/// The current state of the batch operation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="state")]
		public System.Nullable<BatchOperationMetadataState> State { get; set; }
		
		/// <summary>
		/// The time when the batch request was submitted to the server.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="submitTime")]
		public string SubmitTime { get; set; }
	}
	
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public enum BatchOperationMetadataState
	{
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		STATE_UNSPECIFIED = 0,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		PROCESSING = 1,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		SUCCESSFUL = 2,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		FAILED = 3,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		CANCELLED = 4,
	}
	
	/// <summary>
	/// The request message for Operations.CancelOperation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class CancelOperationRequest
	{
	}
	
	/// <summary>
	/// A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); }
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Empty
	{
	}
	
	/// <summary>
	/// Response to a single file annotation request. A file may contain one or more images, which individually have their own responses.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1AnnotateFileResponse
	{
		
		/// <summary>
		/// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="error")]
		public Status Error { get; set; }
		
		/// <summary>
		/// The desired input location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="inputConfig")]
		public GoogleCloudVisionV1p1beta1InputConfig InputConfig { get; set; }
		
		/// <summary>
		/// Individual responses to images found within the file. This field will be empty if the `error` field is set.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="responses")]
		public GoogleCloudVisionV1p1beta1AnnotateImageResponse[] Responses { get; set; }
		
		/// <summary>
		/// This field gives the total number of pages in the file.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="totalPages")]
		public System.Nullable<System.Int32> TotalPages { get; set; }
	}
	
	/// <summary>
	/// The desired input location and metadata.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1InputConfig
	{
		
		/// <summary>
		/// File content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use a pure binary representation, whereas JSON representations use base64. Currently, this field only works for BatchAnnotateFiles requests. It does not work for AsyncBatchAnnotateFiles requests.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="content")]
		public string Content { get; set; }
		
		/// <summary>
		/// The Google Cloud Storage location where the input will be read from.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="gcsSource")]
		public GoogleCloudVisionV1p1beta1GcsSource GcsSource { get; set; }
		
		/// <summary>
		/// The type of the file. Currently only "application/pdf", "image/tiff" and "image/gif" are supported. Wildcards are not supported.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mimeType")]
		public string MimeType { get; set; }
	}
	
	/// <summary>
	/// The Google Cloud Storage location where the input will be read from.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1GcsSource
	{
		
		/// <summary>
		/// Google Cloud Storage URI for the input file. This must only be a Google Cloud Storage object. Wildcards are not currently supported.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Response to an image annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1AnnotateImageResponse
	{
		
		/// <summary>
		/// If an image was produced from a file (e.g. a PDF), this message gives information about the source of that image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="context")]
		public GoogleCloudVisionV1p1beta1ImageAnnotationContext Context { get; set; }
		
		/// <summary>
		/// Set of crop hints that are used to generate new crops when serving images.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="cropHintsAnnotation")]
		public GoogleCloudVisionV1p1beta1CropHintsAnnotation CropHintsAnnotation { get; set; }
		
		/// <summary>
		/// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="error")]
		public Status Error { get; set; }
		
		/// <summary>
		/// If present, face detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="faceAnnotations")]
		public GoogleCloudVisionV1p1beta1FaceAnnotation[] FaceAnnotations { get; set; }
		
		/// <summary>
		/// TextAnnotation contains a structured representation of OCR extracted text. The hierarchy of an OCR extracted text structure is like this: TextAnnotation -> Page -> Block -> Paragraph -> Word -> Symbol Each structural component, starting from Page, may further have their own properties. Properties describe detected languages, breaks etc.. Please refer to the TextAnnotation.TextProperty message definition below for more detail.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fullTextAnnotation")]
		public GoogleCloudVisionV1p1beta1TextAnnotation FullTextAnnotation { get; set; }
		
		/// <summary>
		/// Stores image properties, such as dominant colors.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="imagePropertiesAnnotation")]
		public GoogleCloudVisionV1p1beta1ImageProperties ImagePropertiesAnnotation { get; set; }
		
		/// <summary>
		/// If present, label detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="labelAnnotations")]
		public GoogleCloudVisionV1p1beta1EntityAnnotation[] LabelAnnotations { get; set; }
		
		/// <summary>
		/// If present, landmark detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="landmarkAnnotations")]
		public GoogleCloudVisionV1p1beta1EntityAnnotation[] LandmarkAnnotations { get; set; }
		
		/// <summary>
		/// If present, localized object detection has completed successfully. This will be sorted descending by confidence score.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="localizedObjectAnnotations")]
		public GoogleCloudVisionV1p1beta1LocalizedObjectAnnotation[] LocalizedObjectAnnotations { get; set; }
		
		/// <summary>
		/// If present, logo detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="logoAnnotations")]
		public GoogleCloudVisionV1p1beta1EntityAnnotation[] LogoAnnotations { get; set; }
		
		/// <summary>
		/// Results for a product search request.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productSearchResults")]
		public GoogleCloudVisionV1p1beta1ProductSearchResults ProductSearchResults { get; set; }
		
		/// <summary>
		/// Set of features pertaining to the image, computed by computer vision methods over safe-search verticals (for example, adult, spoof, medical, violence).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="safeSearchAnnotation")]
		public GoogleCloudVisionV1p1beta1SafeSearchAnnotation SafeSearchAnnotation { get; set; }
		
		/// <summary>
		/// If present, text (OCR) detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="textAnnotations")]
		public GoogleCloudVisionV1p1beta1EntityAnnotation[] TextAnnotations { get; set; }
		
		/// <summary>
		/// Relevant information for the image from the Internet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="webDetection")]
		public GoogleCloudVisionV1p1beta1WebDetection WebDetection { get; set; }
	}
	
	/// <summary>
	/// If an image was produced from a file (e.g. a PDF), this message gives information about the source of that image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1ImageAnnotationContext
	{
		
		/// <summary>
		/// If the file was a PDF or TIFF, this field gives the page number within the file used to produce the image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pageNumber")]
		public System.Nullable<System.Int32> PageNumber { get; set; }
		
		/// <summary>
		/// The URI of the file used to produce the image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Set of crop hints that are used to generate new crops when serving images.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1CropHintsAnnotation
	{
		
		/// <summary>
		/// Crop hint results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="cropHints")]
		public GoogleCloudVisionV1p1beta1CropHint[] CropHints { get; set; }
	}
	
	/// <summary>
	/// Single crop hint that is used to generate a new crop when serving an image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1CropHint
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p1beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// Confidence of this being a salient region. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Fraction of importance of this salient region with respect to the original image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="importanceFraction")]
		public System.Nullable<System.Single> ImportanceFraction { get; set; }
	}
	
	/// <summary>
	/// A bounding polygon for the detected image annotation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1BoundingPoly
	{
		
		/// <summary>
		/// The bounding polygon normalized vertices.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="normalizedVertices")]
		public GoogleCloudVisionV1p1beta1NormalizedVertex[] NormalizedVertices { get; set; }
		
		/// <summary>
		/// The bounding polygon vertices.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="vertices")]
		public GoogleCloudVisionV1p1beta1Vertex[] Vertices { get; set; }
	}
	
	/// <summary>
	/// A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1NormalizedVertex
	{
		
		/// <summary>
		/// X coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="x")]
		public System.Nullable<System.Single> X { get; set; }
		
		/// <summary>
		/// Y coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="y")]
		public System.Nullable<System.Single> Y { get; set; }
	}
	
	/// <summary>
	/// A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1Vertex
	{
		
		/// <summary>
		/// X coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="x")]
		public System.Nullable<System.Int32> X { get; set; }
		
		/// <summary>
		/// Y coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="y")]
		public System.Nullable<System.Int32> Y { get; set; }
	}
	
	/// <summary>
	/// A face annotation object contains the results of face detection.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1FaceAnnotation
	{
		
		/// <summary>
		/// Anger likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="angerLikelihood")]
		public FaceAnnotationAngerLikelihood AngerLikelihood { get; set; }
		
		/// <summary>
		/// Blurred likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blurredLikelihood")]
		public FaceAnnotationAngerLikelihood BlurredLikelihood { get; set; }
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p1beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// Detection confidence. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="detectionConfidence")]
		public System.Nullable<System.Single> DetectionConfidence { get; set; }
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fdBoundingPoly")]
		public GoogleCloudVisionV1p1beta1BoundingPoly FdBoundingPoly { get; set; }
		
		/// <summary>
		/// Headwear likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="headwearLikelihood")]
		public FaceAnnotationAngerLikelihood HeadwearLikelihood { get; set; }
		
		/// <summary>
		/// Joy likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="joyLikelihood")]
		public FaceAnnotationAngerLikelihood JoyLikelihood { get; set; }
		
		/// <summary>
		/// Face landmarking confidence. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="landmarkingConfidence")]
		public System.Nullable<System.Single> LandmarkingConfidence { get; set; }
		
		/// <summary>
		/// Detected face landmarks.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="landmarks")]
		public GoogleCloudVisionV1p1beta1FaceAnnotationLandmark[] Landmarks { get; set; }
		
		/// <summary>
		/// Yaw angle, which indicates the leftward/rightward angle that the face is pointing relative to the vertical plane perpendicular to the image. Range [-180,180].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="panAngle")]
		public System.Nullable<System.Single> PanAngle { get; set; }
		
		/// <summary>
		/// Roll angle, which indicates the amount of clockwise/anti-clockwise rotation of the face relative to the image vertical about the axis perpendicular to the face. Range [-180,180].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="rollAngle")]
		public System.Nullable<System.Single> RollAngle { get; set; }
		
		/// <summary>
		/// Sorrow likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="sorrowLikelihood")]
		public FaceAnnotationAngerLikelihood SorrowLikelihood { get; set; }
		
		/// <summary>
		/// Surprise likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="surpriseLikelihood")]
		public FaceAnnotationAngerLikelihood SurpriseLikelihood { get; set; }
		
		/// <summary>
		/// Pitch angle, which indicates the upwards/downwards angle that the face is pointing relative to the image's horizontal plane. Range [-180,180].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="tiltAngle")]
		public System.Nullable<System.Single> TiltAngle { get; set; }
		
		/// <summary>
		/// Under-exposed likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="underExposedLikelihood")]
		public FaceAnnotationAngerLikelihood UnderExposedLikelihood { get; set; }
	}
	
	/// <summary>
	/// A face-specific landmark (for example, a face feature).
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1FaceAnnotationLandmark
	{
		
		/// <summary>
		/// A 3D position in the image, used primarily for Face detection landmarks. A valid Position must have both x and y coordinates. The position coordinates are in the same scale as the original image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="position")]
		public GoogleCloudVisionV1p1beta1Position Position { get; set; }
		
		/// <summary>
		/// Face landmark type.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="type")]
		public LandmarkType Type { get; set; }
	}
	
	/// <summary>
	/// A 3D position in the image, used primarily for Face detection landmarks. A valid Position must have both x and y coordinates. The position coordinates are in the same scale as the original image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1Position
	{
		
		/// <summary>
		/// X coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="x")]
		public System.Nullable<System.Single> X { get; set; }
		
		/// <summary>
		/// Y coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="y")]
		public System.Nullable<System.Single> Y { get; set; }
		
		/// <summary>
		/// Z coordinate (or depth).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="z")]
		public System.Nullable<System.Single> Z { get; set; }
	}
	
	/// <summary>
	/// TextAnnotation contains a structured representation of OCR extracted text. The hierarchy of an OCR extracted text structure is like this: TextAnnotation -> Page -> Block -> Paragraph -> Word -> Symbol Each structural component, starting from Page, may further have their own properties. Properties describe detected languages, breaks etc.. Please refer to the TextAnnotation.TextProperty message definition below for more detail.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1TextAnnotation
	{
		
		/// <summary>
		/// List of pages detected by OCR.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pages")]
		public GoogleCloudVisionV1p1beta1Page[] Pages { get; set; }
		
		/// <summary>
		/// UTF-8 text detected on the pages.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="text")]
		public string Text { get; set; }
	}
	
	/// <summary>
	/// Detected page from OCR.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1Page
	{
		
		/// <summary>
		/// List of blocks of text, images etc on this page.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blocks")]
		public GoogleCloudVisionV1p1beta1Block[] Blocks { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results on the page. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Page height. For PDFs the unit is points. For images (including TIFFs) the unit is pixels.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="height")]
		public System.Nullable<System.Int32> Height { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p1beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// Page width. For PDFs the unit is points. For images (including TIFFs) the unit is pixels.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="width")]
		public System.Nullable<System.Int32> Width { get; set; }
	}
	
	/// <summary>
	/// Logical element on the page.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1Block
	{
		
		/// <summary>
		/// Detected block type (text, image etc) for this block.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blockType")]
		public BlockBlockType BlockType { get; set; }
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p1beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results on the block. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// List of paragraphs in this block (if this blocks is of type text).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="paragraphs")]
		public GoogleCloudVisionV1p1beta1Paragraph[] Paragraphs { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p1beta1TextAnnotationTextProperty Property { get; set; }
	}
	
	/// <summary>
	/// Structural unit of text representing a number of words in certain order.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1Paragraph
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p1beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results for the paragraph. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p1beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// List of all words in this paragraph.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="words")]
		public GoogleCloudVisionV1p1beta1Word[] Words { get; set; }
	}
	
	/// <summary>
	/// Additional information detected on the structural component.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1TextAnnotationTextProperty
	{
		
		/// <summary>
		/// Detected start or end of a structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="detectedBreak")]
		public GoogleCloudVisionV1p1beta1TextAnnotationDetectedBreak DetectedBreak { get; set; }
		
		/// <summary>
		/// A list of detected languages together with confidence.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="detectedLanguages")]
		public GoogleCloudVisionV1p1beta1TextAnnotationDetectedLanguage[] DetectedLanguages { get; set; }
	}
	
	/// <summary>
	/// Detected start or end of a structural component.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1TextAnnotationDetectedBreak
	{
		
		/// <summary>
		/// True if break prepends the element.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="isPrefix")]
		public System.Nullable<System.Boolean> IsPrefix { get; set; }
		
		/// <summary>
		/// Detected break type.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="type")]
		public DetectedBreakType Type { get; set; }
	}
	
	/// <summary>
	/// Detected language for a structural component.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1TextAnnotationDetectedLanguage
	{
		
		/// <summary>
		/// Confidence of detected language. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
	}
	
	/// <summary>
	/// A word representation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1Word
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p1beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results for the word. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p1beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// List of symbols in the word. The order of the symbols follows the natural reading order.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="symbols")]
		public GoogleCloudVisionV1p1beta1Symbol[] Symbols { get; set; }
	}
	
	/// <summary>
	/// A single symbol representation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1Symbol
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p1beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results for the symbol. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p1beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// The actual UTF-8 representation of the symbol.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="text")]
		public string Text { get; set; }
	}
	
	/// <summary>
	/// Stores image properties, such as dominant colors.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1ImageProperties
	{
		
		/// <summary>
		/// Set of dominant colors and their corresponding scores.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="dominantColors")]
		public GoogleCloudVisionV1p1beta1DominantColorsAnnotation DominantColors { get; set; }
	}
	
	/// <summary>
	/// Set of dominant colors and their corresponding scores.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1DominantColorsAnnotation
	{
		
		/// <summary>
		/// RGB color values with their score and pixel fraction.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="colors")]
		public GoogleCloudVisionV1p1beta1ColorInfo[] Colors { get; set; }
	}
	
	/// <summary>
	/// Color information consists of RGB channels, score, and the fraction of the image that the color occupies in the image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1ColorInfo
	{
		
		/// <summary>
		/// Represents a color in the RGBA color space. This representation is designed for simplicity of conversion to and from color representations in various languages over compactness. For example, the fields of this representation can be trivially provided to the constructor of `java.awt.Color` in Java; it can also be trivially provided to UIColor's `+colorWithRed:green:blue:alpha` method in iOS; and, with just a little work, it can be easily formatted into a CSS `rgba()` string in JavaScript. This reference page doesn't have information about the absolute color space that should be used to interpret the RGB valueâ€”for example, sRGB, Adobe RGB, DCI-P3, and BT.2020. By default, applications should assume the sRGB color space. When color equality needs to be decided, implementations, unless documented otherwise, treat two colors as equal if all their red, green, blue, and alpha values each differ by at most `1e-5`. Example (Java): import com.google.type.Color; // ... public static java.awt.Color fromProto(Color protocolor) { float alpha = protocolor.hasAlpha() ? protocolor.getAlpha().getValue() : 1.0; return new java.awt.Color( protocolor.getRed(), protocolor.getGreen(), protocolor.getBlue(), alpha); } public static Color toProto(java.awt.Color color) { float red = (float) color.getRed(); float green = (float) color.getGreen(); float blue = (float) color.getBlue(); float denominator = 255.0; Color.Builder resultBuilder = Color .newBuilder() .setRed(red / denominator) .setGreen(green / denominator) .setBlue(blue / denominator); int alpha = color.getAlpha(); if (alpha != 255) { result.setAlpha( FloatValue .newBuilder() .setValue(((float) alpha) / denominator) .build()); } return resultBuilder.build(); } // ... Example (iOS / Obj-C): // ... static UIColor* fromProto(Color* protocolor) { float red = [protocolor red]; float green = [protocolor green]; float blue = [protocolor blue]; FloatValue* alpha_wrapper = [protocolor alpha]; float alpha = 1.0; if (alpha_wrapper != nil) { alpha = [alpha_wrapper value]; } return [UIColor colorWithRed:red green:green blue:blue alpha:alpha]; } static Color* toProto(UIColor* color) { CGFloat red, green, blue, alpha; if (![color getRed:&red green:&green blue:&blue alpha:&alpha]) { return nil; } Color* result = [[Color alloc] init]; [result setRed:red]; [result setGreen:green]; [result setBlue:blue]; if (alpha <= 0.9999) { [result setAlpha:floatWrapperWithValue(alpha)]; } [result autorelease]; return result; } // ... Example (JavaScript): // ... var protoToCssColor = function(rgb_color) { var redFrac = rgb_color.red || 0.0; var greenFrac = rgb_color.green || 0.0; var blueFrac = rgb_color.blue || 0.0; var red = Math.floor(redFrac * 255); var green = Math.floor(greenFrac * 255); var blue = Math.floor(blueFrac * 255); if (!('alpha' in rgb_color)) { return rgbToCssColor(red, green, blue); } var alphaFrac = rgb_color.alpha.value || 0.0; var rgbParams = [red, green, blue].join(','); return ['rgba(', rgbParams, ',', alphaFrac, ')'].join(''); }; var rgbToCssColor = function(red, green, blue) { var rgbNumber = new Number((red << 16) | (green << 8) | blue); var hexString = rgbNumber.toString(16); var missingZeros = 6 - hexString.length; var resultBuilder = ['#']; for (var i = 0; i < missingZeros; i++) { resultBuilder.push('0'); } resultBuilder.push(hexString); return resultBuilder.join(''); }; // ...
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="color")]
		public Color Color { get; set; }
		
		/// <summary>
		/// The fraction of pixels the color occupies in the image. Value in range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pixelFraction")]
		public System.Nullable<System.Single> PixelFraction { get; set; }
		
		/// <summary>
		/// Image-specific score for this color. Value in range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Set of detected entity features.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1EntityAnnotation
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p1beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// **Deprecated. Use `score` instead.** The accuracy of the entity detection in an image. For example, for an image in which the "Eiffel Tower" entity is detected, this field represents the confidence that there is a tower in the query image. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Entity textual description, expressed in its `locale` language.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// The language code for the locale in which the entity textual `description` is expressed.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="locale")]
		public string Locale { get; set; }
		
		/// <summary>
		/// The location information for the detected entity. Multiple `LocationInfo` elements can be present because one location may indicate the location of the scene in the image, and another location may indicate the location of the place where the image was taken. Location information is usually present for landmarks.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="locations")]
		public GoogleCloudVisionV1p1beta1LocationInfo[] Locations { get; set; }
		
		/// <summary>
		/// Opaque entity ID. Some IDs may be available in [Google Knowledge Graph Search API](https://developers.google.com/knowledge-graph/).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mid")]
		public string Mid { get; set; }
		
		/// <summary>
		/// Some entities may have optional user-supplied `Property` (name/value) fields, such a score or string that qualifies the entity.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="properties")]
		public GoogleCloudVisionV1p1beta1Property[] Properties { get; set; }
		
		/// <summary>
		/// Overall score of the result. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
		
		/// <summary>
		/// The relevancy of the ICA (Image Content Annotation) label to the image. For example, the relevancy of "tower" is likely higher to an image containing the detected "Eiffel Tower" than to an image containing a detected distant towering building, even though the confidence that there is a tower in each image may be the same. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="topicality")]
		public System.Nullable<System.Single> Topicality { get; set; }
	}
	
	/// <summary>
	/// Detected entity location information.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1LocationInfo
	{
		
		/// <summary>
		/// An object that represents a latitude/longitude pair. This is expressed as a pair of doubles to represent degrees latitude and degrees longitude. Unless specified otherwise, this object must conform to the WGS84 standard. Values must be within normalized ranges.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="latLng")]
		public LatLng LatLng { get; set; }
	}
	
	/// <summary>
	/// A `Property` consists of a user-supplied name/value pair.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1Property
	{
		
		/// <summary>
		/// Name of the property.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Value of numeric properties.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uint64Value")]
		public string Uint64Value { get; set; }
		
		/// <summary>
		/// Value of the property.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="value")]
		public string Value { get; set; }
	}
	
	/// <summary>
	/// Set of detected objects with bounding boxes.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1LocalizedObjectAnnotation
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p1beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
		
		/// <summary>
		/// Object ID that should align with EntityAnnotation mid.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mid")]
		public string Mid { get; set; }
		
		/// <summary>
		/// Object name, expressed in its `language_code` language.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Score of the result. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Results for a product search request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1ProductSearchResults
	{
		
		/// <summary>
		/// Timestamp of the index which provided these results. Products added to the product set and products removed from the product set after this time are not reflected in the current results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="indexTime")]
		public string IndexTime { get; set; }
		
		/// <summary>
		/// List of results grouped by products detected in the query image. Each entry corresponds to one bounding polygon in the query image, and contains the matching products specific to that region. There may be duplicate product matches in the union of all the per-product results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productGroupedResults")]
		public GoogleCloudVisionV1p1beta1ProductSearchResultsGroupedResult[] ProductGroupedResults { get; set; }
		
		/// <summary>
		/// List of results, one for each product match.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="results")]
		public GoogleCloudVisionV1p1beta1ProductSearchResultsResult[] Results { get; set; }
	}
	
	/// <summary>
	/// Information about the products similar to a single product in a query image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1ProductSearchResultsGroupedResult
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p1beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// List of generic predictions for the object in the bounding box.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="objectAnnotations")]
		public GoogleCloudVisionV1p1beta1ProductSearchResultsObjectAnnotation[] ObjectAnnotations { get; set; }
		
		/// <summary>
		/// List of results, one for each product match.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="results")]
		public GoogleCloudVisionV1p1beta1ProductSearchResultsResult[] Results { get; set; }
	}
	
	/// <summary>
	/// Prediction for what the object in the bounding box is.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1ProductSearchResultsObjectAnnotation
	{
		
		/// <summary>
		/// The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
		
		/// <summary>
		/// Object ID that should align with EntityAnnotation mid.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mid")]
		public string Mid { get; set; }
		
		/// <summary>
		/// Object name, expressed in its `language_code` language.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Score of the result. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Information about a product.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1ProductSearchResultsResult
	{
		
		/// <summary>
		/// The resource name of the image from the product that is the closest match to the query.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="image")]
		public string Image { get; set; }
		
		/// <summary>
		/// A Product contains ReferenceImages.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="product")]
		public GoogleCloudVisionV1p1beta1Product Product { get; set; }
		
		/// <summary>
		/// A confidence level on the match, ranging from 0 (no confidence) to 1 (full confidence).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// A Product contains ReferenceImages.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1Product
	{
		
		/// <summary>
		/// User-provided metadata to be stored with this product. Must be at most 4096 characters long.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// The user-provided name for this Product. Must not be empty. Must be at most 4096 characters long.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="displayName")]
		public string DisplayName { get; set; }
		
		/// <summary>
		/// The resource name of the product. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID`. This field is ignored when creating a product.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Immutable. The category for the product identified by the reference image. This should be one of "homegoods-v2", "apparel-v2", "toys-v2", "packagedgoods-v1" or "general-v1". The legacy categories "homegoods", "apparel", and "toys" are still supported, but these should not be used for new products.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productCategory")]
		public string ProductCategory { get; set; }
		
		/// <summary>
		/// Key-value pairs that can be attached to a product. At query time, constraints can be specified based on the product_labels. Note that integer values can be provided as strings, e.g. "1199". Only strings with integer values can match a range-based restriction which is to be supported soon. Multiple values can be assigned to the same key. One product may have up to 500 product_labels. Notice that the total number of distinct product_labels over all products in one ProductSet cannot exceed 1M, otherwise the product search pipeline will refuse to work for that ProductSet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productLabels")]
		public GoogleCloudVisionV1p1beta1ProductKeyValue[] ProductLabels { get; set; }
	}
	
	/// <summary>
	/// A product label represented as a key-value pair.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1ProductKeyValue
	{
		
		/// <summary>
		/// The key of the label attached to the product. Cannot be empty and cannot exceed 128 bytes.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="key")]
		public string Key { get; set; }
		
		/// <summary>
		/// The value of the label attached to the product. Cannot be empty and cannot exceed 128 bytes.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="value")]
		public string Value { get; set; }
	}
	
	/// <summary>
	/// Set of features pertaining to the image, computed by computer vision methods over safe-search verticals (for example, adult, spoof, medical, violence).
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1SafeSearchAnnotation
	{
		
		/// <summary>
		/// Represents the adult content likelihood for the image. Adult content may contain elements such as nudity, pornographic images or cartoons, or sexual activities.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="adult")]
		public FaceAnnotationAngerLikelihood Adult { get; set; }
		
		/// <summary>
		/// Likelihood that this is a medical image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="medical")]
		public FaceAnnotationAngerLikelihood Medical { get; set; }
		
		/// <summary>
		/// Likelihood that the request image contains racy content. Racy content may include (but is not limited to) skimpy or sheer clothing, strategically covered nudity, lewd or provocative poses, or close-ups of sensitive body areas.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="racy")]
		public FaceAnnotationAngerLikelihood Racy { get; set; }
		
		/// <summary>
		/// Spoof likelihood. The likelihood that an modification was made to the image's canonical version to make it appear funny or offensive.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="spoof")]
		public FaceAnnotationAngerLikelihood Spoof { get; set; }
		
		/// <summary>
		/// Likelihood that this image contains violent content. Violent content may include death, serious harm, or injury to individuals or groups of individuals.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="violence")]
		public FaceAnnotationAngerLikelihood Violence { get; set; }
	}
	
	/// <summary>
	/// Relevant information for the image from the Internet.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1WebDetection
	{
		
		/// <summary>
		/// The service's best guess as to the topic of the request image. Inferred from similar images on the open web.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="bestGuessLabels")]
		public GoogleCloudVisionV1p1beta1WebDetectionWebLabel[] BestGuessLabels { get; set; }
		
		/// <summary>
		/// Fully matching images from the Internet. Can include resized copies of the query image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fullMatchingImages")]
		public GoogleCloudVisionV1p1beta1WebDetectionWebImage[] FullMatchingImages { get; set; }
		
		/// <summary>
		/// Web pages containing the matching images from the Internet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pagesWithMatchingImages")]
		public GoogleCloudVisionV1p1beta1WebDetectionWebPage[] PagesWithMatchingImages { get; set; }
		
		/// <summary>
		/// Partial matching images from the Internet. Those images are similar enough to share some key-point features. For example an original image will likely have partial matching for its crops.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="partialMatchingImages")]
		public GoogleCloudVisionV1p1beta1WebDetectionWebImage[] PartialMatchingImages { get; set; }
		
		/// <summary>
		/// The visually similar image results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="visuallySimilarImages")]
		public GoogleCloudVisionV1p1beta1WebDetectionWebImage[] VisuallySimilarImages { get; set; }
		
		/// <summary>
		/// Deduced entities from similar images on the Internet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="webEntities")]
		public GoogleCloudVisionV1p1beta1WebDetectionWebEntity[] WebEntities { get; set; }
	}
	
	/// <summary>
	/// Label to provide extra metadata for the web detection.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1WebDetectionWebLabel
	{
		
		/// <summary>
		/// Label for extra metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="label")]
		public string Label { get; set; }
		
		/// <summary>
		/// The BCP-47 language code for `label`, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
	}
	
	/// <summary>
	/// Metadata for online images.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1WebDetectionWebImage
	{
		
		/// <summary>
		/// (Deprecated) Overall relevancy score for the image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
		
		/// <summary>
		/// The result image URL.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="url")]
		public string Url { get; set; }
	}
	
	/// <summary>
	/// Metadata for web pages.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1WebDetectionWebPage
	{
		
		/// <summary>
		/// Fully matching images on the page. Can include resized copies of the query image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fullMatchingImages")]
		public GoogleCloudVisionV1p1beta1WebDetectionWebImage[] FullMatchingImages { get; set; }
		
		/// <summary>
		/// Title for the web page, may contain HTML markups.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pageTitle")]
		public string PageTitle { get; set; }
		
		/// <summary>
		/// Partial matching images on the page. Those images are similar enough to share some key-point features. For example an original image will likely have partial matching for its crops.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="partialMatchingImages")]
		public GoogleCloudVisionV1p1beta1WebDetectionWebImage[] PartialMatchingImages { get; set; }
		
		/// <summary>
		/// (Deprecated) Overall relevancy score for the web page.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
		
		/// <summary>
		/// The result web page URL.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="url")]
		public string Url { get; set; }
	}
	
	/// <summary>
	/// Entity deduced from similar images on the Internet.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1WebDetectionWebEntity
	{
		
		/// <summary>
		/// Canonical description of the entity, in English.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// Opaque entity ID.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="entityId")]
		public string EntityId { get; set; }
		
		/// <summary>
		/// Overall relevancy score for the entity. Not normalized and not comparable across different image queries.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// The response for a single offline file annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1AsyncAnnotateFileResponse
	{
		
		/// <summary>
		/// The desired output location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="outputConfig")]
		public GoogleCloudVisionV1p1beta1OutputConfig OutputConfig { get; set; }
	}
	
	/// <summary>
	/// The desired output location and metadata.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1OutputConfig
	{
		
		/// <summary>
		/// The max number of response protos to put into each output JSON file on Google Cloud Storage. The valid range is [1, 100]. If not specified, the default value is 20. For example, for one pdf file with 100 pages, 100 response protos will be generated. If `batch_size` = 20, then 5 json files each containing 20 response protos will be written under the prefix `gcs_destination`.`uri`. Currently, batch_size only applies to GcsDestination, with potential future support for other output configurations.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="batchSize")]
		public System.Nullable<System.Int32> BatchSize { get; set; }
		
		/// <summary>
		/// The Google Cloud Storage location where the output will be written to.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="gcsDestination")]
		public GoogleCloudVisionV1p1beta1GcsDestination GcsDestination { get; set; }
	}
	
	/// <summary>
	/// The Google Cloud Storage location where the output will be written to.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1GcsDestination
	{
		
		/// <summary>
		/// Google Cloud Storage URI prefix where the results will be stored. Results will be in JSON format and preceded by its corresponding input URI prefix. This field can either represent a gcs file prefix or gcs directory. In either case, the uri should be unique because in order to get all of the output files, you will need to do a wildcard gcs search on the uri prefix you provide. Examples: * File Prefix: gs://bucket-name/here/filenameprefix The output files will be created in gs://bucket-name/here/ and the names of the output files will begin with "filenameprefix". * Directory Prefix: gs://bucket-name/some/location/ The output files will be created in gs://bucket-name/some/location/ and the names of the output files could be anything because there was no filename prefix specified. If multiple outputs, each response is still AnnotateFileResponse, each of which contains some subset of the full list of AnnotateImageResponse. Multiple outputs can happen if, for example, the output JSON is too large and overflows into multiple sharded files.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Response to an async batch file annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1AsyncBatchAnnotateFilesResponse
	{
		
		/// <summary>
		/// The list of file annotation responses, one for each request in AsyncBatchAnnotateFilesRequest.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="responses")]
		public GoogleCloudVisionV1p1beta1AsyncAnnotateFileResponse[] Responses { get; set; }
	}
	
	/// <summary>
	/// Contains metadata for the BatchAnnotateImages operation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p1beta1OperationMetadata
	{
		
		/// <summary>
		/// The time when the batch request was received.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="createTime")]
		public string CreateTime { get; set; }
		
		/// <summary>
		/// Current state of the batch operation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="state")]
		public System.Nullable<GoogleCloudVisionV1p1beta1OperationMetadataState> State { get; set; }
		
		/// <summary>
		/// The time when the operation result was last updated.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="updateTime")]
		public string UpdateTime { get; set; }
	}
	
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public enum GoogleCloudVisionV1p1beta1OperationMetadataState
	{
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		STATE_UNSPECIFIED = 0,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		CREATED = 1,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		RUNNING = 2,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		DONE = 3,
		
		[System.Runtime.Serialization.EnumMemberAttribute()]
		CANCELLED = 4,
	}
	
	/// <summary>
	/// Response to a single file annotation request. A file may contain one or more images, which individually have their own responses.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1AnnotateFileResponse
	{
		
		/// <summary>
		/// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="error")]
		public Status Error { get; set; }
		
		/// <summary>
		/// The desired input location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="inputConfig")]
		public GoogleCloudVisionV1p2beta1InputConfig InputConfig { get; set; }
		
		/// <summary>
		/// Individual responses to images found within the file. This field will be empty if the `error` field is set.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="responses")]
		public GoogleCloudVisionV1p2beta1AnnotateImageResponse[] Responses { get; set; }
		
		/// <summary>
		/// This field gives the total number of pages in the file.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="totalPages")]
		public System.Nullable<System.Int32> TotalPages { get; set; }
	}
	
	/// <summary>
	/// The desired input location and metadata.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1InputConfig
	{
		
		/// <summary>
		/// File content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use a pure binary representation, whereas JSON representations use base64. Currently, this field only works for BatchAnnotateFiles requests. It does not work for AsyncBatchAnnotateFiles requests.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="content")]
		public string Content { get; set; }
		
		/// <summary>
		/// The Google Cloud Storage location where the input will be read from.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="gcsSource")]
		public GoogleCloudVisionV1p2beta1GcsSource GcsSource { get; set; }
		
		/// <summary>
		/// The type of the file. Currently only "application/pdf", "image/tiff" and "image/gif" are supported. Wildcards are not supported.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mimeType")]
		public string MimeType { get; set; }
	}
	
	/// <summary>
	/// The Google Cloud Storage location where the input will be read from.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1GcsSource
	{
		
		/// <summary>
		/// Google Cloud Storage URI for the input file. This must only be a Google Cloud Storage object. Wildcards are not currently supported.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Response to an image annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1AnnotateImageResponse
	{
		
		/// <summary>
		/// If an image was produced from a file (e.g. a PDF), this message gives information about the source of that image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="context")]
		public GoogleCloudVisionV1p2beta1ImageAnnotationContext Context { get; set; }
		
		/// <summary>
		/// Set of crop hints that are used to generate new crops when serving images.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="cropHintsAnnotation")]
		public GoogleCloudVisionV1p2beta1CropHintsAnnotation CropHintsAnnotation { get; set; }
		
		/// <summary>
		/// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="error")]
		public Status Error { get; set; }
		
		/// <summary>
		/// If present, face detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="faceAnnotations")]
		public GoogleCloudVisionV1p2beta1FaceAnnotation[] FaceAnnotations { get; set; }
		
		/// <summary>
		/// TextAnnotation contains a structured representation of OCR extracted text. The hierarchy of an OCR extracted text structure is like this: TextAnnotation -> Page -> Block -> Paragraph -> Word -> Symbol Each structural component, starting from Page, may further have their own properties. Properties describe detected languages, breaks etc.. Please refer to the TextAnnotation.TextProperty message definition below for more detail.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fullTextAnnotation")]
		public GoogleCloudVisionV1p2beta1TextAnnotation FullTextAnnotation { get; set; }
		
		/// <summary>
		/// Stores image properties, such as dominant colors.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="imagePropertiesAnnotation")]
		public GoogleCloudVisionV1p2beta1ImageProperties ImagePropertiesAnnotation { get; set; }
		
		/// <summary>
		/// If present, label detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="labelAnnotations")]
		public GoogleCloudVisionV1p2beta1EntityAnnotation[] LabelAnnotations { get; set; }
		
		/// <summary>
		/// If present, landmark detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="landmarkAnnotations")]
		public GoogleCloudVisionV1p2beta1EntityAnnotation[] LandmarkAnnotations { get; set; }
		
		/// <summary>
		/// If present, localized object detection has completed successfully. This will be sorted descending by confidence score.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="localizedObjectAnnotations")]
		public GoogleCloudVisionV1p2beta1LocalizedObjectAnnotation[] LocalizedObjectAnnotations { get; set; }
		
		/// <summary>
		/// If present, logo detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="logoAnnotations")]
		public GoogleCloudVisionV1p2beta1EntityAnnotation[] LogoAnnotations { get; set; }
		
		/// <summary>
		/// Results for a product search request.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productSearchResults")]
		public GoogleCloudVisionV1p2beta1ProductSearchResults ProductSearchResults { get; set; }
		
		/// <summary>
		/// Set of features pertaining to the image, computed by computer vision methods over safe-search verticals (for example, adult, spoof, medical, violence).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="safeSearchAnnotation")]
		public GoogleCloudVisionV1p2beta1SafeSearchAnnotation SafeSearchAnnotation { get; set; }
		
		/// <summary>
		/// If present, text (OCR) detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="textAnnotations")]
		public GoogleCloudVisionV1p2beta1EntityAnnotation[] TextAnnotations { get; set; }
		
		/// <summary>
		/// Relevant information for the image from the Internet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="webDetection")]
		public GoogleCloudVisionV1p2beta1WebDetection WebDetection { get; set; }
	}
	
	/// <summary>
	/// If an image was produced from a file (e.g. a PDF), this message gives information about the source of that image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1ImageAnnotationContext
	{
		
		/// <summary>
		/// If the file was a PDF or TIFF, this field gives the page number within the file used to produce the image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pageNumber")]
		public System.Nullable<System.Int32> PageNumber { get; set; }
		
		/// <summary>
		/// The URI of the file used to produce the image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Set of crop hints that are used to generate new crops when serving images.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1CropHintsAnnotation
	{
		
		/// <summary>
		/// Crop hint results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="cropHints")]
		public GoogleCloudVisionV1p2beta1CropHint[] CropHints { get; set; }
	}
	
	/// <summary>
	/// Single crop hint that is used to generate a new crop when serving an image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1CropHint
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p2beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// Confidence of this being a salient region. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Fraction of importance of this salient region with respect to the original image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="importanceFraction")]
		public System.Nullable<System.Single> ImportanceFraction { get; set; }
	}
	
	/// <summary>
	/// A bounding polygon for the detected image annotation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1BoundingPoly
	{
		
		/// <summary>
		/// The bounding polygon normalized vertices.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="normalizedVertices")]
		public GoogleCloudVisionV1p2beta1NormalizedVertex[] NormalizedVertices { get; set; }
		
		/// <summary>
		/// The bounding polygon vertices.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="vertices")]
		public GoogleCloudVisionV1p2beta1Vertex[] Vertices { get; set; }
	}
	
	/// <summary>
	/// A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1NormalizedVertex
	{
		
		/// <summary>
		/// X coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="x")]
		public System.Nullable<System.Single> X { get; set; }
		
		/// <summary>
		/// Y coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="y")]
		public System.Nullable<System.Single> Y { get; set; }
	}
	
	/// <summary>
	/// A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1Vertex
	{
		
		/// <summary>
		/// X coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="x")]
		public System.Nullable<System.Int32> X { get; set; }
		
		/// <summary>
		/// Y coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="y")]
		public System.Nullable<System.Int32> Y { get; set; }
	}
	
	/// <summary>
	/// A face annotation object contains the results of face detection.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1FaceAnnotation
	{
		
		/// <summary>
		/// Anger likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="angerLikelihood")]
		public FaceAnnotationAngerLikelihood AngerLikelihood { get; set; }
		
		/// <summary>
		/// Blurred likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blurredLikelihood")]
		public FaceAnnotationAngerLikelihood BlurredLikelihood { get; set; }
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p2beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// Detection confidence. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="detectionConfidence")]
		public System.Nullable<System.Single> DetectionConfidence { get; set; }
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fdBoundingPoly")]
		public GoogleCloudVisionV1p2beta1BoundingPoly FdBoundingPoly { get; set; }
		
		/// <summary>
		/// Headwear likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="headwearLikelihood")]
		public FaceAnnotationAngerLikelihood HeadwearLikelihood { get; set; }
		
		/// <summary>
		/// Joy likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="joyLikelihood")]
		public FaceAnnotationAngerLikelihood JoyLikelihood { get; set; }
		
		/// <summary>
		/// Face landmarking confidence. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="landmarkingConfidence")]
		public System.Nullable<System.Single> LandmarkingConfidence { get; set; }
		
		/// <summary>
		/// Detected face landmarks.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="landmarks")]
		public GoogleCloudVisionV1p2beta1FaceAnnotationLandmark[] Landmarks { get; set; }
		
		/// <summary>
		/// Yaw angle, which indicates the leftward/rightward angle that the face is pointing relative to the vertical plane perpendicular to the image. Range [-180,180].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="panAngle")]
		public System.Nullable<System.Single> PanAngle { get; set; }
		
		/// <summary>
		/// Roll angle, which indicates the amount of clockwise/anti-clockwise rotation of the face relative to the image vertical about the axis perpendicular to the face. Range [-180,180].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="rollAngle")]
		public System.Nullable<System.Single> RollAngle { get; set; }
		
		/// <summary>
		/// Sorrow likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="sorrowLikelihood")]
		public FaceAnnotationAngerLikelihood SorrowLikelihood { get; set; }
		
		/// <summary>
		/// Surprise likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="surpriseLikelihood")]
		public FaceAnnotationAngerLikelihood SurpriseLikelihood { get; set; }
		
		/// <summary>
		/// Pitch angle, which indicates the upwards/downwards angle that the face is pointing relative to the image's horizontal plane. Range [-180,180].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="tiltAngle")]
		public System.Nullable<System.Single> TiltAngle { get; set; }
		
		/// <summary>
		/// Under-exposed likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="underExposedLikelihood")]
		public FaceAnnotationAngerLikelihood UnderExposedLikelihood { get; set; }
	}
	
	/// <summary>
	/// A face-specific landmark (for example, a face feature).
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1FaceAnnotationLandmark
	{
		
		/// <summary>
		/// A 3D position in the image, used primarily for Face detection landmarks. A valid Position must have both x and y coordinates. The position coordinates are in the same scale as the original image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="position")]
		public GoogleCloudVisionV1p2beta1Position Position { get; set; }
		
		/// <summary>
		/// Face landmark type.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="type")]
		public LandmarkType Type { get; set; }
	}
	
	/// <summary>
	/// A 3D position in the image, used primarily for Face detection landmarks. A valid Position must have both x and y coordinates. The position coordinates are in the same scale as the original image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1Position
	{
		
		/// <summary>
		/// X coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="x")]
		public System.Nullable<System.Single> X { get; set; }
		
		/// <summary>
		/// Y coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="y")]
		public System.Nullable<System.Single> Y { get; set; }
		
		/// <summary>
		/// Z coordinate (or depth).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="z")]
		public System.Nullable<System.Single> Z { get; set; }
	}
	
	/// <summary>
	/// TextAnnotation contains a structured representation of OCR extracted text. The hierarchy of an OCR extracted text structure is like this: TextAnnotation -> Page -> Block -> Paragraph -> Word -> Symbol Each structural component, starting from Page, may further have their own properties. Properties describe detected languages, breaks etc.. Please refer to the TextAnnotation.TextProperty message definition below for more detail.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1TextAnnotation
	{
		
		/// <summary>
		/// List of pages detected by OCR.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pages")]
		public GoogleCloudVisionV1p2beta1Page[] Pages { get; set; }
		
		/// <summary>
		/// UTF-8 text detected on the pages.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="text")]
		public string Text { get; set; }
	}
	
	/// <summary>
	/// Detected page from OCR.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1Page
	{
		
		/// <summary>
		/// List of blocks of text, images etc on this page.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blocks")]
		public GoogleCloudVisionV1p2beta1Block[] Blocks { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results on the page. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Page height. For PDFs the unit is points. For images (including TIFFs) the unit is pixels.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="height")]
		public System.Nullable<System.Int32> Height { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p2beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// Page width. For PDFs the unit is points. For images (including TIFFs) the unit is pixels.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="width")]
		public System.Nullable<System.Int32> Width { get; set; }
	}
	
	/// <summary>
	/// Logical element on the page.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1Block
	{
		
		/// <summary>
		/// Detected block type (text, image etc) for this block.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blockType")]
		public BlockBlockType BlockType { get; set; }
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p2beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results on the block. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// List of paragraphs in this block (if this blocks is of type text).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="paragraphs")]
		public GoogleCloudVisionV1p2beta1Paragraph[] Paragraphs { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p2beta1TextAnnotationTextProperty Property { get; set; }
	}
	
	/// <summary>
	/// Structural unit of text representing a number of words in certain order.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1Paragraph
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p2beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results for the paragraph. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p2beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// List of all words in this paragraph.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="words")]
		public GoogleCloudVisionV1p2beta1Word[] Words { get; set; }
	}
	
	/// <summary>
	/// Additional information detected on the structural component.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1TextAnnotationTextProperty
	{
		
		/// <summary>
		/// Detected start or end of a structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="detectedBreak")]
		public GoogleCloudVisionV1p2beta1TextAnnotationDetectedBreak DetectedBreak { get; set; }
		
		/// <summary>
		/// A list of detected languages together with confidence.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="detectedLanguages")]
		public GoogleCloudVisionV1p2beta1TextAnnotationDetectedLanguage[] DetectedLanguages { get; set; }
	}
	
	/// <summary>
	/// Detected start or end of a structural component.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1TextAnnotationDetectedBreak
	{
		
		/// <summary>
		/// True if break prepends the element.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="isPrefix")]
		public System.Nullable<System.Boolean> IsPrefix { get; set; }
		
		/// <summary>
		/// Detected break type.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="type")]
		public DetectedBreakType Type { get; set; }
	}
	
	/// <summary>
	/// Detected language for a structural component.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1TextAnnotationDetectedLanguage
	{
		
		/// <summary>
		/// Confidence of detected language. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
	}
	
	/// <summary>
	/// A word representation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1Word
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p2beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results for the word. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p2beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// List of symbols in the word. The order of the symbols follows the natural reading order.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="symbols")]
		public GoogleCloudVisionV1p2beta1Symbol[] Symbols { get; set; }
	}
	
	/// <summary>
	/// A single symbol representation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1Symbol
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p2beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results for the symbol. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p2beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// The actual UTF-8 representation of the symbol.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="text")]
		public string Text { get; set; }
	}
	
	/// <summary>
	/// Stores image properties, such as dominant colors.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1ImageProperties
	{
		
		/// <summary>
		/// Set of dominant colors and their corresponding scores.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="dominantColors")]
		public GoogleCloudVisionV1p2beta1DominantColorsAnnotation DominantColors { get; set; }
	}
	
	/// <summary>
	/// Set of dominant colors and their corresponding scores.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1DominantColorsAnnotation
	{
		
		/// <summary>
		/// RGB color values with their score and pixel fraction.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="colors")]
		public GoogleCloudVisionV1p2beta1ColorInfo[] Colors { get; set; }
	}
	
	/// <summary>
	/// Color information consists of RGB channels, score, and the fraction of the image that the color occupies in the image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1ColorInfo
	{
		
		/// <summary>
		/// Represents a color in the RGBA color space. This representation is designed for simplicity of conversion to and from color representations in various languages over compactness. For example, the fields of this representation can be trivially provided to the constructor of `java.awt.Color` in Java; it can also be trivially provided to UIColor's `+colorWithRed:green:blue:alpha` method in iOS; and, with just a little work, it can be easily formatted into a CSS `rgba()` string in JavaScript. This reference page doesn't have information about the absolute color space that should be used to interpret the RGB valueâ€”for example, sRGB, Adobe RGB, DCI-P3, and BT.2020. By default, applications should assume the sRGB color space. When color equality needs to be decided, implementations, unless documented otherwise, treat two colors as equal if all their red, green, blue, and alpha values each differ by at most `1e-5`. Example (Java): import com.google.type.Color; // ... public static java.awt.Color fromProto(Color protocolor) { float alpha = protocolor.hasAlpha() ? protocolor.getAlpha().getValue() : 1.0; return new java.awt.Color( protocolor.getRed(), protocolor.getGreen(), protocolor.getBlue(), alpha); } public static Color toProto(java.awt.Color color) { float red = (float) color.getRed(); float green = (float) color.getGreen(); float blue = (float) color.getBlue(); float denominator = 255.0; Color.Builder resultBuilder = Color .newBuilder() .setRed(red / denominator) .setGreen(green / denominator) .setBlue(blue / denominator); int alpha = color.getAlpha(); if (alpha != 255) { result.setAlpha( FloatValue .newBuilder() .setValue(((float) alpha) / denominator) .build()); } return resultBuilder.build(); } // ... Example (iOS / Obj-C): // ... static UIColor* fromProto(Color* protocolor) { float red = [protocolor red]; float green = [protocolor green]; float blue = [protocolor blue]; FloatValue* alpha_wrapper = [protocolor alpha]; float alpha = 1.0; if (alpha_wrapper != nil) { alpha = [alpha_wrapper value]; } return [UIColor colorWithRed:red green:green blue:blue alpha:alpha]; } static Color* toProto(UIColor* color) { CGFloat red, green, blue, alpha; if (![color getRed:&red green:&green blue:&blue alpha:&alpha]) { return nil; } Color* result = [[Color alloc] init]; [result setRed:red]; [result setGreen:green]; [result setBlue:blue]; if (alpha <= 0.9999) { [result setAlpha:floatWrapperWithValue(alpha)]; } [result autorelease]; return result; } // ... Example (JavaScript): // ... var protoToCssColor = function(rgb_color) { var redFrac = rgb_color.red || 0.0; var greenFrac = rgb_color.green || 0.0; var blueFrac = rgb_color.blue || 0.0; var red = Math.floor(redFrac * 255); var green = Math.floor(greenFrac * 255); var blue = Math.floor(blueFrac * 255); if (!('alpha' in rgb_color)) { return rgbToCssColor(red, green, blue); } var alphaFrac = rgb_color.alpha.value || 0.0; var rgbParams = [red, green, blue].join(','); return ['rgba(', rgbParams, ',', alphaFrac, ')'].join(''); }; var rgbToCssColor = function(red, green, blue) { var rgbNumber = new Number((red << 16) | (green << 8) | blue); var hexString = rgbNumber.toString(16); var missingZeros = 6 - hexString.length; var resultBuilder = ['#']; for (var i = 0; i < missingZeros; i++) { resultBuilder.push('0'); } resultBuilder.push(hexString); return resultBuilder.join(''); }; // ...
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="color")]
		public Color Color { get; set; }
		
		/// <summary>
		/// The fraction of pixels the color occupies in the image. Value in range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pixelFraction")]
		public System.Nullable<System.Single> PixelFraction { get; set; }
		
		/// <summary>
		/// Image-specific score for this color. Value in range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Set of detected entity features.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1EntityAnnotation
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p2beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// **Deprecated. Use `score` instead.** The accuracy of the entity detection in an image. For example, for an image in which the "Eiffel Tower" entity is detected, this field represents the confidence that there is a tower in the query image. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Entity textual description, expressed in its `locale` language.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// The language code for the locale in which the entity textual `description` is expressed.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="locale")]
		public string Locale { get; set; }
		
		/// <summary>
		/// The location information for the detected entity. Multiple `LocationInfo` elements can be present because one location may indicate the location of the scene in the image, and another location may indicate the location of the place where the image was taken. Location information is usually present for landmarks.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="locations")]
		public GoogleCloudVisionV1p2beta1LocationInfo[] Locations { get; set; }
		
		/// <summary>
		/// Opaque entity ID. Some IDs may be available in [Google Knowledge Graph Search API](https://developers.google.com/knowledge-graph/).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mid")]
		public string Mid { get; set; }
		
		/// <summary>
		/// Some entities may have optional user-supplied `Property` (name/value) fields, such a score or string that qualifies the entity.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="properties")]
		public GoogleCloudVisionV1p2beta1Property[] Properties { get; set; }
		
		/// <summary>
		/// Overall score of the result. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
		
		/// <summary>
		/// The relevancy of the ICA (Image Content Annotation) label to the image. For example, the relevancy of "tower" is likely higher to an image containing the detected "Eiffel Tower" than to an image containing a detected distant towering building, even though the confidence that there is a tower in each image may be the same. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="topicality")]
		public System.Nullable<System.Single> Topicality { get; set; }
	}
	
	/// <summary>
	/// Detected entity location information.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1LocationInfo
	{
		
		/// <summary>
		/// An object that represents a latitude/longitude pair. This is expressed as a pair of doubles to represent degrees latitude and degrees longitude. Unless specified otherwise, this object must conform to the WGS84 standard. Values must be within normalized ranges.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="latLng")]
		public LatLng LatLng { get; set; }
	}
	
	/// <summary>
	/// A `Property` consists of a user-supplied name/value pair.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1Property
	{
		
		/// <summary>
		/// Name of the property.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Value of numeric properties.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uint64Value")]
		public string Uint64Value { get; set; }
		
		/// <summary>
		/// Value of the property.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="value")]
		public string Value { get; set; }
	}
	
	/// <summary>
	/// Set of detected objects with bounding boxes.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1LocalizedObjectAnnotation
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p2beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
		
		/// <summary>
		/// Object ID that should align with EntityAnnotation mid.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mid")]
		public string Mid { get; set; }
		
		/// <summary>
		/// Object name, expressed in its `language_code` language.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Score of the result. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Results for a product search request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1ProductSearchResults
	{
		
		/// <summary>
		/// Timestamp of the index which provided these results. Products added to the product set and products removed from the product set after this time are not reflected in the current results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="indexTime")]
		public string IndexTime { get; set; }
		
		/// <summary>
		/// List of results grouped by products detected in the query image. Each entry corresponds to one bounding polygon in the query image, and contains the matching products specific to that region. There may be duplicate product matches in the union of all the per-product results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productGroupedResults")]
		public GoogleCloudVisionV1p2beta1ProductSearchResultsGroupedResult[] ProductGroupedResults { get; set; }
		
		/// <summary>
		/// List of results, one for each product match.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="results")]
		public GoogleCloudVisionV1p2beta1ProductSearchResultsResult[] Results { get; set; }
	}
	
	/// <summary>
	/// Information about the products similar to a single product in a query image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1ProductSearchResultsGroupedResult
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p2beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// List of generic predictions for the object in the bounding box.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="objectAnnotations")]
		public GoogleCloudVisionV1p2beta1ProductSearchResultsObjectAnnotation[] ObjectAnnotations { get; set; }
		
		/// <summary>
		/// List of results, one for each product match.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="results")]
		public GoogleCloudVisionV1p2beta1ProductSearchResultsResult[] Results { get; set; }
	}
	
	/// <summary>
	/// Prediction for what the object in the bounding box is.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1ProductSearchResultsObjectAnnotation
	{
		
		/// <summary>
		/// The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
		
		/// <summary>
		/// Object ID that should align with EntityAnnotation mid.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mid")]
		public string Mid { get; set; }
		
		/// <summary>
		/// Object name, expressed in its `language_code` language.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Score of the result. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Information about a product.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1ProductSearchResultsResult
	{
		
		/// <summary>
		/// The resource name of the image from the product that is the closest match to the query.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="image")]
		public string Image { get; set; }
		
		/// <summary>
		/// A Product contains ReferenceImages.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="product")]
		public GoogleCloudVisionV1p2beta1Product Product { get; set; }
		
		/// <summary>
		/// A confidence level on the match, ranging from 0 (no confidence) to 1 (full confidence).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// A Product contains ReferenceImages.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1Product
	{
		
		/// <summary>
		/// User-provided metadata to be stored with this product. Must be at most 4096 characters long.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// The user-provided name for this Product. Must not be empty. Must be at most 4096 characters long.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="displayName")]
		public string DisplayName { get; set; }
		
		/// <summary>
		/// The resource name of the product. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID`. This field is ignored when creating a product.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Immutable. The category for the product identified by the reference image. This should be one of "homegoods-v2", "apparel-v2", "toys-v2", "packagedgoods-v1" or "general-v1". The legacy categories "homegoods", "apparel", and "toys" are still supported, but these should not be used for new products.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productCategory")]
		public string ProductCategory { get; set; }
		
		/// <summary>
		/// Key-value pairs that can be attached to a product. At query time, constraints can be specified based on the product_labels. Note that integer values can be provided as strings, e.g. "1199". Only strings with integer values can match a range-based restriction which is to be supported soon. Multiple values can be assigned to the same key. One product may have up to 500 product_labels. Notice that the total number of distinct product_labels over all products in one ProductSet cannot exceed 1M, otherwise the product search pipeline will refuse to work for that ProductSet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productLabels")]
		public GoogleCloudVisionV1p2beta1ProductKeyValue[] ProductLabels { get; set; }
	}
	
	/// <summary>
	/// A product label represented as a key-value pair.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1ProductKeyValue
	{
		
		/// <summary>
		/// The key of the label attached to the product. Cannot be empty and cannot exceed 128 bytes.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="key")]
		public string Key { get; set; }
		
		/// <summary>
		/// The value of the label attached to the product. Cannot be empty and cannot exceed 128 bytes.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="value")]
		public string Value { get; set; }
	}
	
	/// <summary>
	/// Set of features pertaining to the image, computed by computer vision methods over safe-search verticals (for example, adult, spoof, medical, violence).
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1SafeSearchAnnotation
	{
		
		/// <summary>
		/// Represents the adult content likelihood for the image. Adult content may contain elements such as nudity, pornographic images or cartoons, or sexual activities.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="adult")]
		public FaceAnnotationAngerLikelihood Adult { get; set; }
		
		/// <summary>
		/// Likelihood that this is a medical image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="medical")]
		public FaceAnnotationAngerLikelihood Medical { get; set; }
		
		/// <summary>
		/// Likelihood that the request image contains racy content. Racy content may include (but is not limited to) skimpy or sheer clothing, strategically covered nudity, lewd or provocative poses, or close-ups of sensitive body areas.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="racy")]
		public FaceAnnotationAngerLikelihood Racy { get; set; }
		
		/// <summary>
		/// Spoof likelihood. The likelihood that an modification was made to the image's canonical version to make it appear funny or offensive.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="spoof")]
		public FaceAnnotationAngerLikelihood Spoof { get; set; }
		
		/// <summary>
		/// Likelihood that this image contains violent content. Violent content may include death, serious harm, or injury to individuals or groups of individuals.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="violence")]
		public FaceAnnotationAngerLikelihood Violence { get; set; }
	}
	
	/// <summary>
	/// Relevant information for the image from the Internet.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1WebDetection
	{
		
		/// <summary>
		/// The service's best guess as to the topic of the request image. Inferred from similar images on the open web.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="bestGuessLabels")]
		public GoogleCloudVisionV1p2beta1WebDetectionWebLabel[] BestGuessLabels { get; set; }
		
		/// <summary>
		/// Fully matching images from the Internet. Can include resized copies of the query image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fullMatchingImages")]
		public GoogleCloudVisionV1p2beta1WebDetectionWebImage[] FullMatchingImages { get; set; }
		
		/// <summary>
		/// Web pages containing the matching images from the Internet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pagesWithMatchingImages")]
		public GoogleCloudVisionV1p2beta1WebDetectionWebPage[] PagesWithMatchingImages { get; set; }
		
		/// <summary>
		/// Partial matching images from the Internet. Those images are similar enough to share some key-point features. For example an original image will likely have partial matching for its crops.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="partialMatchingImages")]
		public GoogleCloudVisionV1p2beta1WebDetectionWebImage[] PartialMatchingImages { get; set; }
		
		/// <summary>
		/// The visually similar image results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="visuallySimilarImages")]
		public GoogleCloudVisionV1p2beta1WebDetectionWebImage[] VisuallySimilarImages { get; set; }
		
		/// <summary>
		/// Deduced entities from similar images on the Internet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="webEntities")]
		public GoogleCloudVisionV1p2beta1WebDetectionWebEntity[] WebEntities { get; set; }
	}
	
	/// <summary>
	/// Label to provide extra metadata for the web detection.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1WebDetectionWebLabel
	{
		
		/// <summary>
		/// Label for extra metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="label")]
		public string Label { get; set; }
		
		/// <summary>
		/// The BCP-47 language code for `label`, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
	}
	
	/// <summary>
	/// Metadata for online images.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1WebDetectionWebImage
	{
		
		/// <summary>
		/// (Deprecated) Overall relevancy score for the image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
		
		/// <summary>
		/// The result image URL.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="url")]
		public string Url { get; set; }
	}
	
	/// <summary>
	/// Metadata for web pages.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1WebDetectionWebPage
	{
		
		/// <summary>
		/// Fully matching images on the page. Can include resized copies of the query image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fullMatchingImages")]
		public GoogleCloudVisionV1p2beta1WebDetectionWebImage[] FullMatchingImages { get; set; }
		
		/// <summary>
		/// Title for the web page, may contain HTML markups.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pageTitle")]
		public string PageTitle { get; set; }
		
		/// <summary>
		/// Partial matching images on the page. Those images are similar enough to share some key-point features. For example an original image will likely have partial matching for its crops.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="partialMatchingImages")]
		public GoogleCloudVisionV1p2beta1WebDetectionWebImage[] PartialMatchingImages { get; set; }
		
		/// <summary>
		/// (Deprecated) Overall relevancy score for the web page.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
		
		/// <summary>
		/// The result web page URL.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="url")]
		public string Url { get; set; }
	}
	
	/// <summary>
	/// Entity deduced from similar images on the Internet.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1WebDetectionWebEntity
	{
		
		/// <summary>
		/// Canonical description of the entity, in English.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// Opaque entity ID.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="entityId")]
		public string EntityId { get; set; }
		
		/// <summary>
		/// Overall relevancy score for the entity. Not normalized and not comparable across different image queries.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// The response for a single offline file annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1AsyncAnnotateFileResponse
	{
		
		/// <summary>
		/// The desired output location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="outputConfig")]
		public GoogleCloudVisionV1p2beta1OutputConfig OutputConfig { get; set; }
	}
	
	/// <summary>
	/// The desired output location and metadata.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1OutputConfig
	{
		
		/// <summary>
		/// The max number of response protos to put into each output JSON file on Google Cloud Storage. The valid range is [1, 100]. If not specified, the default value is 20. For example, for one pdf file with 100 pages, 100 response protos will be generated. If `batch_size` = 20, then 5 json files each containing 20 response protos will be written under the prefix `gcs_destination`.`uri`. Currently, batch_size only applies to GcsDestination, with potential future support for other output configurations.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="batchSize")]
		public System.Nullable<System.Int32> BatchSize { get; set; }
		
		/// <summary>
		/// The Google Cloud Storage location where the output will be written to.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="gcsDestination")]
		public GoogleCloudVisionV1p2beta1GcsDestination GcsDestination { get; set; }
	}
	
	/// <summary>
	/// The Google Cloud Storage location where the output will be written to.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1GcsDestination
	{
		
		/// <summary>
		/// Google Cloud Storage URI prefix where the results will be stored. Results will be in JSON format and preceded by its corresponding input URI prefix. This field can either represent a gcs file prefix or gcs directory. In either case, the uri should be unique because in order to get all of the output files, you will need to do a wildcard gcs search on the uri prefix you provide. Examples: * File Prefix: gs://bucket-name/here/filenameprefix The output files will be created in gs://bucket-name/here/ and the names of the output files will begin with "filenameprefix". * Directory Prefix: gs://bucket-name/some/location/ The output files will be created in gs://bucket-name/some/location/ and the names of the output files could be anything because there was no filename prefix specified. If multiple outputs, each response is still AnnotateFileResponse, each of which contains some subset of the full list of AnnotateImageResponse. Multiple outputs can happen if, for example, the output JSON is too large and overflows into multiple sharded files.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Response to an async batch file annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1AsyncBatchAnnotateFilesResponse
	{
		
		/// <summary>
		/// The list of file annotation responses, one for each request in AsyncBatchAnnotateFilesRequest.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="responses")]
		public GoogleCloudVisionV1p2beta1AsyncAnnotateFileResponse[] Responses { get; set; }
	}
	
	/// <summary>
	/// Contains metadata for the BatchAnnotateImages operation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p2beta1OperationMetadata
	{
		
		/// <summary>
		/// The time when the batch request was received.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="createTime")]
		public string CreateTime { get; set; }
		
		/// <summary>
		/// Current state of the batch operation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="state")]
		public GoogleCloudVisionV1p1beta1OperationMetadataState State { get; set; }
		
		/// <summary>
		/// The time when the operation result was last updated.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="updateTime")]
		public string UpdateTime { get; set; }
	}
	
	/// <summary>
	/// Response to a single file annotation request. A file may contain one or more images, which individually have their own responses.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1AnnotateFileResponse
	{
		
		/// <summary>
		/// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="error")]
		public Status Error { get; set; }
		
		/// <summary>
		/// The desired input location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="inputConfig")]
		public GoogleCloudVisionV1p3beta1InputConfig InputConfig { get; set; }
		
		/// <summary>
		/// Individual responses to images found within the file. This field will be empty if the `error` field is set.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="responses")]
		public GoogleCloudVisionV1p3beta1AnnotateImageResponse[] Responses { get; set; }
		
		/// <summary>
		/// This field gives the total number of pages in the file.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="totalPages")]
		public System.Nullable<System.Int32> TotalPages { get; set; }
	}
	
	/// <summary>
	/// The desired input location and metadata.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1InputConfig
	{
		
		/// <summary>
		/// File content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use a pure binary representation, whereas JSON representations use base64. Currently, this field only works for BatchAnnotateFiles requests. It does not work for AsyncBatchAnnotateFiles requests.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="content")]
		public string Content { get; set; }
		
		/// <summary>
		/// The Google Cloud Storage location where the input will be read from.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="gcsSource")]
		public GoogleCloudVisionV1p3beta1GcsSource GcsSource { get; set; }
		
		/// <summary>
		/// The type of the file. Currently only "application/pdf", "image/tiff" and "image/gif" are supported. Wildcards are not supported.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mimeType")]
		public string MimeType { get; set; }
	}
	
	/// <summary>
	/// The Google Cloud Storage location where the input will be read from.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1GcsSource
	{
		
		/// <summary>
		/// Google Cloud Storage URI for the input file. This must only be a Google Cloud Storage object. Wildcards are not currently supported.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Response to an image annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1AnnotateImageResponse
	{
		
		/// <summary>
		/// If an image was produced from a file (e.g. a PDF), this message gives information about the source of that image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="context")]
		public GoogleCloudVisionV1p3beta1ImageAnnotationContext Context { get; set; }
		
		/// <summary>
		/// Set of crop hints that are used to generate new crops when serving images.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="cropHintsAnnotation")]
		public GoogleCloudVisionV1p3beta1CropHintsAnnotation CropHintsAnnotation { get; set; }
		
		/// <summary>
		/// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="error")]
		public Status Error { get; set; }
		
		/// <summary>
		/// If present, face detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="faceAnnotations")]
		public GoogleCloudVisionV1p3beta1FaceAnnotation[] FaceAnnotations { get; set; }
		
		/// <summary>
		/// TextAnnotation contains a structured representation of OCR extracted text. The hierarchy of an OCR extracted text structure is like this: TextAnnotation -> Page -> Block -> Paragraph -> Word -> Symbol Each structural component, starting from Page, may further have their own properties. Properties describe detected languages, breaks etc.. Please refer to the TextAnnotation.TextProperty message definition below for more detail.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fullTextAnnotation")]
		public GoogleCloudVisionV1p3beta1TextAnnotation FullTextAnnotation { get; set; }
		
		/// <summary>
		/// Stores image properties, such as dominant colors.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="imagePropertiesAnnotation")]
		public GoogleCloudVisionV1p3beta1ImageProperties ImagePropertiesAnnotation { get; set; }
		
		/// <summary>
		/// If present, label detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="labelAnnotations")]
		public GoogleCloudVisionV1p3beta1EntityAnnotation[] LabelAnnotations { get; set; }
		
		/// <summary>
		/// If present, landmark detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="landmarkAnnotations")]
		public GoogleCloudVisionV1p3beta1EntityAnnotation[] LandmarkAnnotations { get; set; }
		
		/// <summary>
		/// If present, localized object detection has completed successfully. This will be sorted descending by confidence score.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="localizedObjectAnnotations")]
		public GoogleCloudVisionV1p3beta1LocalizedObjectAnnotation[] LocalizedObjectAnnotations { get; set; }
		
		/// <summary>
		/// If present, logo detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="logoAnnotations")]
		public GoogleCloudVisionV1p3beta1EntityAnnotation[] LogoAnnotations { get; set; }
		
		/// <summary>
		/// Results for a product search request.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productSearchResults")]
		public GoogleCloudVisionV1p3beta1ProductSearchResults ProductSearchResults { get; set; }
		
		/// <summary>
		/// Set of features pertaining to the image, computed by computer vision methods over safe-search verticals (for example, adult, spoof, medical, violence).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="safeSearchAnnotation")]
		public GoogleCloudVisionV1p3beta1SafeSearchAnnotation SafeSearchAnnotation { get; set; }
		
		/// <summary>
		/// If present, text (OCR) detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="textAnnotations")]
		public GoogleCloudVisionV1p3beta1EntityAnnotation[] TextAnnotations { get; set; }
		
		/// <summary>
		/// Relevant information for the image from the Internet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="webDetection")]
		public GoogleCloudVisionV1p3beta1WebDetection WebDetection { get; set; }
	}
	
	/// <summary>
	/// If an image was produced from a file (e.g. a PDF), this message gives information about the source of that image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1ImageAnnotationContext
	{
		
		/// <summary>
		/// If the file was a PDF or TIFF, this field gives the page number within the file used to produce the image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pageNumber")]
		public System.Nullable<System.Int32> PageNumber { get; set; }
		
		/// <summary>
		/// The URI of the file used to produce the image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Set of crop hints that are used to generate new crops when serving images.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1CropHintsAnnotation
	{
		
		/// <summary>
		/// Crop hint results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="cropHints")]
		public GoogleCloudVisionV1p3beta1CropHint[] CropHints { get; set; }
	}
	
	/// <summary>
	/// Single crop hint that is used to generate a new crop when serving an image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1CropHint
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p3beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// Confidence of this being a salient region. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Fraction of importance of this salient region with respect to the original image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="importanceFraction")]
		public System.Nullable<System.Single> ImportanceFraction { get; set; }
	}
	
	/// <summary>
	/// A bounding polygon for the detected image annotation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1BoundingPoly
	{
		
		/// <summary>
		/// The bounding polygon normalized vertices.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="normalizedVertices")]
		public GoogleCloudVisionV1p3beta1NormalizedVertex[] NormalizedVertices { get; set; }
		
		/// <summary>
		/// The bounding polygon vertices.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="vertices")]
		public GoogleCloudVisionV1p3beta1Vertex[] Vertices { get; set; }
	}
	
	/// <summary>
	/// A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1NormalizedVertex
	{
		
		/// <summary>
		/// X coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="x")]
		public System.Nullable<System.Single> X { get; set; }
		
		/// <summary>
		/// Y coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="y")]
		public System.Nullable<System.Single> Y { get; set; }
	}
	
	/// <summary>
	/// A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1Vertex
	{
		
		/// <summary>
		/// X coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="x")]
		public System.Nullable<System.Int32> X { get; set; }
		
		/// <summary>
		/// Y coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="y")]
		public System.Nullable<System.Int32> Y { get; set; }
	}
	
	/// <summary>
	/// A face annotation object contains the results of face detection.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1FaceAnnotation
	{
		
		/// <summary>
		/// Anger likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="angerLikelihood")]
		public FaceAnnotationAngerLikelihood AngerLikelihood { get; set; }
		
		/// <summary>
		/// Blurred likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blurredLikelihood")]
		public FaceAnnotationAngerLikelihood BlurredLikelihood { get; set; }
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p3beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// Detection confidence. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="detectionConfidence")]
		public System.Nullable<System.Single> DetectionConfidence { get; set; }
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fdBoundingPoly")]
		public GoogleCloudVisionV1p3beta1BoundingPoly FdBoundingPoly { get; set; }
		
		/// <summary>
		/// Headwear likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="headwearLikelihood")]
		public FaceAnnotationAngerLikelihood HeadwearLikelihood { get; set; }
		
		/// <summary>
		/// Joy likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="joyLikelihood")]
		public FaceAnnotationAngerLikelihood JoyLikelihood { get; set; }
		
		/// <summary>
		/// Face landmarking confidence. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="landmarkingConfidence")]
		public System.Nullable<System.Single> LandmarkingConfidence { get; set; }
		
		/// <summary>
		/// Detected face landmarks.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="landmarks")]
		public GoogleCloudVisionV1p3beta1FaceAnnotationLandmark[] Landmarks { get; set; }
		
		/// <summary>
		/// Yaw angle, which indicates the leftward/rightward angle that the face is pointing relative to the vertical plane perpendicular to the image. Range [-180,180].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="panAngle")]
		public System.Nullable<System.Single> PanAngle { get; set; }
		
		/// <summary>
		/// Roll angle, which indicates the amount of clockwise/anti-clockwise rotation of the face relative to the image vertical about the axis perpendicular to the face. Range [-180,180].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="rollAngle")]
		public System.Nullable<System.Single> RollAngle { get; set; }
		
		/// <summary>
		/// Sorrow likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="sorrowLikelihood")]
		public FaceAnnotationAngerLikelihood SorrowLikelihood { get; set; }
		
		/// <summary>
		/// Surprise likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="surpriseLikelihood")]
		public FaceAnnotationAngerLikelihood SurpriseLikelihood { get; set; }
		
		/// <summary>
		/// Pitch angle, which indicates the upwards/downwards angle that the face is pointing relative to the image's horizontal plane. Range [-180,180].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="tiltAngle")]
		public System.Nullable<System.Single> TiltAngle { get; set; }
		
		/// <summary>
		/// Under-exposed likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="underExposedLikelihood")]
		public FaceAnnotationAngerLikelihood UnderExposedLikelihood { get; set; }
	}
	
	/// <summary>
	/// A face-specific landmark (for example, a face feature).
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1FaceAnnotationLandmark
	{
		
		/// <summary>
		/// A 3D position in the image, used primarily for Face detection landmarks. A valid Position must have both x and y coordinates. The position coordinates are in the same scale as the original image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="position")]
		public GoogleCloudVisionV1p3beta1Position Position { get; set; }
		
		/// <summary>
		/// Face landmark type.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="type")]
		public LandmarkType Type { get; set; }
	}
	
	/// <summary>
	/// A 3D position in the image, used primarily for Face detection landmarks. A valid Position must have both x and y coordinates. The position coordinates are in the same scale as the original image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1Position
	{
		
		/// <summary>
		/// X coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="x")]
		public System.Nullable<System.Single> X { get; set; }
		
		/// <summary>
		/// Y coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="y")]
		public System.Nullable<System.Single> Y { get; set; }
		
		/// <summary>
		/// Z coordinate (or depth).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="z")]
		public System.Nullable<System.Single> Z { get; set; }
	}
	
	/// <summary>
	/// TextAnnotation contains a structured representation of OCR extracted text. The hierarchy of an OCR extracted text structure is like this: TextAnnotation -> Page -> Block -> Paragraph -> Word -> Symbol Each structural component, starting from Page, may further have their own properties. Properties describe detected languages, breaks etc.. Please refer to the TextAnnotation.TextProperty message definition below for more detail.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1TextAnnotation
	{
		
		/// <summary>
		/// List of pages detected by OCR.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pages")]
		public GoogleCloudVisionV1p3beta1Page[] Pages { get; set; }
		
		/// <summary>
		/// UTF-8 text detected on the pages.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="text")]
		public string Text { get; set; }
	}
	
	/// <summary>
	/// Detected page from OCR.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1Page
	{
		
		/// <summary>
		/// List of blocks of text, images etc on this page.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blocks")]
		public GoogleCloudVisionV1p3beta1Block[] Blocks { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results on the page. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Page height. For PDFs the unit is points. For images (including TIFFs) the unit is pixels.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="height")]
		public System.Nullable<System.Int32> Height { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p3beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// Page width. For PDFs the unit is points. For images (including TIFFs) the unit is pixels.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="width")]
		public System.Nullable<System.Int32> Width { get; set; }
	}
	
	/// <summary>
	/// Logical element on the page.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1Block
	{
		
		/// <summary>
		/// Detected block type (text, image etc) for this block.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blockType")]
		public BlockBlockType BlockType { get; set; }
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p3beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results on the block. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// List of paragraphs in this block (if this blocks is of type text).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="paragraphs")]
		public GoogleCloudVisionV1p3beta1Paragraph[] Paragraphs { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p3beta1TextAnnotationTextProperty Property { get; set; }
	}
	
	/// <summary>
	/// Structural unit of text representing a number of words in certain order.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1Paragraph
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p3beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results for the paragraph. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p3beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// List of all words in this paragraph.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="words")]
		public GoogleCloudVisionV1p3beta1Word[] Words { get; set; }
	}
	
	/// <summary>
	/// Additional information detected on the structural component.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1TextAnnotationTextProperty
	{
		
		/// <summary>
		/// Detected start or end of a structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="detectedBreak")]
		public GoogleCloudVisionV1p3beta1TextAnnotationDetectedBreak DetectedBreak { get; set; }
		
		/// <summary>
		/// A list of detected languages together with confidence.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="detectedLanguages")]
		public GoogleCloudVisionV1p3beta1TextAnnotationDetectedLanguage[] DetectedLanguages { get; set; }
	}
	
	/// <summary>
	/// Detected start or end of a structural component.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1TextAnnotationDetectedBreak
	{
		
		/// <summary>
		/// True if break prepends the element.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="isPrefix")]
		public System.Nullable<System.Boolean> IsPrefix { get; set; }
		
		/// <summary>
		/// Detected break type.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="type")]
		public DetectedBreakType Type { get; set; }
	}
	
	/// <summary>
	/// Detected language for a structural component.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1TextAnnotationDetectedLanguage
	{
		
		/// <summary>
		/// Confidence of detected language. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
	}
	
	/// <summary>
	/// A word representation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1Word
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p3beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results for the word. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p3beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// List of symbols in the word. The order of the symbols follows the natural reading order.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="symbols")]
		public GoogleCloudVisionV1p3beta1Symbol[] Symbols { get; set; }
	}
	
	/// <summary>
	/// A single symbol representation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1Symbol
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p3beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results for the symbol. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p3beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// The actual UTF-8 representation of the symbol.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="text")]
		public string Text { get; set; }
	}
	
	/// <summary>
	/// Stores image properties, such as dominant colors.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1ImageProperties
	{
		
		/// <summary>
		/// Set of dominant colors and their corresponding scores.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="dominantColors")]
		public GoogleCloudVisionV1p3beta1DominantColorsAnnotation DominantColors { get; set; }
	}
	
	/// <summary>
	/// Set of dominant colors and their corresponding scores.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1DominantColorsAnnotation
	{
		
		/// <summary>
		/// RGB color values with their score and pixel fraction.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="colors")]
		public GoogleCloudVisionV1p3beta1ColorInfo[] Colors { get; set; }
	}
	
	/// <summary>
	/// Color information consists of RGB channels, score, and the fraction of the image that the color occupies in the image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1ColorInfo
	{
		
		/// <summary>
		/// Represents a color in the RGBA color space. This representation is designed for simplicity of conversion to and from color representations in various languages over compactness. For example, the fields of this representation can be trivially provided to the constructor of `java.awt.Color` in Java; it can also be trivially provided to UIColor's `+colorWithRed:green:blue:alpha` method in iOS; and, with just a little work, it can be easily formatted into a CSS `rgba()` string in JavaScript. This reference page doesn't have information about the absolute color space that should be used to interpret the RGB valueâ€”for example, sRGB, Adobe RGB, DCI-P3, and BT.2020. By default, applications should assume the sRGB color space. When color equality needs to be decided, implementations, unless documented otherwise, treat two colors as equal if all their red, green, blue, and alpha values each differ by at most `1e-5`. Example (Java): import com.google.type.Color; // ... public static java.awt.Color fromProto(Color protocolor) { float alpha = protocolor.hasAlpha() ? protocolor.getAlpha().getValue() : 1.0; return new java.awt.Color( protocolor.getRed(), protocolor.getGreen(), protocolor.getBlue(), alpha); } public static Color toProto(java.awt.Color color) { float red = (float) color.getRed(); float green = (float) color.getGreen(); float blue = (float) color.getBlue(); float denominator = 255.0; Color.Builder resultBuilder = Color .newBuilder() .setRed(red / denominator) .setGreen(green / denominator) .setBlue(blue / denominator); int alpha = color.getAlpha(); if (alpha != 255) { result.setAlpha( FloatValue .newBuilder() .setValue(((float) alpha) / denominator) .build()); } return resultBuilder.build(); } // ... Example (iOS / Obj-C): // ... static UIColor* fromProto(Color* protocolor) { float red = [protocolor red]; float green = [protocolor green]; float blue = [protocolor blue]; FloatValue* alpha_wrapper = [protocolor alpha]; float alpha = 1.0; if (alpha_wrapper != nil) { alpha = [alpha_wrapper value]; } return [UIColor colorWithRed:red green:green blue:blue alpha:alpha]; } static Color* toProto(UIColor* color) { CGFloat red, green, blue, alpha; if (![color getRed:&red green:&green blue:&blue alpha:&alpha]) { return nil; } Color* result = [[Color alloc] init]; [result setRed:red]; [result setGreen:green]; [result setBlue:blue]; if (alpha <= 0.9999) { [result setAlpha:floatWrapperWithValue(alpha)]; } [result autorelease]; return result; } // ... Example (JavaScript): // ... var protoToCssColor = function(rgb_color) { var redFrac = rgb_color.red || 0.0; var greenFrac = rgb_color.green || 0.0; var blueFrac = rgb_color.blue || 0.0; var red = Math.floor(redFrac * 255); var green = Math.floor(greenFrac * 255); var blue = Math.floor(blueFrac * 255); if (!('alpha' in rgb_color)) { return rgbToCssColor(red, green, blue); } var alphaFrac = rgb_color.alpha.value || 0.0; var rgbParams = [red, green, blue].join(','); return ['rgba(', rgbParams, ',', alphaFrac, ')'].join(''); }; var rgbToCssColor = function(red, green, blue) { var rgbNumber = new Number((red << 16) | (green << 8) | blue); var hexString = rgbNumber.toString(16); var missingZeros = 6 - hexString.length; var resultBuilder = ['#']; for (var i = 0; i < missingZeros; i++) { resultBuilder.push('0'); } resultBuilder.push(hexString); return resultBuilder.join(''); }; // ...
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="color")]
		public Color Color { get; set; }
		
		/// <summary>
		/// The fraction of pixels the color occupies in the image. Value in range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pixelFraction")]
		public System.Nullable<System.Single> PixelFraction { get; set; }
		
		/// <summary>
		/// Image-specific score for this color. Value in range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Set of detected entity features.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1EntityAnnotation
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p3beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// **Deprecated. Use `score` instead.** The accuracy of the entity detection in an image. For example, for an image in which the "Eiffel Tower" entity is detected, this field represents the confidence that there is a tower in the query image. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Entity textual description, expressed in its `locale` language.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// The language code for the locale in which the entity textual `description` is expressed.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="locale")]
		public string Locale { get; set; }
		
		/// <summary>
		/// The location information for the detected entity. Multiple `LocationInfo` elements can be present because one location may indicate the location of the scene in the image, and another location may indicate the location of the place where the image was taken. Location information is usually present for landmarks.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="locations")]
		public GoogleCloudVisionV1p3beta1LocationInfo[] Locations { get; set; }
		
		/// <summary>
		/// Opaque entity ID. Some IDs may be available in [Google Knowledge Graph Search API](https://developers.google.com/knowledge-graph/).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mid")]
		public string Mid { get; set; }
		
		/// <summary>
		/// Some entities may have optional user-supplied `Property` (name/value) fields, such a score or string that qualifies the entity.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="properties")]
		public GoogleCloudVisionV1p3beta1Property[] Properties { get; set; }
		
		/// <summary>
		/// Overall score of the result. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
		
		/// <summary>
		/// The relevancy of the ICA (Image Content Annotation) label to the image. For example, the relevancy of "tower" is likely higher to an image containing the detected "Eiffel Tower" than to an image containing a detected distant towering building, even though the confidence that there is a tower in each image may be the same. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="topicality")]
		public System.Nullable<System.Single> Topicality { get; set; }
	}
	
	/// <summary>
	/// Detected entity location information.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1LocationInfo
	{
		
		/// <summary>
		/// An object that represents a latitude/longitude pair. This is expressed as a pair of doubles to represent degrees latitude and degrees longitude. Unless specified otherwise, this object must conform to the WGS84 standard. Values must be within normalized ranges.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="latLng")]
		public LatLng LatLng { get; set; }
	}
	
	/// <summary>
	/// A `Property` consists of a user-supplied name/value pair.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1Property
	{
		
		/// <summary>
		/// Name of the property.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Value of numeric properties.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uint64Value")]
		public string Uint64Value { get; set; }
		
		/// <summary>
		/// Value of the property.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="value")]
		public string Value { get; set; }
	}
	
	/// <summary>
	/// Set of detected objects with bounding boxes.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1LocalizedObjectAnnotation
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p3beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
		
		/// <summary>
		/// Object ID that should align with EntityAnnotation mid.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mid")]
		public string Mid { get; set; }
		
		/// <summary>
		/// Object name, expressed in its `language_code` language.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Score of the result. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Results for a product search request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1ProductSearchResults
	{
		
		/// <summary>
		/// Timestamp of the index which provided these results. Products added to the product set and products removed from the product set after this time are not reflected in the current results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="indexTime")]
		public string IndexTime { get; set; }
		
		/// <summary>
		/// List of results grouped by products detected in the query image. Each entry corresponds to one bounding polygon in the query image, and contains the matching products specific to that region. There may be duplicate product matches in the union of all the per-product results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productGroupedResults")]
		public GoogleCloudVisionV1p3beta1ProductSearchResultsGroupedResult[] ProductGroupedResults { get; set; }
		
		/// <summary>
		/// List of results, one for each product match.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="results")]
		public GoogleCloudVisionV1p3beta1ProductSearchResultsResult[] Results { get; set; }
	}
	
	/// <summary>
	/// Information about the products similar to a single product in a query image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1ProductSearchResultsGroupedResult
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p3beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// List of generic predictions for the object in the bounding box.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="objectAnnotations")]
		public GoogleCloudVisionV1p3beta1ProductSearchResultsObjectAnnotation[] ObjectAnnotations { get; set; }
		
		/// <summary>
		/// List of results, one for each product match.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="results")]
		public GoogleCloudVisionV1p3beta1ProductSearchResultsResult[] Results { get; set; }
	}
	
	/// <summary>
	/// Prediction for what the object in the bounding box is.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1ProductSearchResultsObjectAnnotation
	{
		
		/// <summary>
		/// The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
		
		/// <summary>
		/// Object ID that should align with EntityAnnotation mid.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mid")]
		public string Mid { get; set; }
		
		/// <summary>
		/// Object name, expressed in its `language_code` language.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Score of the result. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Information about a product.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1ProductSearchResultsResult
	{
		
		/// <summary>
		/// The resource name of the image from the product that is the closest match to the query.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="image")]
		public string Image { get; set; }
		
		/// <summary>
		/// A Product contains ReferenceImages.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="product")]
		public GoogleCloudVisionV1p3beta1Product Product { get; set; }
		
		/// <summary>
		/// A confidence level on the match, ranging from 0 (no confidence) to 1 (full confidence).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// A Product contains ReferenceImages.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1Product
	{
		
		/// <summary>
		/// User-provided metadata to be stored with this product. Must be at most 4096 characters long.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// The user-provided name for this Product. Must not be empty. Must be at most 4096 characters long.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="displayName")]
		public string DisplayName { get; set; }
		
		/// <summary>
		/// The resource name of the product. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID`. This field is ignored when creating a product.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Immutable. The category for the product identified by the reference image. This should be one of "homegoods-v2", "apparel-v2", "toys-v2", "packagedgoods-v1" or "general-v1". The legacy categories "homegoods", "apparel", and "toys" are still supported, but these should not be used for new products.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productCategory")]
		public string ProductCategory { get; set; }
		
		/// <summary>
		/// Key-value pairs that can be attached to a product. At query time, constraints can be specified based on the product_labels. Note that integer values can be provided as strings, e.g. "1199". Only strings with integer values can match a range-based restriction which is to be supported soon. Multiple values can be assigned to the same key. One product may have up to 500 product_labels. Notice that the total number of distinct product_labels over all products in one ProductSet cannot exceed 1M, otherwise the product search pipeline will refuse to work for that ProductSet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productLabels")]
		public GoogleCloudVisionV1p3beta1ProductKeyValue[] ProductLabels { get; set; }
	}
	
	/// <summary>
	/// A product label represented as a key-value pair.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1ProductKeyValue
	{
		
		/// <summary>
		/// The key of the label attached to the product. Cannot be empty and cannot exceed 128 bytes.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="key")]
		public string Key { get; set; }
		
		/// <summary>
		/// The value of the label attached to the product. Cannot be empty and cannot exceed 128 bytes.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="value")]
		public string Value { get; set; }
	}
	
	/// <summary>
	/// Set of features pertaining to the image, computed by computer vision methods over safe-search verticals (for example, adult, spoof, medical, violence).
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1SafeSearchAnnotation
	{
		
		/// <summary>
		/// Represents the adult content likelihood for the image. Adult content may contain elements such as nudity, pornographic images or cartoons, or sexual activities.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="adult")]
		public FaceAnnotationAngerLikelihood Adult { get; set; }
		
		/// <summary>
		/// Likelihood that this is a medical image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="medical")]
		public FaceAnnotationAngerLikelihood Medical { get; set; }
		
		/// <summary>
		/// Likelihood that the request image contains racy content. Racy content may include (but is not limited to) skimpy or sheer clothing, strategically covered nudity, lewd or provocative poses, or close-ups of sensitive body areas.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="racy")]
		public FaceAnnotationAngerLikelihood Racy { get; set; }
		
		/// <summary>
		/// Spoof likelihood. The likelihood that an modification was made to the image's canonical version to make it appear funny or offensive.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="spoof")]
		public FaceAnnotationAngerLikelihood Spoof { get; set; }
		
		/// <summary>
		/// Likelihood that this image contains violent content. Violent content may include death, serious harm, or injury to individuals or groups of individuals.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="violence")]
		public FaceAnnotationAngerLikelihood Violence { get; set; }
	}
	
	/// <summary>
	/// Relevant information for the image from the Internet.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1WebDetection
	{
		
		/// <summary>
		/// The service's best guess as to the topic of the request image. Inferred from similar images on the open web.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="bestGuessLabels")]
		public GoogleCloudVisionV1p3beta1WebDetectionWebLabel[] BestGuessLabels { get; set; }
		
		/// <summary>
		/// Fully matching images from the Internet. Can include resized copies of the query image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fullMatchingImages")]
		public GoogleCloudVisionV1p3beta1WebDetectionWebImage[] FullMatchingImages { get; set; }
		
		/// <summary>
		/// Web pages containing the matching images from the Internet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pagesWithMatchingImages")]
		public GoogleCloudVisionV1p3beta1WebDetectionWebPage[] PagesWithMatchingImages { get; set; }
		
		/// <summary>
		/// Partial matching images from the Internet. Those images are similar enough to share some key-point features. For example an original image will likely have partial matching for its crops.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="partialMatchingImages")]
		public GoogleCloudVisionV1p3beta1WebDetectionWebImage[] PartialMatchingImages { get; set; }
		
		/// <summary>
		/// The visually similar image results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="visuallySimilarImages")]
		public GoogleCloudVisionV1p3beta1WebDetectionWebImage[] VisuallySimilarImages { get; set; }
		
		/// <summary>
		/// Deduced entities from similar images on the Internet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="webEntities")]
		public GoogleCloudVisionV1p3beta1WebDetectionWebEntity[] WebEntities { get; set; }
	}
	
	/// <summary>
	/// Label to provide extra metadata for the web detection.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1WebDetectionWebLabel
	{
		
		/// <summary>
		/// Label for extra metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="label")]
		public string Label { get; set; }
		
		/// <summary>
		/// The BCP-47 language code for `label`, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
	}
	
	/// <summary>
	/// Metadata for online images.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1WebDetectionWebImage
	{
		
		/// <summary>
		/// (Deprecated) Overall relevancy score for the image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
		
		/// <summary>
		/// The result image URL.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="url")]
		public string Url { get; set; }
	}
	
	/// <summary>
	/// Metadata for web pages.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1WebDetectionWebPage
	{
		
		/// <summary>
		/// Fully matching images on the page. Can include resized copies of the query image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fullMatchingImages")]
		public GoogleCloudVisionV1p3beta1WebDetectionWebImage[] FullMatchingImages { get; set; }
		
		/// <summary>
		/// Title for the web page, may contain HTML markups.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pageTitle")]
		public string PageTitle { get; set; }
		
		/// <summary>
		/// Partial matching images on the page. Those images are similar enough to share some key-point features. For example an original image will likely have partial matching for its crops.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="partialMatchingImages")]
		public GoogleCloudVisionV1p3beta1WebDetectionWebImage[] PartialMatchingImages { get; set; }
		
		/// <summary>
		/// (Deprecated) Overall relevancy score for the web page.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
		
		/// <summary>
		/// The result web page URL.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="url")]
		public string Url { get; set; }
	}
	
	/// <summary>
	/// Entity deduced from similar images on the Internet.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1WebDetectionWebEntity
	{
		
		/// <summary>
		/// Canonical description of the entity, in English.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// Opaque entity ID.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="entityId")]
		public string EntityId { get; set; }
		
		/// <summary>
		/// Overall relevancy score for the entity. Not normalized and not comparable across different image queries.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// The response for a single offline file annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1AsyncAnnotateFileResponse
	{
		
		/// <summary>
		/// The desired output location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="outputConfig")]
		public GoogleCloudVisionV1p3beta1OutputConfig OutputConfig { get; set; }
	}
	
	/// <summary>
	/// The desired output location and metadata.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1OutputConfig
	{
		
		/// <summary>
		/// The max number of response protos to put into each output JSON file on Google Cloud Storage. The valid range is [1, 100]. If not specified, the default value is 20. For example, for one pdf file with 100 pages, 100 response protos will be generated. If `batch_size` = 20, then 5 json files each containing 20 response protos will be written under the prefix `gcs_destination`.`uri`. Currently, batch_size only applies to GcsDestination, with potential future support for other output configurations.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="batchSize")]
		public System.Nullable<System.Int32> BatchSize { get; set; }
		
		/// <summary>
		/// The Google Cloud Storage location where the output will be written to.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="gcsDestination")]
		public GoogleCloudVisionV1p3beta1GcsDestination GcsDestination { get; set; }
	}
	
	/// <summary>
	/// The Google Cloud Storage location where the output will be written to.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1GcsDestination
	{
		
		/// <summary>
		/// Google Cloud Storage URI prefix where the results will be stored. Results will be in JSON format and preceded by its corresponding input URI prefix. This field can either represent a gcs file prefix or gcs directory. In either case, the uri should be unique because in order to get all of the output files, you will need to do a wildcard gcs search on the uri prefix you provide. Examples: * File Prefix: gs://bucket-name/here/filenameprefix The output files will be created in gs://bucket-name/here/ and the names of the output files will begin with "filenameprefix". * Directory Prefix: gs://bucket-name/some/location/ The output files will be created in gs://bucket-name/some/location/ and the names of the output files could be anything because there was no filename prefix specified. If multiple outputs, each response is still AnnotateFileResponse, each of which contains some subset of the full list of AnnotateImageResponse. Multiple outputs can happen if, for example, the output JSON is too large and overflows into multiple sharded files.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Response to an async batch file annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1AsyncBatchAnnotateFilesResponse
	{
		
		/// <summary>
		/// The list of file annotation responses, one for each request in AsyncBatchAnnotateFilesRequest.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="responses")]
		public GoogleCloudVisionV1p3beta1AsyncAnnotateFileResponse[] Responses { get; set; }
	}
	
	/// <summary>
	/// Metadata for the batch operations such as the current state. This is included in the `metadata` field of the `Operation` returned by the `GetOperation` call of the `google::longrunning::Operations` service.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1BatchOperationMetadata
	{
		
		/// <summary>
		/// The time when the batch request is finished and google.longrunning.Operation.done is set to true.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="endTime")]
		public string EndTime { get; set; }
		
		/// <summary>
		/// The current state of the batch operation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="state")]
		public BatchOperationMetadataState State { get; set; }
		
		/// <summary>
		/// The time when the batch request was submitted to the server.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="submitTime")]
		public string SubmitTime { get; set; }
	}
	
	/// <summary>
	/// Response message for the `ImportProductSets` method. This message is returned by the google.longrunning.Operations.GetOperation method in the returned google.longrunning.Operation.response field.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1ImportProductSetsResponse
	{
		
		/// <summary>
		/// The list of reference_images that are imported successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="referenceImages")]
		public GoogleCloudVisionV1p3beta1ReferenceImage[] ReferenceImages { get; set; }
		
		/// <summary>
		/// The rpc status for each ImportProductSet request, including both successes and errors. The number of statuses here matches the number of lines in the csv file, and statuses[i] stores the success or failure status of processing the i-th line of the csv, starting from line 0.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="statuses")]
		public Status[] Statuses { get; set; }
	}
	
	/// <summary>
	/// A `ReferenceImage` represents a product image and its associated metadata, such as bounding boxes.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1ReferenceImage
	{
		
		/// <summary>
		/// Optional. Bounding polygons around the areas of interest in the reference image. If this field is empty, the system will try to detect regions of interest. At most 10 bounding polygons will be used. The provided shape is converted into a non-rotated rectangle. Once converted, the small edge of the rectangle must be greater than or equal to 300 pixels. The aspect ratio must be 1:4 or less (i.e. 1:3 is ok; 1:5 is not).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPolys")]
		public GoogleCloudVisionV1p3beta1BoundingPoly[] BoundingPolys { get; set; }
		
		/// <summary>
		/// The resource name of the reference image. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID/referenceImages/IMAGE_ID`. This field is ignored when creating a reference image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Required. The Google Cloud Storage URI of the reference image. The URI must start with `gs://`.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Contains metadata for the BatchAnnotateImages operation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p3beta1OperationMetadata
	{
		
		/// <summary>
		/// The time when the batch request was received.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="createTime")]
		public string CreateTime { get; set; }
		
		/// <summary>
		/// Current state of the batch operation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="state")]
		public GoogleCloudVisionV1p1beta1OperationMetadataState State { get; set; }
		
		/// <summary>
		/// The time when the operation result was last updated.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="updateTime")]
		public string UpdateTime { get; set; }
	}
	
	/// <summary>
	/// Response to a single file annotation request. A file may contain one or more images, which individually have their own responses.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1AnnotateFileResponse
	{
		
		/// <summary>
		/// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="error")]
		public Status Error { get; set; }
		
		/// <summary>
		/// The desired input location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="inputConfig")]
		public GoogleCloudVisionV1p4beta1InputConfig InputConfig { get; set; }
		
		/// <summary>
		/// Individual responses to images found within the file. This field will be empty if the `error` field is set.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="responses")]
		public GoogleCloudVisionV1p4beta1AnnotateImageResponse[] Responses { get; set; }
		
		/// <summary>
		/// This field gives the total number of pages in the file.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="totalPages")]
		public System.Nullable<System.Int32> TotalPages { get; set; }
	}
	
	/// <summary>
	/// The desired input location and metadata.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1InputConfig
	{
		
		/// <summary>
		/// File content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use a pure binary representation, whereas JSON representations use base64. Currently, this field only works for BatchAnnotateFiles requests. It does not work for AsyncBatchAnnotateFiles requests.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="content")]
		public string Content { get; set; }
		
		/// <summary>
		/// The Google Cloud Storage location where the input will be read from.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="gcsSource")]
		public GoogleCloudVisionV1p4beta1GcsSource GcsSource { get; set; }
		
		/// <summary>
		/// The type of the file. Currently only "application/pdf", "image/tiff" and "image/gif" are supported. Wildcards are not supported.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mimeType")]
		public string MimeType { get; set; }
	}
	
	/// <summary>
	/// The Google Cloud Storage location where the input will be read from.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1GcsSource
	{
		
		/// <summary>
		/// Google Cloud Storage URI for the input file. This must only be a Google Cloud Storage object. Wildcards are not currently supported.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Response to an image annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1AnnotateImageResponse
	{
		
		/// <summary>
		/// If an image was produced from a file (e.g. a PDF), this message gives information about the source of that image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="context")]
		public GoogleCloudVisionV1p4beta1ImageAnnotationContext Context { get; set; }
		
		/// <summary>
		/// Set of crop hints that are used to generate new crops when serving images.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="cropHintsAnnotation")]
		public GoogleCloudVisionV1p4beta1CropHintsAnnotation CropHintsAnnotation { get; set; }
		
		/// <summary>
		/// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="error")]
		public Status Error { get; set; }
		
		/// <summary>
		/// If present, face detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="faceAnnotations")]
		public GoogleCloudVisionV1p4beta1FaceAnnotation[] FaceAnnotations { get; set; }
		
		/// <summary>
		/// TextAnnotation contains a structured representation of OCR extracted text. The hierarchy of an OCR extracted text structure is like this: TextAnnotation -> Page -> Block -> Paragraph -> Word -> Symbol Each structural component, starting from Page, may further have their own properties. Properties describe detected languages, breaks etc.. Please refer to the TextAnnotation.TextProperty message definition below for more detail.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fullTextAnnotation")]
		public GoogleCloudVisionV1p4beta1TextAnnotation FullTextAnnotation { get; set; }
		
		/// <summary>
		/// Stores image properties, such as dominant colors.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="imagePropertiesAnnotation")]
		public GoogleCloudVisionV1p4beta1ImageProperties ImagePropertiesAnnotation { get; set; }
		
		/// <summary>
		/// If present, label detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="labelAnnotations")]
		public GoogleCloudVisionV1p4beta1EntityAnnotation[] LabelAnnotations { get; set; }
		
		/// <summary>
		/// If present, landmark detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="landmarkAnnotations")]
		public GoogleCloudVisionV1p4beta1EntityAnnotation[] LandmarkAnnotations { get; set; }
		
		/// <summary>
		/// If present, localized object detection has completed successfully. This will be sorted descending by confidence score.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="localizedObjectAnnotations")]
		public GoogleCloudVisionV1p4beta1LocalizedObjectAnnotation[] LocalizedObjectAnnotations { get; set; }
		
		/// <summary>
		/// If present, logo detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="logoAnnotations")]
		public GoogleCloudVisionV1p4beta1EntityAnnotation[] LogoAnnotations { get; set; }
		
		/// <summary>
		/// Results for a product search request.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productSearchResults")]
		public GoogleCloudVisionV1p4beta1ProductSearchResults ProductSearchResults { get; set; }
		
		/// <summary>
		/// Set of features pertaining to the image, computed by computer vision methods over safe-search verticals (for example, adult, spoof, medical, violence).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="safeSearchAnnotation")]
		public GoogleCloudVisionV1p4beta1SafeSearchAnnotation SafeSearchAnnotation { get; set; }
		
		/// <summary>
		/// If present, text (OCR) detection has completed successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="textAnnotations")]
		public GoogleCloudVisionV1p4beta1EntityAnnotation[] TextAnnotations { get; set; }
		
		/// <summary>
		/// Relevant information for the image from the Internet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="webDetection")]
		public GoogleCloudVisionV1p4beta1WebDetection WebDetection { get; set; }
	}
	
	/// <summary>
	/// If an image was produced from a file (e.g. a PDF), this message gives information about the source of that image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1ImageAnnotationContext
	{
		
		/// <summary>
		/// If the file was a PDF or TIFF, this field gives the page number within the file used to produce the image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pageNumber")]
		public System.Nullable<System.Int32> PageNumber { get; set; }
		
		/// <summary>
		/// The URI of the file used to produce the image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Set of crop hints that are used to generate new crops when serving images.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1CropHintsAnnotation
	{
		
		/// <summary>
		/// Crop hint results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="cropHints")]
		public GoogleCloudVisionV1p4beta1CropHint[] CropHints { get; set; }
	}
	
	/// <summary>
	/// Single crop hint that is used to generate a new crop when serving an image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1CropHint
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p4beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// Confidence of this being a salient region. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Fraction of importance of this salient region with respect to the original image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="importanceFraction")]
		public System.Nullable<System.Single> ImportanceFraction { get; set; }
	}
	
	/// <summary>
	/// A bounding polygon for the detected image annotation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1BoundingPoly
	{
		
		/// <summary>
		/// The bounding polygon normalized vertices.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="normalizedVertices")]
		public GoogleCloudVisionV1p4beta1NormalizedVertex[] NormalizedVertices { get; set; }
		
		/// <summary>
		/// The bounding polygon vertices.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="vertices")]
		public GoogleCloudVisionV1p4beta1Vertex[] Vertices { get; set; }
	}
	
	/// <summary>
	/// A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1NormalizedVertex
	{
		
		/// <summary>
		/// X coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="x")]
		public System.Nullable<System.Single> X { get; set; }
		
		/// <summary>
		/// Y coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="y")]
		public System.Nullable<System.Single> Y { get; set; }
	}
	
	/// <summary>
	/// A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1Vertex
	{
		
		/// <summary>
		/// X coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="x")]
		public System.Nullable<System.Int32> X { get; set; }
		
		/// <summary>
		/// Y coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="y")]
		public System.Nullable<System.Int32> Y { get; set; }
	}
	
	/// <summary>
	/// A face annotation object contains the results of face detection.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1FaceAnnotation
	{
		
		/// <summary>
		/// Anger likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="angerLikelihood")]
		public FaceAnnotationAngerLikelihood AngerLikelihood { get; set; }
		
		/// <summary>
		/// Blurred likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blurredLikelihood")]
		public FaceAnnotationAngerLikelihood BlurredLikelihood { get; set; }
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p4beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// Detection confidence. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="detectionConfidence")]
		public System.Nullable<System.Single> DetectionConfidence { get; set; }
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fdBoundingPoly")]
		public GoogleCloudVisionV1p4beta1BoundingPoly FdBoundingPoly { get; set; }
		
		/// <summary>
		/// Headwear likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="headwearLikelihood")]
		public FaceAnnotationAngerLikelihood HeadwearLikelihood { get; set; }
		
		/// <summary>
		/// Joy likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="joyLikelihood")]
		public FaceAnnotationAngerLikelihood JoyLikelihood { get; set; }
		
		/// <summary>
		/// Face landmarking confidence. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="landmarkingConfidence")]
		public System.Nullable<System.Single> LandmarkingConfidence { get; set; }
		
		/// <summary>
		/// Detected face landmarks.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="landmarks")]
		public GoogleCloudVisionV1p4beta1FaceAnnotationLandmark[] Landmarks { get; set; }
		
		/// <summary>
		/// Yaw angle, which indicates the leftward/rightward angle that the face is pointing relative to the vertical plane perpendicular to the image. Range [-180,180].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="panAngle")]
		public System.Nullable<System.Single> PanAngle { get; set; }
		
		/// <summary>
		/// Additional recognition information. Only computed if image_context.face_recognition_params is provided, **and** a match is found to a Celebrity in the input CelebritySet. This field is sorted in order of decreasing confidence values.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="recognitionResult")]
		public GoogleCloudVisionV1p4beta1FaceRecognitionResult[] RecognitionResult { get; set; }
		
		/// <summary>
		/// Roll angle, which indicates the amount of clockwise/anti-clockwise rotation of the face relative to the image vertical about the axis perpendicular to the face. Range [-180,180].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="rollAngle")]
		public System.Nullable<System.Single> RollAngle { get; set; }
		
		/// <summary>
		/// Sorrow likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="sorrowLikelihood")]
		public FaceAnnotationAngerLikelihood SorrowLikelihood { get; set; }
		
		/// <summary>
		/// Surprise likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="surpriseLikelihood")]
		public FaceAnnotationAngerLikelihood SurpriseLikelihood { get; set; }
		
		/// <summary>
		/// Pitch angle, which indicates the upwards/downwards angle that the face is pointing relative to the image's horizontal plane. Range [-180,180].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="tiltAngle")]
		public System.Nullable<System.Single> TiltAngle { get; set; }
		
		/// <summary>
		/// Under-exposed likelihood.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="underExposedLikelihood")]
		public FaceAnnotationAngerLikelihood UnderExposedLikelihood { get; set; }
	}
	
	/// <summary>
	/// A face-specific landmark (for example, a face feature).
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1FaceAnnotationLandmark
	{
		
		/// <summary>
		/// A 3D position in the image, used primarily for Face detection landmarks. A valid Position must have both x and y coordinates. The position coordinates are in the same scale as the original image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="position")]
		public GoogleCloudVisionV1p4beta1Position Position { get; set; }
		
		/// <summary>
		/// Face landmark type.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="type")]
		public LandmarkType Type { get; set; }
	}
	
	/// <summary>
	/// A 3D position in the image, used primarily for Face detection landmarks. A valid Position must have both x and y coordinates. The position coordinates are in the same scale as the original image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1Position
	{
		
		/// <summary>
		/// X coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="x")]
		public System.Nullable<System.Single> X { get; set; }
		
		/// <summary>
		/// Y coordinate.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="y")]
		public System.Nullable<System.Single> Y { get; set; }
		
		/// <summary>
		/// Z coordinate (or depth).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="z")]
		public System.Nullable<System.Single> Z { get; set; }
	}
	
	/// <summary>
	/// Information about a face's identity.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1FaceRecognitionResult
	{
		
		/// <summary>
		/// A Celebrity is a group of Faces with an identity.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="celebrity")]
		public GoogleCloudVisionV1p4beta1Celebrity Celebrity { get; set; }
		
		/// <summary>
		/// Recognition confidence. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
	}
	
	/// <summary>
	/// A Celebrity is a group of Faces with an identity.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1Celebrity
	{
		
		/// <summary>
		/// The Celebrity's description.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// The Celebrity's display name.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="displayName")]
		public string DisplayName { get; set; }
		
		/// <summary>
		/// The resource name of the preloaded Celebrity. Has the format `builtin/{mid}`.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
	}
	
	/// <summary>
	/// TextAnnotation contains a structured representation of OCR extracted text. The hierarchy of an OCR extracted text structure is like this: TextAnnotation -> Page -> Block -> Paragraph -> Word -> Symbol Each structural component, starting from Page, may further have their own properties. Properties describe detected languages, breaks etc.. Please refer to the TextAnnotation.TextProperty message definition below for more detail.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1TextAnnotation
	{
		
		/// <summary>
		/// List of pages detected by OCR.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pages")]
		public GoogleCloudVisionV1p4beta1Page[] Pages { get; set; }
		
		/// <summary>
		/// UTF-8 text detected on the pages.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="text")]
		public string Text { get; set; }
	}
	
	/// <summary>
	/// Detected page from OCR.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1Page
	{
		
		/// <summary>
		/// List of blocks of text, images etc on this page.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blocks")]
		public GoogleCloudVisionV1p4beta1Block[] Blocks { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results on the page. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Page height. For PDFs the unit is points. For images (including TIFFs) the unit is pixels.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="height")]
		public System.Nullable<System.Int32> Height { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p4beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// Page width. For PDFs the unit is points. For images (including TIFFs) the unit is pixels.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="width")]
		public System.Nullable<System.Int32> Width { get; set; }
	}
	
	/// <summary>
	/// Logical element on the page.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1Block
	{
		
		/// <summary>
		/// Detected block type (text, image etc) for this block.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="blockType")]
		public BlockBlockType BlockType { get; set; }
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p4beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results on the block. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// List of paragraphs in this block (if this blocks is of type text).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="paragraphs")]
		public GoogleCloudVisionV1p4beta1Paragraph[] Paragraphs { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p4beta1TextAnnotationTextProperty Property { get; set; }
	}
	
	/// <summary>
	/// Structural unit of text representing a number of words in certain order.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1Paragraph
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p4beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results for the paragraph. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p4beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// List of all words in this paragraph.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="words")]
		public GoogleCloudVisionV1p4beta1Word[] Words { get; set; }
	}
	
	/// <summary>
	/// Additional information detected on the structural component.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1TextAnnotationTextProperty
	{
		
		/// <summary>
		/// Detected start or end of a structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="detectedBreak")]
		public GoogleCloudVisionV1p4beta1TextAnnotationDetectedBreak DetectedBreak { get; set; }
		
		/// <summary>
		/// A list of detected languages together with confidence.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="detectedLanguages")]
		public GoogleCloudVisionV1p4beta1TextAnnotationDetectedLanguage[] DetectedLanguages { get; set; }
	}
	
	/// <summary>
	/// Detected start or end of a structural component.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1TextAnnotationDetectedBreak
	{
		
		/// <summary>
		/// True if break prepends the element.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="isPrefix")]
		public System.Nullable<System.Boolean> IsPrefix { get; set; }
		
		/// <summary>
		/// Detected break type.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="type")]
		public DetectedBreakType Type { get; set; }
	}
	
	/// <summary>
	/// Detected language for a structural component.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1TextAnnotationDetectedLanguage
	{
		
		/// <summary>
		/// Confidence of detected language. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
	}
	
	/// <summary>
	/// A word representation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1Word
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p4beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results for the word. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p4beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// List of symbols in the word. The order of the symbols follows the natural reading order.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="symbols")]
		public GoogleCloudVisionV1p4beta1Symbol[] Symbols { get; set; }
	}
	
	/// <summary>
	/// A single symbol representation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1Symbol
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingBox")]
		public GoogleCloudVisionV1p4beta1BoundingPoly BoundingBox { get; set; }
		
		/// <summary>
		/// Confidence of the OCR results for the symbol. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Additional information detected on the structural component.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="property")]
		public GoogleCloudVisionV1p4beta1TextAnnotationTextProperty Property { get; set; }
		
		/// <summary>
		/// The actual UTF-8 representation of the symbol.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="text")]
		public string Text { get; set; }
	}
	
	/// <summary>
	/// Stores image properties, such as dominant colors.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1ImageProperties
	{
		
		/// <summary>
		/// Set of dominant colors and their corresponding scores.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="dominantColors")]
		public GoogleCloudVisionV1p4beta1DominantColorsAnnotation DominantColors { get; set; }
	}
	
	/// <summary>
	/// Set of dominant colors and their corresponding scores.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1DominantColorsAnnotation
	{
		
		/// <summary>
		/// RGB color values with their score and pixel fraction.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="colors")]
		public GoogleCloudVisionV1p4beta1ColorInfo[] Colors { get; set; }
	}
	
	/// <summary>
	/// Color information consists of RGB channels, score, and the fraction of the image that the color occupies in the image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1ColorInfo
	{
		
		/// <summary>
		/// Represents a color in the RGBA color space. This representation is designed for simplicity of conversion to and from color representations in various languages over compactness. For example, the fields of this representation can be trivially provided to the constructor of `java.awt.Color` in Java; it can also be trivially provided to UIColor's `+colorWithRed:green:blue:alpha` method in iOS; and, with just a little work, it can be easily formatted into a CSS `rgba()` string in JavaScript. This reference page doesn't have information about the absolute color space that should be used to interpret the RGB valueâ€”for example, sRGB, Adobe RGB, DCI-P3, and BT.2020. By default, applications should assume the sRGB color space. When color equality needs to be decided, implementations, unless documented otherwise, treat two colors as equal if all their red, green, blue, and alpha values each differ by at most `1e-5`. Example (Java): import com.google.type.Color; // ... public static java.awt.Color fromProto(Color protocolor) { float alpha = protocolor.hasAlpha() ? protocolor.getAlpha().getValue() : 1.0; return new java.awt.Color( protocolor.getRed(), protocolor.getGreen(), protocolor.getBlue(), alpha); } public static Color toProto(java.awt.Color color) { float red = (float) color.getRed(); float green = (float) color.getGreen(); float blue = (float) color.getBlue(); float denominator = 255.0; Color.Builder resultBuilder = Color .newBuilder() .setRed(red / denominator) .setGreen(green / denominator) .setBlue(blue / denominator); int alpha = color.getAlpha(); if (alpha != 255) { result.setAlpha( FloatValue .newBuilder() .setValue(((float) alpha) / denominator) .build()); } return resultBuilder.build(); } // ... Example (iOS / Obj-C): // ... static UIColor* fromProto(Color* protocolor) { float red = [protocolor red]; float green = [protocolor green]; float blue = [protocolor blue]; FloatValue* alpha_wrapper = [protocolor alpha]; float alpha = 1.0; if (alpha_wrapper != nil) { alpha = [alpha_wrapper value]; } return [UIColor colorWithRed:red green:green blue:blue alpha:alpha]; } static Color* toProto(UIColor* color) { CGFloat red, green, blue, alpha; if (![color getRed:&red green:&green blue:&blue alpha:&alpha]) { return nil; } Color* result = [[Color alloc] init]; [result setRed:red]; [result setGreen:green]; [result setBlue:blue]; if (alpha <= 0.9999) { [result setAlpha:floatWrapperWithValue(alpha)]; } [result autorelease]; return result; } // ... Example (JavaScript): // ... var protoToCssColor = function(rgb_color) { var redFrac = rgb_color.red || 0.0; var greenFrac = rgb_color.green || 0.0; var blueFrac = rgb_color.blue || 0.0; var red = Math.floor(redFrac * 255); var green = Math.floor(greenFrac * 255); var blue = Math.floor(blueFrac * 255); if (!('alpha' in rgb_color)) { return rgbToCssColor(red, green, blue); } var alphaFrac = rgb_color.alpha.value || 0.0; var rgbParams = [red, green, blue].join(','); return ['rgba(', rgbParams, ',', alphaFrac, ')'].join(''); }; var rgbToCssColor = function(red, green, blue) { var rgbNumber = new Number((red << 16) | (green << 8) | blue); var hexString = rgbNumber.toString(16); var missingZeros = 6 - hexString.length; var resultBuilder = ['#']; for (var i = 0; i < missingZeros; i++) { resultBuilder.push('0'); } resultBuilder.push(hexString); return resultBuilder.join(''); }; // ...
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="color")]
		public Color Color { get; set; }
		
		/// <summary>
		/// The fraction of pixels the color occupies in the image. Value in range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pixelFraction")]
		public System.Nullable<System.Single> PixelFraction { get; set; }
		
		/// <summary>
		/// Image-specific score for this color. Value in range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Set of detected entity features.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1EntityAnnotation
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p4beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// **Deprecated. Use `score` instead.** The accuracy of the entity detection in an image. For example, for an image in which the "Eiffel Tower" entity is detected, this field represents the confidence that there is a tower in the query image. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="confidence")]
		public System.Nullable<System.Single> Confidence { get; set; }
		
		/// <summary>
		/// Entity textual description, expressed in its `locale` language.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// The language code for the locale in which the entity textual `description` is expressed.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="locale")]
		public string Locale { get; set; }
		
		/// <summary>
		/// The location information for the detected entity. Multiple `LocationInfo` elements can be present because one location may indicate the location of the scene in the image, and another location may indicate the location of the place where the image was taken. Location information is usually present for landmarks.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="locations")]
		public GoogleCloudVisionV1p4beta1LocationInfo[] Locations { get; set; }
		
		/// <summary>
		/// Opaque entity ID. Some IDs may be available in [Google Knowledge Graph Search API](https://developers.google.com/knowledge-graph/).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mid")]
		public string Mid { get; set; }
		
		/// <summary>
		/// Some entities may have optional user-supplied `Property` (name/value) fields, such a score or string that qualifies the entity.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="properties")]
		public GoogleCloudVisionV1p4beta1Property[] Properties { get; set; }
		
		/// <summary>
		/// Overall score of the result. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
		
		/// <summary>
		/// The relevancy of the ICA (Image Content Annotation) label to the image. For example, the relevancy of "tower" is likely higher to an image containing the detected "Eiffel Tower" than to an image containing a detected distant towering building, even though the confidence that there is a tower in each image may be the same. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="topicality")]
		public System.Nullable<System.Single> Topicality { get; set; }
	}
	
	/// <summary>
	/// Detected entity location information.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1LocationInfo
	{
		
		/// <summary>
		/// An object that represents a latitude/longitude pair. This is expressed as a pair of doubles to represent degrees latitude and degrees longitude. Unless specified otherwise, this object must conform to the WGS84 standard. Values must be within normalized ranges.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="latLng")]
		public LatLng LatLng { get; set; }
	}
	
	/// <summary>
	/// A `Property` consists of a user-supplied name/value pair.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1Property
	{
		
		/// <summary>
		/// Name of the property.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Value of numeric properties.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uint64Value")]
		public string Uint64Value { get; set; }
		
		/// <summary>
		/// Value of the property.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="value")]
		public string Value { get; set; }
	}
	
	/// <summary>
	/// Set of detected objects with bounding boxes.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1LocalizedObjectAnnotation
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p4beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
		
		/// <summary>
		/// Object ID that should align with EntityAnnotation mid.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mid")]
		public string Mid { get; set; }
		
		/// <summary>
		/// Object name, expressed in its `language_code` language.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Score of the result. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Results for a product search request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1ProductSearchResults
	{
		
		/// <summary>
		/// Timestamp of the index which provided these results. Products added to the product set and products removed from the product set after this time are not reflected in the current results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="indexTime")]
		public string IndexTime { get; set; }
		
		/// <summary>
		/// List of results grouped by products detected in the query image. Each entry corresponds to one bounding polygon in the query image, and contains the matching products specific to that region. There may be duplicate product matches in the union of all the per-product results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productGroupedResults")]
		public GoogleCloudVisionV1p4beta1ProductSearchResultsGroupedResult[] ProductGroupedResults { get; set; }
		
		/// <summary>
		/// List of results, one for each product match.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="results")]
		public GoogleCloudVisionV1p4beta1ProductSearchResultsResult[] Results { get; set; }
	}
	
	/// <summary>
	/// Information about the products similar to a single product in a query image.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1ProductSearchResultsGroupedResult
	{
		
		/// <summary>
		/// A bounding polygon for the detected image annotation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPoly")]
		public GoogleCloudVisionV1p4beta1BoundingPoly BoundingPoly { get; set; }
		
		/// <summary>
		/// List of generic predictions for the object in the bounding box.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="objectAnnotations")]
		public GoogleCloudVisionV1p4beta1ProductSearchResultsObjectAnnotation[] ObjectAnnotations { get; set; }
		
		/// <summary>
		/// List of results, one for each product match.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="results")]
		public GoogleCloudVisionV1p4beta1ProductSearchResultsResult[] Results { get; set; }
	}
	
	/// <summary>
	/// Prediction for what the object in the bounding box is.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1ProductSearchResultsObjectAnnotation
	{
		
		/// <summary>
		/// The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
		
		/// <summary>
		/// Object ID that should align with EntityAnnotation mid.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="mid")]
		public string Mid { get; set; }
		
		/// <summary>
		/// Object name, expressed in its `language_code` language.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Score of the result. Range [0, 1].
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// Information about a product.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1ProductSearchResultsResult
	{
		
		/// <summary>
		/// The resource name of the image from the product that is the closest match to the query.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="image")]
		public string Image { get; set; }
		
		/// <summary>
		/// A Product contains ReferenceImages.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="product")]
		public GoogleCloudVisionV1p4beta1Product Product { get; set; }
		
		/// <summary>
		/// A confidence level on the match, ranging from 0 (no confidence) to 1 (full confidence).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// A Product contains ReferenceImages.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1Product
	{
		
		/// <summary>
		/// User-provided metadata to be stored with this product. Must be at most 4096 characters long.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// The user-provided name for this Product. Must not be empty. Must be at most 4096 characters long.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="displayName")]
		public string DisplayName { get; set; }
		
		/// <summary>
		/// The resource name of the product. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID`. This field is ignored when creating a product.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Immutable. The category for the product identified by the reference image. This should be one of "homegoods-v2", "apparel-v2", "toys-v2", "packagedgoods-v1" or "general-v1". The legacy categories "homegoods", "apparel", and "toys" are still supported, but these should not be used for new products.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productCategory")]
		public string ProductCategory { get; set; }
		
		/// <summary>
		/// Key-value pairs that can be attached to a product. At query time, constraints can be specified based on the product_labels. Note that integer values can be provided as strings, e.g. "1199". Only strings with integer values can match a range-based restriction which is to be supported soon. Multiple values can be assigned to the same key. One product may have up to 500 product_labels. Notice that the total number of distinct product_labels over all products in one ProductSet cannot exceed 1M, otherwise the product search pipeline will refuse to work for that ProductSet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productLabels")]
		public GoogleCloudVisionV1p4beta1ProductKeyValue[] ProductLabels { get; set; }
	}
	
	/// <summary>
	/// A product label represented as a key-value pair.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1ProductKeyValue
	{
		
		/// <summary>
		/// The key of the label attached to the product. Cannot be empty and cannot exceed 128 bytes.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="key")]
		public string Key { get; set; }
		
		/// <summary>
		/// The value of the label attached to the product. Cannot be empty and cannot exceed 128 bytes.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="value")]
		public string Value { get; set; }
	}
	
	/// <summary>
	/// Set of features pertaining to the image, computed by computer vision methods over safe-search verticals (for example, adult, spoof, medical, violence).
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1SafeSearchAnnotation
	{
		
		/// <summary>
		/// Represents the adult content likelihood for the image. Adult content may contain elements such as nudity, pornographic images or cartoons, or sexual activities.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="adult")]
		public FaceAnnotationAngerLikelihood Adult { get; set; }
		
		/// <summary>
		/// Likelihood that this is a medical image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="medical")]
		public FaceAnnotationAngerLikelihood Medical { get; set; }
		
		/// <summary>
		/// Likelihood that the request image contains racy content. Racy content may include (but is not limited to) skimpy or sheer clothing, strategically covered nudity, lewd or provocative poses, or close-ups of sensitive body areas.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="racy")]
		public FaceAnnotationAngerLikelihood Racy { get; set; }
		
		/// <summary>
		/// Spoof likelihood. The likelihood that an modification was made to the image's canonical version to make it appear funny or offensive.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="spoof")]
		public FaceAnnotationAngerLikelihood Spoof { get; set; }
		
		/// <summary>
		/// Likelihood that this image contains violent content. Violent content may include death, serious harm, or injury to individuals or groups of individuals.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="violence")]
		public FaceAnnotationAngerLikelihood Violence { get; set; }
	}
	
	/// <summary>
	/// Relevant information for the image from the Internet.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1WebDetection
	{
		
		/// <summary>
		/// The service's best guess as to the topic of the request image. Inferred from similar images on the open web.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="bestGuessLabels")]
		public GoogleCloudVisionV1p4beta1WebDetectionWebLabel[] BestGuessLabels { get; set; }
		
		/// <summary>
		/// Fully matching images from the Internet. Can include resized copies of the query image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fullMatchingImages")]
		public GoogleCloudVisionV1p4beta1WebDetectionWebImage[] FullMatchingImages { get; set; }
		
		/// <summary>
		/// Web pages containing the matching images from the Internet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pagesWithMatchingImages")]
		public GoogleCloudVisionV1p4beta1WebDetectionWebPage[] PagesWithMatchingImages { get; set; }
		
		/// <summary>
		/// Partial matching images from the Internet. Those images are similar enough to share some key-point features. For example an original image will likely have partial matching for its crops.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="partialMatchingImages")]
		public GoogleCloudVisionV1p4beta1WebDetectionWebImage[] PartialMatchingImages { get; set; }
		
		/// <summary>
		/// The visually similar image results.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="visuallySimilarImages")]
		public GoogleCloudVisionV1p4beta1WebDetectionWebImage[] VisuallySimilarImages { get; set; }
		
		/// <summary>
		/// Deduced entities from similar images on the Internet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="webEntities")]
		public GoogleCloudVisionV1p4beta1WebDetectionWebEntity[] WebEntities { get; set; }
	}
	
	/// <summary>
	/// Label to provide extra metadata for the web detection.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1WebDetectionWebLabel
	{
		
		/// <summary>
		/// Label for extra metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="label")]
		public string Label { get; set; }
		
		/// <summary>
		/// The BCP-47 language code for `label`, such as "en-US" or "sr-Latn". For more information, see http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="languageCode")]
		public string LanguageCode { get; set; }
	}
	
	/// <summary>
	/// Metadata for online images.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1WebDetectionWebImage
	{
		
		/// <summary>
		/// (Deprecated) Overall relevancy score for the image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
		
		/// <summary>
		/// The result image URL.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="url")]
		public string Url { get; set; }
	}
	
	/// <summary>
	/// Metadata for web pages.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1WebDetectionWebPage
	{
		
		/// <summary>
		/// Fully matching images on the page. Can include resized copies of the query image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="fullMatchingImages")]
		public GoogleCloudVisionV1p4beta1WebDetectionWebImage[] FullMatchingImages { get; set; }
		
		/// <summary>
		/// Title for the web page, may contain HTML markups.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pageTitle")]
		public string PageTitle { get; set; }
		
		/// <summary>
		/// Partial matching images on the page. Those images are similar enough to share some key-point features. For example an original image will likely have partial matching for its crops.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="partialMatchingImages")]
		public GoogleCloudVisionV1p4beta1WebDetectionWebImage[] PartialMatchingImages { get; set; }
		
		/// <summary>
		/// (Deprecated) Overall relevancy score for the web page.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
		
		/// <summary>
		/// The result web page URL.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="url")]
		public string Url { get; set; }
	}
	
	/// <summary>
	/// Entity deduced from similar images on the Internet.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1WebDetectionWebEntity
	{
		
		/// <summary>
		/// Canonical description of the entity, in English.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="description")]
		public string Description { get; set; }
		
		/// <summary>
		/// Opaque entity ID.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="entityId")]
		public string EntityId { get; set; }
		
		/// <summary>
		/// Overall relevancy score for the entity. Not normalized and not comparable across different image queries.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="score")]
		public System.Nullable<System.Single> Score { get; set; }
	}
	
	/// <summary>
	/// The response for a single offline file annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1AsyncAnnotateFileResponse
	{
		
		/// <summary>
		/// The desired output location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="outputConfig")]
		public GoogleCloudVisionV1p4beta1OutputConfig OutputConfig { get; set; }
	}
	
	/// <summary>
	/// The desired output location and metadata.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1OutputConfig
	{
		
		/// <summary>
		/// The max number of response protos to put into each output JSON file on Google Cloud Storage. The valid range is [1, 100]. If not specified, the default value is 20. For example, for one pdf file with 100 pages, 100 response protos will be generated. If `batch_size` = 20, then 5 json files each containing 20 response protos will be written under the prefix `gcs_destination`.`uri`. Currently, batch_size only applies to GcsDestination, with potential future support for other output configurations.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="batchSize")]
		public System.Nullable<System.Int32> BatchSize { get; set; }
		
		/// <summary>
		/// The Google Cloud Storage location where the output will be written to.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="gcsDestination")]
		public GoogleCloudVisionV1p4beta1GcsDestination GcsDestination { get; set; }
	}
	
	/// <summary>
	/// The Google Cloud Storage location where the output will be written to.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1GcsDestination
	{
		
		/// <summary>
		/// Google Cloud Storage URI prefix where the results will be stored. Results will be in JSON format and preceded by its corresponding input URI prefix. This field can either represent a gcs file prefix or gcs directory. In either case, the uri should be unique because in order to get all of the output files, you will need to do a wildcard gcs search on the uri prefix you provide. Examples: * File Prefix: gs://bucket-name/here/filenameprefix The output files will be created in gs://bucket-name/here/ and the names of the output files will begin with "filenameprefix". * Directory Prefix: gs://bucket-name/some/location/ The output files will be created in gs://bucket-name/some/location/ and the names of the output files could be anything because there was no filename prefix specified. If multiple outputs, each response is still AnnotateFileResponse, each of which contains some subset of the full list of AnnotateImageResponse. Multiple outputs can happen if, for example, the output JSON is too large and overflows into multiple sharded files.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Response to an async batch file annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1AsyncBatchAnnotateFilesResponse
	{
		
		/// <summary>
		/// The list of file annotation responses, one for each request in AsyncBatchAnnotateFilesRequest.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="responses")]
		public GoogleCloudVisionV1p4beta1AsyncAnnotateFileResponse[] Responses { get; set; }
	}
	
	/// <summary>
	/// Response to an async batch image annotation request.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1AsyncBatchAnnotateImagesResponse
	{
		
		/// <summary>
		/// The desired output location and metadata.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="outputConfig")]
		public GoogleCloudVisionV1p4beta1OutputConfig OutputConfig { get; set; }
	}
	
	/// <summary>
	/// A list of file annotation responses.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1BatchAnnotateFilesResponse
	{
		
		/// <summary>
		/// The list of file annotation responses, each response corresponding to each AnnotateFileRequest in BatchAnnotateFilesRequest.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="responses")]
		public GoogleCloudVisionV1p4beta1AnnotateFileResponse[] Responses { get; set; }
	}
	
	/// <summary>
	/// Metadata for the batch operations such as the current state. This is included in the `metadata` field of the `Operation` returned by the `GetOperation` call of the `google::longrunning::Operations` service.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1BatchOperationMetadata
	{
		
		/// <summary>
		/// The time when the batch request is finished and google.longrunning.Operation.done is set to true.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="endTime")]
		public string EndTime { get; set; }
		
		/// <summary>
		/// The current state of the batch operation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="state")]
		public BatchOperationMetadataState State { get; set; }
		
		/// <summary>
		/// The time when the batch request was submitted to the server.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="submitTime")]
		public string SubmitTime { get; set; }
	}
	
	/// <summary>
	/// Response message for the `ImportProductSets` method. This message is returned by the google.longrunning.Operations.GetOperation method in the returned google.longrunning.Operation.response field.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1ImportProductSetsResponse
	{
		
		/// <summary>
		/// The list of reference_images that are imported successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="referenceImages")]
		public GoogleCloudVisionV1p4beta1ReferenceImage[] ReferenceImages { get; set; }
		
		/// <summary>
		/// The rpc status for each ImportProductSet request, including both successes and errors. The number of statuses here matches the number of lines in the csv file, and statuses[i] stores the success or failure status of processing the i-th line of the csv, starting from line 0.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="statuses")]
		public Status[] Statuses { get; set; }
	}
	
	/// <summary>
	/// A `ReferenceImage` represents a product image and its associated metadata, such as bounding boxes.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1ReferenceImage
	{
		
		/// <summary>
		/// Optional. Bounding polygons around the areas of interest in the reference image. If this field is empty, the system will try to detect regions of interest. At most 10 bounding polygons will be used. The provided shape is converted into a non-rotated rectangle. Once converted, the small edge of the rectangle must be greater than or equal to 300 pixels. The aspect ratio must be 1:4 or less (i.e. 1:3 is ok; 1:5 is not).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPolys")]
		public GoogleCloudVisionV1p4beta1BoundingPoly[] BoundingPolys { get; set; }
		
		/// <summary>
		/// The resource name of the reference image. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID/referenceImages/IMAGE_ID`. This field is ignored when creating a reference image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Required. The Google Cloud Storage URI of the reference image. The URI must start with `gs://`.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// Contains metadata for the BatchAnnotateImages operation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class GoogleCloudVisionV1p4beta1OperationMetadata
	{
		
		/// <summary>
		/// The time when the batch request was received.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="createTime")]
		public string CreateTime { get; set; }
		
		/// <summary>
		/// Current state of the batch operation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="state")]
		public GoogleCloudVisionV1p1beta1OperationMetadataState State { get; set; }
		
		/// <summary>
		/// The time when the operation result was last updated.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="updateTime")]
		public string UpdateTime { get; set; }
	}
	
	/// <summary>
	/// The Google Cloud Storage location for a csv file which preserves a list of ImportProductSetRequests in each line.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ImportProductSetsGcsSource
	{
		
		/// <summary>
		/// The Google Cloud Storage URI of the input csv file. The URI must start with `gs://`. The format of the input csv file should be one image per line. In each line, there are 8 columns. 1. image-uri 2. image-id 3. product-set-id 4. product-id 5. product-category 6. product-display-name 7. labels 8. bounding-poly The `image-uri`, `product-set-id`, `product-id`, and `product-category` columns are required. All other columns are optional. If the `ProductSet` or `Product` specified by the `product-set-id` and `product-id` values does not exist, then the system will create a new `ProductSet` or `Product` for the image. In this case, the `product-display-name` column refers to display_name, the `product-category` column refers to product_category, and the `labels` column refers to product_labels. The `image-id` column is optional but must be unique if provided. If it is empty, the system will automatically assign a unique id to the image. The `product-display-name` column is optional. If it is empty, the system sets the display_name field for the product to a space (" "). You can update the `display_name` later by using the API. If a `Product` with the specified `product-id` already exists, then the system ignores the `product-display-name`, `product-category`, and `labels` columns. The `labels` column (optional) is a line containing a list of comma-separated key-value pairs, in the following format: "key_1=value_1,key_2=value_2,...,key_n=value_n" The `bounding-poly` column (optional) identifies one region of interest from the image in the same manner as `CreateReferenceImage`. If you do not specify the `bounding-poly` column, then the system will try to detect regions of interest automatically. At most one `bounding-poly` column is allowed per line. If the image contains multiple regions of interest, add a line to the CSV file that includes the same product information, and the `bounding-poly` values for each region of interest. The `bounding-poly` column must contain an even number of comma-separated numbers, in the format "p1_x,p1_y,p2_x,p2_y,...,pn_x,pn_y". Use non-negative integers for absolute bounding polygons, and float values in [0, 1] for normalized bounding polygons. The system will resize the image if the image resolution is too large to process (larger than 20MP).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="csvFileUri")]
		public string CsvFileUri { get; set; }
	}
	
	/// <summary>
	/// The input content for the `ImportProductSets` method.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ImportProductSetsInputConfig
	{
		
		/// <summary>
		/// The Google Cloud Storage location for a csv file which preserves a list of ImportProductSetRequests in each line.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="gcsSource")]
		public ImportProductSetsGcsSource GcsSource { get; set; }
	}
	
	/// <summary>
	/// Request message for the `ImportProductSets` method.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ImportProductSetsRequest
	{
		
		/// <summary>
		/// The input content for the `ImportProductSets` method.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="inputConfig")]
		public ImportProductSetsInputConfig InputConfig { get; set; }
	}
	
	/// <summary>
	/// Response message for the `ImportProductSets` method. This message is returned by the google.longrunning.Operations.GetOperation method in the returned google.longrunning.Operation.response field.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ImportProductSetsResponse
	{
		
		/// <summary>
		/// The list of reference_images that are imported successfully.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="referenceImages")]
		public ReferenceImage[] ReferenceImages { get; set; }
		
		/// <summary>
		/// The rpc status for each ImportProductSet request, including both successes and errors. The number of statuses here matches the number of lines in the csv file, and statuses[i] stores the success or failure status of processing the i-th line of the csv, starting from line 0.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="statuses")]
		public Status[] Statuses { get; set; }
	}
	
	/// <summary>
	/// A `ReferenceImage` represents a product image and its associated metadata, such as bounding boxes.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ReferenceImage
	{
		
		/// <summary>
		/// Optional. Bounding polygons around the areas of interest in the reference image. If this field is empty, the system will try to detect regions of interest. At most 10 bounding polygons will be used. The provided shape is converted into a non-rotated rectangle. Once converted, the small edge of the rectangle must be greater than or equal to 300 pixels. The aspect ratio must be 1:4 or less (i.e. 1:3 is ok; 1:5 is not).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="boundingPolys")]
		public BoundingPoly[] BoundingPolys { get; set; }
		
		/// <summary>
		/// The resource name of the reference image. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID/referenceImages/IMAGE_ID`. This field is ignored when creating a reference image.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// Required. The Google Cloud Storage URI of the reference image. The URI must start with `gs://`.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="uri")]
		public string Uri { get; set; }
	}
	
	/// <summary>
	/// The response message for Operations.ListOperations.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ListOperationsResponse
	{
		
		/// <summary>
		/// The standard List next-page token.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="nextPageToken")]
		public string NextPageToken { get; set; }
		
		/// <summary>
		/// A list of operations that matches the specified filter in the request.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="operations")]
		public Operation[] Operations { get; set; }
	}
	
	/// <summary>
	/// This resource represents a long-running operation that is the result of a network API call.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class Operation
	{
		
		/// <summary>
		/// If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="done")]
		public System.Nullable<System.Boolean> Done { get; set; }
		
		/// <summary>
		/// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="error")]
		public Status Error { get; set; }
		
		/// <summary>
		/// Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="metadata")]
		public System.Collections.Generic.Dictionary<string, object> Metadata { get; set; }
		
		/// <summary>
		/// The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
		
		/// <summary>
		/// The normal, successful response of the operation. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="response")]
		public System.Collections.Generic.Dictionary<string, object> Response { get; set; }
	}
	
	/// <summary>
	/// Response message for the `ListProductSets` method.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ListProductSetsResponse
	{
		
		/// <summary>
		/// Token to retrieve the next page of results, or empty if there are no more results in the list.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="nextPageToken")]
		public string NextPageToken { get; set; }
		
		/// <summary>
		/// List of ProductSets.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productSets")]
		public ProductSet[] ProductSets { get; set; }
	}
	
	/// <summary>
	/// A ProductSet contains Products. A ProductSet can contain a maximum of 1 million reference images. If the limit is exceeded, periodic indexing will fail.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ProductSet
	{
		
		/// <summary>
		/// The user-provided name for this ProductSet. Must not be empty. Must be at most 4096 characters long.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="displayName")]
		public string DisplayName { get; set; }
		
		/// <summary>
		/// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="indexError")]
		public Status IndexError { get; set; }
		
		/// <summary>
		/// Output only. The time at which this ProductSet was last indexed. Query results will reflect all updates before this time. If this ProductSet has never been indexed, this timestamp is the default value "1970-01-01T00:00:00Z". This field is ignored when creating a ProductSet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="indexTime")]
		public string IndexTime { get; set; }
		
		/// <summary>
		/// The resource name of the ProductSet. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`. This field is ignored when creating a ProductSet.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="name")]
		public string Name { get; set; }
	}
	
	/// <summary>
	/// Response message for the `ListProductsInProductSet` method.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ListProductsInProductSetResponse
	{
		
		/// <summary>
		/// Token to retrieve the next page of results, or empty if there are no more results in the list.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="nextPageToken")]
		public string NextPageToken { get; set; }
		
		/// <summary>
		/// The list of Products.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="products")]
		public Product[] Products { get; set; }
	}
	
	/// <summary>
	/// Response message for the `ListProducts` method.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ListProductsResponse
	{
		
		/// <summary>
		/// Token to retrieve the next page of results, or empty if there are no more results in the list.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="nextPageToken")]
		public string NextPageToken { get; set; }
		
		/// <summary>
		/// List of products.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="products")]
		public Product[] Products { get; set; }
	}
	
	/// <summary>
	/// Response message for the `ListReferenceImages` method.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ListReferenceImagesResponse
	{
		
		/// <summary>
		/// The next_page_token returned from a previous List request, if any.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="nextPageToken")]
		public string NextPageToken { get; set; }
		
		/// <summary>
		/// The maximum number of items to return. Default 10, maximum 100.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="pageSize")]
		public System.Nullable<System.Int32> PageSize { get; set; }
		
		/// <summary>
		/// The list of reference images.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="referenceImages")]
		public ReferenceImage[] ReferenceImages { get; set; }
	}
	
	/// <summary>
	/// Contains metadata for the BatchAnnotateImages operation.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class OperationMetadata
	{
		
		/// <summary>
		/// The time when the batch request was received.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="createTime")]
		public string CreateTime { get; set; }
		
		/// <summary>
		/// Current state of the batch operation.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="state")]
		public GoogleCloudVisionV1p1beta1OperationMetadataState State { get; set; }
		
		/// <summary>
		/// The time when the operation result was last updated.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="updateTime")]
		public string UpdateTime { get; set; }
	}
	
	/// <summary>
	/// Config to control which ProductSet contains the Products to be deleted.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class ProductSetPurgeConfig
	{
		
		/// <summary>
		/// The ProductSet that contains the Products to delete. If a Product is a member of product_set_id in addition to other ProductSets, the Product will still be deleted.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productSetId")]
		public string ProductSetId { get; set; }
	}
	
	/// <summary>
	/// Request message for the `PurgeProducts` method.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class PurgeProductsRequest
	{
		
		/// <summary>
		/// If delete_orphan_products is true, all Products that are not in any ProductSet will be deleted.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="deleteOrphanProducts")]
		public System.Nullable<System.Boolean> DeleteOrphanProducts { get; set; }
		
		/// <summary>
		/// The default value is false. Override this value to true to actually perform the purge.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="force")]
		public System.Nullable<System.Boolean> Force { get; set; }
		
		/// <summary>
		/// Config to control which ProductSet contains the Products to be deleted.
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="productSetPurgeConfig")]
		public ProductSetPurgeConfig ProductSetPurgeConfig { get; set; }
	}
	
	/// <summary>
	/// Request message for the `RemoveProductFromProductSet` method.
	/// </summary>
	[System.Runtime.Serialization.DataContract(Namespace="http://fonlow.com/TestOpenApi/2024/04")]
	public class RemoveProductFromProductSetRequest
	{
		
		/// <summary>
		/// Required. The resource name for the Product to be removed from this ProductSet. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID`
		/// </summary>
		[System.Runtime.Serialization.DataMember(Name="product")]
		public string Product { get; set; }
	}
	
	public partial class Misc
	{
		
		private System.Net.Http.HttpClient httpClient;
		
		private JsonSerializerSettings jsonSerializerSettings;
		
		public Misc(System.Net.Http.HttpClient httpClient, JsonSerializerSettings jsonSerializerSettings=null)
		{
			if (httpClient == null)
				throw new ArgumentNullException("Null HttpClient.", "httpClient");

			if (httpClient.BaseAddress == null)
				throw new ArgumentNullException("HttpClient has no BaseAddress", "httpClient");

			this.httpClient = httpClient;
			this.jsonSerializerSettings = jsonSerializerSettings;
		}
		
		/// <summary>
		/// Service that performs image detection and annotation for a batch of files. Now only "application/pdf", "image/tiff" and "image/gif" are supported. This service will extract at most 5 (customers can specify which 5 in AnnotateFileRequest.pages) frames (gif) or pages (pdf or tiff) from each file provided and perform detection and annotation for each image extracted.
		/// Vision_files_annotate v1/files:annotate
		/// </summary>
		/// <returns>Successful response</returns>
		public async Task<BatchAnnotateFilesResponse> Vision_files_annotateAsync(BatchAnnotateFilesRequest requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/files:annotate";
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<BatchAnnotateFilesResponse>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Run asynchronous image detection and annotation for a list of generic files, such as PDF files, which may contain multiple pages and multiple images per page. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateFilesResponse` (results).
		/// Vision_files_asyncBatchAnnotate v1/files:asyncBatchAnnotate
		/// </summary>
		/// <returns>Successful response</returns>
		public async Task<Operation> Vision_files_asyncBatchAnnotateAsync(AsyncBatchAnnotateFilesRequest requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/files:asyncBatchAnnotate";
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<Operation>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Run image detection and annotation for a batch of images.
		/// Vision_images_annotate v1/images:annotate
		/// </summary>
		/// <returns>Successful response</returns>
		public async Task<BatchAnnotateImagesResponse> Vision_images_annotateAsync(BatchAnnotateImagesRequest requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/images:annotate";
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<BatchAnnotateImagesResponse>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Run asynchronous image detection and annotation for a list of images. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateImagesResponse` (results). This service will write image annotation outputs to json files in customer GCS bucket, each json file containing BatchAnnotateImagesResponse proto.
		/// Vision_images_asyncBatchAnnotate v1/images:asyncBatchAnnotate
		/// </summary>
		/// <returns>Successful response</returns>
		public async Task<Operation> Vision_images_asyncBatchAnnotateAsync(AsyncBatchAnnotateImagesRequest requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/images:asyncBatchAnnotate";
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<Operation>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Permanently deletes a ProductSet. Products and ReferenceImages in the ProductSet are not deleted. The actual image files are not deleted from Google Cloud Storage.
		/// Vision_projects_locations_productSets_delete v1/{name}
		/// </summary>
		/// <param name="name">Required. Resource name of the ProductSet to delete. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`</param>
		/// <returns>Successful response</returns>
		public async Task<Empty> Vision_projects_locations_productSets_deleteAsync(string name, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (name==null? "" : System.Uri.EscapeDataString(name));
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Delete, requestUri))
			{
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<Empty>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
		}
		
		/// <summary>
		/// Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service.
		/// Vision_projects_operations_get v1/{name}
		/// </summary>
		/// <param name="name">The name of the operation resource.</param>
		/// <param name="filter">The standard list filter.</param>
		/// <param name="pageSize">The standard list page size.</param>
		/// <param name="pageToken">The standard list page token.</param>
		/// <returns>Successful response</returns>
		public async Task<Operation> Vision_projects_operations_getAsync(string name, string filter, int pageSize, string pageToken, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (name==null? "" : System.Uri.EscapeDataString(name))+"&filter=" + (filter==null? "" : System.Uri.EscapeDataString(filter))+"&pageSize="+pageSize+"&pageToken=" + (pageToken==null? "" : System.Uri.EscapeDataString(pageToken));
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Get, requestUri))
			{
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<Operation>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
		}
		
		/// <summary>
		/// Makes changes to a ProductSet resource. Only display_name can be updated currently. Possible errors: * Returns NOT_FOUND if the ProductSet does not exist. * Returns INVALID_ARGUMENT if display_name is present in update_mask but missing from the request or longer than 4096 characters.
		/// Vision_projects_locations_productSets_patch v1/{name}
		/// </summary>
		/// <param name="name">The resource name of the ProductSet. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`. This field is ignored when creating a ProductSet.</param>
		/// <param name="updateMask">The FieldMask that specifies which fields to update. If update_mask isn't specified, all mutable fields are to be updated. Valid mask path is `display_name`.</param>
		/// <returns>Successful response</returns>
		public async Task<ProductSet> Vision_projects_locations_productSets_patchAsync(string name, string updateMask, ProductSet requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (name==null? "" : System.Uri.EscapeDataString(name))+"&updateMask=" + (updateMask==null? "" : System.Uri.EscapeDataString(updateMask));
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Patch, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<ProductSet>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Lists the Products in a ProductSet, in an unspecified order. If the ProductSet does not exist, the products field of the response will be empty. Possible errors: * Returns INVALID_ARGUMENT if page_size is greater than 100 or less than 1.
		/// Vision_projects_locations_productSets_products_list v1/{name}/products
		/// </summary>
		/// <param name="name">Required. The ProductSet resource for which to retrieve Products. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`</param>
		/// <param name="pageSize">The maximum number of items to return. Default 10, maximum 100.</param>
		/// <param name="pageToken">The next_page_token returned from a previous List request, if any.</param>
		/// <returns>Successful response</returns>
		public async Task<ListProductsInProductSetResponse> Vision_projects_locations_productSets_products_listAsync(string name, int pageSize, string pageToken, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (name==null? "" : System.Uri.EscapeDataString(name))+"/products&pageSize="+pageSize+"&pageToken=" + (pageToken==null? "" : System.Uri.EscapeDataString(pageToken));
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Get, requestUri))
			{
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<ListProductsInProductSetResponse>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
		}
		
		/// <summary>
		/// Adds a Product to the specified ProductSet. If the Product is already present, no change is made. One Product can be added to at most 100 ProductSets. Possible errors: * Returns NOT_FOUND if the Product or the ProductSet doesn't exist.
		/// Vision_projects_locations_productSets_addProduct v1/{name}:addProduct
		/// </summary>
		/// <param name="name">Required. The resource name for the ProductSet to modify. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`</param>
		/// <returns>Successful response</returns>
		public async Task<Empty> Vision_projects_locations_productSets_addProductAsync(string name, AddProductToProductSetRequest requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (name==null? "" : System.Uri.EscapeDataString(name))+":addProduct";
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<Empty>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Starts asynchronous cancellation on a long-running operation. The server makes a best effort to cancel the operation, but success is not guaranteed. If the server doesn't support this method, it returns `google.rpc.Code.UNIMPLEMENTED`. Clients can use Operations.GetOperation or other methods to check whether the cancellation succeeded or whether the operation completed despite cancellation. On successful cancellation, the operation is not deleted; instead, it becomes an operation with an Operation.error value with a google.rpc.Status.code of 1, corresponding to `Code.CANCELLED`.
		/// Vision_operations_cancel v1/{name}:cancel
		/// </summary>
		/// <param name="name">The name of the operation resource to be cancelled.</param>
		/// <returns>Successful response</returns>
		public async Task<Empty> Vision_operations_cancelAsync(string name, CancelOperationRequest requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (name==null? "" : System.Uri.EscapeDataString(name))+":cancel";
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<Empty>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Removes a Product from the specified ProductSet.
		/// Vision_projects_locations_productSets_removeProduct v1/{name}:removeProduct
		/// </summary>
		/// <param name="name">Required. The resource name for the ProductSet to modify. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`</param>
		/// <returns>Successful response</returns>
		public async Task<Empty> Vision_projects_locations_productSets_removeProductAsync(string name, RemoveProductFromProductSetRequest requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (name==null? "" : System.Uri.EscapeDataString(name))+":removeProduct";
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<Empty>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Service that performs image detection and annotation for a batch of files. Now only "application/pdf", "image/tiff" and "image/gif" are supported. This service will extract at most 5 (customers can specify which 5 in AnnotateFileRequest.pages) frames (gif) or pages (pdf or tiff) from each file provided and perform detection and annotation for each image extracted.
		/// Vision_projects_locations_files_annotate v1/{parent}/files:annotate
		/// </summary>
		/// <param name="parent">Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`.</param>
		/// <returns>Successful response</returns>
		public async Task<BatchAnnotateFilesResponse> Vision_projects_locations_files_annotateAsync(string parent, BatchAnnotateFilesRequest requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (parent==null? "" : System.Uri.EscapeDataString(parent))+"/files:annotate";
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<BatchAnnotateFilesResponse>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Run asynchronous image detection and annotation for a list of generic files, such as PDF files, which may contain multiple pages and multiple images per page. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateFilesResponse` (results).
		/// Vision_projects_locations_files_asyncBatchAnnotate v1/{parent}/files:asyncBatchAnnotate
		/// </summary>
		/// <param name="parent">Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`.</param>
		/// <returns>Successful response</returns>
		public async Task<Operation> Vision_projects_locations_files_asyncBatchAnnotateAsync(string parent, AsyncBatchAnnotateFilesRequest requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (parent==null? "" : System.Uri.EscapeDataString(parent))+"/files:asyncBatchAnnotate";
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<Operation>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Run image detection and annotation for a batch of images.
		/// Vision_projects_locations_images_annotate v1/{parent}/images:annotate
		/// </summary>
		/// <param name="parent">Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`.</param>
		/// <returns>Successful response</returns>
		public async Task<BatchAnnotateImagesResponse> Vision_projects_locations_images_annotateAsync(string parent, BatchAnnotateImagesRequest requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (parent==null? "" : System.Uri.EscapeDataString(parent))+"/images:annotate";
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<BatchAnnotateImagesResponse>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Run asynchronous image detection and annotation for a list of images. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateImagesResponse` (results). This service will write image annotation outputs to json files in customer GCS bucket, each json file containing BatchAnnotateImagesResponse proto.
		/// Vision_projects_locations_images_asyncBatchAnnotate v1/{parent}/images:asyncBatchAnnotate
		/// </summary>
		/// <param name="parent">Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`.</param>
		/// <returns>Successful response</returns>
		public async Task<Operation> Vision_projects_locations_images_asyncBatchAnnotateAsync(string parent, AsyncBatchAnnotateImagesRequest requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (parent==null? "" : System.Uri.EscapeDataString(parent))+"/images:asyncBatchAnnotate";
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<Operation>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Lists ProductSets in an unspecified order. Possible errors: * Returns INVALID_ARGUMENT if page_size is greater than 100, or less than 1.
		/// Vision_projects_locations_productSets_list v1/{parent}/productSets
		/// </summary>
		/// <param name="parent">Required. The project from which ProductSets should be listed. Format is `projects/PROJECT_ID/locations/LOC_ID`.</param>
		/// <param name="pageSize">The maximum number of items to return. Default 10, maximum 100.</param>
		/// <param name="pageToken">The next_page_token returned from a previous List request, if any.</param>
		/// <returns>Successful response</returns>
		public async Task<ListProductSetsResponse> Vision_projects_locations_productSets_listAsync(string parent, int pageSize, string pageToken, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (parent==null? "" : System.Uri.EscapeDataString(parent))+"/productSets&pageSize="+pageSize+"&pageToken=" + (pageToken==null? "" : System.Uri.EscapeDataString(pageToken));
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Get, requestUri))
			{
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<ListProductSetsResponse>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
		}
		
		/// <summary>
		/// Creates and returns a new ProductSet resource. Possible errors: * Returns INVALID_ARGUMENT if display_name is missing, or is longer than 4096 characters.
		/// Vision_projects_locations_productSets_create v1/{parent}/productSets
		/// </summary>
		/// <param name="parent">Required. The project in which the ProductSet should be created. Format is `projects/PROJECT_ID/locations/LOC_ID`.</param>
		/// <param name="productSetId">A user-supplied resource id for this ProductSet. If set, the server will attempt to use this value as the resource id. If it is already in use, an error is returned with code ALREADY_EXISTS. Must be at most 128 characters long. It cannot contain the character `/`.</param>
		/// <returns>Successful response</returns>
		public async Task<ProductSet> Vision_projects_locations_productSets_createAsync(string parent, string productSetId, ProductSet requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (parent==null? "" : System.Uri.EscapeDataString(parent))+"/productSets&productSetId=" + (productSetId==null? "" : System.Uri.EscapeDataString(productSetId));
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<ProductSet>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Asynchronous API that imports a list of reference images to specified product sets based on a list of image information. The google.longrunning.Operation API can be used to keep track of the progress and results of the request. `Operation.metadata` contains `BatchOperationMetadata`. (progress) `Operation.response` contains `ImportProductSetsResponse`. (results) The input source of this method is a csv file on Google Cloud Storage. For the format of the csv file please see ImportProductSetsGcsSource.csv_file_uri.
		/// Vision_projects_locations_productSets_import v1/{parent}/productSets:import
		/// </summary>
		/// <param name="parent">Required. The project in which the ProductSets should be imported. Format is `projects/PROJECT_ID/locations/LOC_ID`.</param>
		/// <returns>Successful response</returns>
		public async Task<Operation> Vision_projects_locations_productSets_importAsync(string parent, ImportProductSetsRequest requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (parent==null? "" : System.Uri.EscapeDataString(parent))+"/productSets:import";
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<Operation>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Lists products in an unspecified order. Possible errors: * Returns INVALID_ARGUMENT if page_size is greater than 100 or less than 1.
		/// Vision_projects_locations_products_list v1/{parent}/products
		/// </summary>
		/// <param name="parent">Required. The project OR ProductSet from which Products should be listed. Format: `projects/PROJECT_ID/locations/LOC_ID`</param>
		/// <param name="pageSize">The maximum number of items to return. Default 10, maximum 100.</param>
		/// <param name="pageToken">The next_page_token returned from a previous List request, if any.</param>
		/// <returns>Successful response</returns>
		public async Task<ListProductsResponse> Vision_projects_locations_products_listAsync(string parent, int pageSize, string pageToken, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (parent==null? "" : System.Uri.EscapeDataString(parent))+"/products&pageSize="+pageSize+"&pageToken=" + (pageToken==null? "" : System.Uri.EscapeDataString(pageToken));
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Get, requestUri))
			{
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<ListProductsResponse>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
		}
		
		/// <summary>
		/// Creates and returns a new product resource. Possible errors: * Returns INVALID_ARGUMENT if display_name is missing or longer than 4096 characters. * Returns INVALID_ARGUMENT if description is longer than 4096 characters. * Returns INVALID_ARGUMENT if product_category is missing or invalid.
		/// Vision_projects_locations_products_create v1/{parent}/products
		/// </summary>
		/// <param name="parent">Required. The project in which the Product should be created. Format is `projects/PROJECT_ID/locations/LOC_ID`.</param>
		/// <param name="productId">A user-supplied resource id for this Product. If set, the server will attempt to use this value as the resource id. If it is already in use, an error is returned with code ALREADY_EXISTS. Must be at most 128 characters long. It cannot contain the character `/`.</param>
		/// <returns>Successful response</returns>
		public async Task<Product> Vision_projects_locations_products_createAsync(string parent, string productId, Product requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (parent==null? "" : System.Uri.EscapeDataString(parent))+"/products&productId=" + (productId==null? "" : System.Uri.EscapeDataString(productId));
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<Product>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Asynchronous API to delete all Products in a ProductSet or all Products that are in no ProductSet. If a Product is a member of the specified ProductSet in addition to other ProductSets, the Product will still be deleted. It is recommended to not delete the specified ProductSet until after this operation has completed. It is also recommended to not add any of the Products involved in the batch delete to a new ProductSet while this operation is running because those Products may still end up deleted. It's not possible to undo the PurgeProducts operation. Therefore, it is recommended to keep the csv files used in ImportProductSets (if that was how you originally built the Product Set) before starting PurgeProducts, in case you need to re-import the data after deletion. If the plan is to purge all of the Products from a ProductSet and then re-use the empty ProductSet to re-import new Products into the empty ProductSet, you must wait until the PurgeProducts operation has finished for that ProductSet. The google.longrunning.Operation API can be used to keep track of the progress and results of the request. `Operation.metadata` contains `BatchOperationMetadata`. (progress)
		/// Vision_projects_locations_products_purge v1/{parent}/products:purge
		/// </summary>
		/// <param name="parent">Required. The project and location in which the Products should be deleted. Format is `projects/PROJECT_ID/locations/LOC_ID`.</param>
		/// <returns>Successful response</returns>
		public async Task<Operation> Vision_projects_locations_products_purgeAsync(string parent, PurgeProductsRequest requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (parent==null? "" : System.Uri.EscapeDataString(parent))+"/products:purge";
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<Operation>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
		
		/// <summary>
		/// Lists reference images. Possible errors: * Returns NOT_FOUND if the parent product does not exist. * Returns INVALID_ARGUMENT if the page_size is greater than 100, or less than 1.
		/// Vision_projects_locations_products_referenceImages_list v1/{parent}/referenceImages
		/// </summary>
		/// <param name="parent">Required. Resource name of the product containing the reference images. Format is `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID`.</param>
		/// <param name="pageSize">The maximum number of items to return. Default 10, maximum 100.</param>
		/// <param name="pageToken">A token identifying a page of results to be returned. This is the value of `nextPageToken` returned in a previous reference image list request. Defaults to the first page if not specified.</param>
		/// <returns>Successful response</returns>
		public async Task<ListReferenceImagesResponse> Vision_projects_locations_products_referenceImages_listAsync(string parent, int pageSize, string pageToken, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (parent==null? "" : System.Uri.EscapeDataString(parent))+"/referenceImages&pageSize="+pageSize+"&pageToken=" + (pageToken==null? "" : System.Uri.EscapeDataString(pageToken));
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Get, requestUri))
			{
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<ListReferenceImagesResponse>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
		}
		
		/// <summary>
		/// Creates and returns a new ReferenceImage resource. The `bounding_poly` field is optional. If `bounding_poly` is not specified, the system will try to detect regions of interest in the image that are compatible with the product_category on the parent product. If it is specified, detection is ALWAYS skipped. The system converts polygons into non-rotated rectangles. Note that the pipeline will resize the image if the image resolution is too large to process (above 50MP). Possible errors: * Returns INVALID_ARGUMENT if the image_uri is missing or longer than 4096 characters. * Returns INVALID_ARGUMENT if the product does not exist. * Returns INVALID_ARGUMENT if bounding_poly is not provided, and nothing compatible with the parent product's product_category is detected. * Returns INVALID_ARGUMENT if bounding_poly contains more than 10 polygons.
		/// Vision_projects_locations_products_referenceImages_create v1/{parent}/referenceImages
		/// </summary>
		/// <param name="parent">Required. Resource name of the product in which to create the reference image. Format is `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID`.</param>
		/// <param name="referenceImageId">A user-supplied resource id for the ReferenceImage to be added. If set, the server will attempt to use this value as the resource id. If it is already in use, an error is returned with code ALREADY_EXISTS. Must be at most 128 characters long. It cannot contain the character `/`.</param>
		/// <returns>Successful response</returns>
		public async Task<ReferenceImage> Vision_projects_locations_products_referenceImages_createAsync(string parent, string referenceImageId, ReferenceImage requestBody, Action<System.Net.Http.Headers.HttpRequestHeaders> handleHeaders = null)
		{
			var requestUri = "v1/"+ (parent==null? "" : System.Uri.EscapeDataString(parent))+"/referenceImages&referenceImageId=" + (referenceImageId==null? "" : System.Uri.EscapeDataString(referenceImageId));
			using (var httpRequestMessage = new System.Net.Http.HttpRequestMessage(System.Net.Http.HttpMethod.Post, requestUri))
			{
			using (var requestWriter = new System.IO.StringWriter())
			{
			var requestSerializer = JsonSerializer.Create(jsonSerializerSettings);
			requestSerializer.Serialize(requestWriter, requestBody);
			var content = new System.Net.Http.StringContent(requestWriter.ToString(), System.Text.Encoding.UTF8, "application/json");
			httpRequestMessage.Content = content;
			if (handleHeaders != null)
			{
				handleHeaders(httpRequestMessage.Headers);
			}

			var responseMessage = await httpClient.SendAsync(httpRequestMessage);
			try
			{
				responseMessage.EnsureSuccessStatusCodeEx();
				var responseMessageStream = await responseMessage.Content.ReadAsStreamAsync();
				using (JsonReader jsonReader = new JsonTextReader(new System.IO.StreamReader(responseMessageStream)))
				{
				var serializer = JsonSerializer.Create(jsonSerializerSettings);
				return serializer.Deserialize<ReferenceImage>(jsonReader);
				}
			}
			finally
			{
				responseMessage.Dispose();
			}
			}
			}
		}
	}
}

namespace Fonlow.Net.Http
{
	using System.Net.Http;

	public class WebApiRequestException : HttpRequestException
	{
		public System.Net.HttpStatusCode StatusCode { get; private set; }

		public string Response { get; private set; }

		public System.Net.Http.Headers.HttpResponseHeaders Headers { get; private set; }

		public System.Net.Http.Headers.MediaTypeHeaderValue ContentType { get; private set; }

		public WebApiRequestException(string message, System.Net.HttpStatusCode statusCode, string response, System.Net.Http.Headers.HttpResponseHeaders headers, System.Net.Http.Headers.MediaTypeHeaderValue contentType) : base(message)
		{
			StatusCode = statusCode;
			Response = response;
			Headers = headers;
			ContentType = contentType;
		}
	}

	public static class ResponseMessageExtensions
	{
		public static void EnsureSuccessStatusCodeEx(this HttpResponseMessage responseMessage)
		{
			if (!responseMessage.IsSuccessStatusCode)
			{
				var responseText = responseMessage.Content.ReadAsStringAsync().Result;
				var contentType = responseMessage.Content.Headers.ContentType;
				throw new WebApiRequestException(responseMessage.ReasonPhrase, responseMessage.StatusCode, responseText, responseMessage.Headers, contentType);
			}
		}
	}
}
